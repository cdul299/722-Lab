
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{DataExploration1}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{n}{dataset} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dataset.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{dataset}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
      Age Attrition     BusinessTravel  DailyRate              Department  \textbackslash{}
0      41       Yes      Travel\_Rarely       1102                   Sales   
1      49        No  Travel\_Frequently        279  Research \& Development   
2      37       Yes      Travel\_Rarely       1373  Research \& Development   
3      33        No  Travel\_Frequently       1392  Research \& Development   
4      27        No      Travel\_Rarely        591  Research \& Development   
5      32        No  Travel\_Frequently       1005  Research \& Development   
6      59        No      Travel\_Rarely       1324  Research \& Development   
7      30        No      Travel\_Rarely       1358  Research \& Development   
8      38        No  Travel\_Frequently        216  Research \& Development   
9      36        No      Travel\_Rarely       1299  Research \& Development   
10     35        No      Travel\_Rarely        809  Research \& Development   
11     29        No      Travel\_Rarely        153  Research \& Development   
12     31        No      Travel\_Rarely        670  Research \& Development   
13     34        No      Travel\_Rarely       1346  Research \& Development   
14     28       Yes      Travel\_Rarely        103  Research \& Development   
15     29        No      Travel\_Rarely       1389  Research \& Development   
16     32        No      Travel\_Rarely        334  Research \& Development   
17     22        No         Non-Travel       1123  Research \& Development   
18     53        No      Travel\_Rarely       1219                   Sales   
19     38        No      Travel\_Rarely        371  Research \& Development   
20     24        No         Non-Travel        673  Research \& Development   
21     36       Yes      Travel\_Rarely       1218                   Sales   
22     34        No      Travel\_Rarely        419  Research \& Development   
23     21        No      Travel\_Rarely        391  Research \& Development   
24     34       Yes      Travel\_Rarely        699  Research \& Development   
25     53        No      Travel\_Rarely       1282  Research \& Development   
26     32       Yes  Travel\_Frequently       1125  Research \& Development   
27     42        No      Travel\_Rarely        691                   Sales   
28     44        No      Travel\_Rarely        477  Research \& Development   
29     46        No      Travel\_Rarely        705                   Sales   
{\ldots}   {\ldots}       {\ldots}                {\ldots}        {\ldots}                     {\ldots}   
1440   36        No  Travel\_Frequently        688  Research \& Development   
1441   56        No         Non-Travel        667  Research \& Development   
1442   29       Yes      Travel\_Rarely       1092  Research \& Development   
1443   42        No      Travel\_Rarely        300  Research \& Development   
1444   56       Yes      Travel\_Rarely        310  Research \& Development   
1445   41        No      Travel\_Rarely        582  Research \& Development   
1446   34        No      Travel\_Rarely        704                   Sales   
1447   36        No         Non-Travel        301                   Sales   
1448   41        No      Travel\_Rarely        930                   Sales   
1449   32        No      Travel\_Rarely        529  Research \& Development   
1450   35        No      Travel\_Rarely       1146         Human Resources   
1451   38        No      Travel\_Rarely        345                   Sales   
1452   50       Yes  Travel\_Frequently        878                   Sales   
1453   36        No      Travel\_Rarely       1120                   Sales   
1454   45        No      Travel\_Rarely        374                   Sales   
1455   40        No      Travel\_Rarely       1322  Research \& Development   
1456   35        No  Travel\_Frequently       1199  Research \& Development   
1457   40        No      Travel\_Rarely       1194  Research \& Development   
1458   35        No      Travel\_Rarely        287  Research \& Development   
1459   29        No      Travel\_Rarely       1378  Research \& Development   
1460   29        No      Travel\_Rarely        468  Research \& Development   
1461   50       Yes      Travel\_Rarely        410                   Sales   
1462   39        No      Travel\_Rarely        722                   Sales   
1463   31        No         Non-Travel        325  Research \& Development   
1464   26        No      Travel\_Rarely       1167                   Sales   
1465   36        No  Travel\_Frequently        884  Research \& Development   
1466   39        No      Travel\_Rarely        613  Research \& Development   
1467   27        No      Travel\_Rarely        155  Research \& Development   
1468   49        No  Travel\_Frequently       1023                   Sales   
1469   34        No      Travel\_Rarely        628  Research \& Development   

      DistanceFromHome  Education    EducationField  EmployeeCount  \textbackslash{}
0                    1          2     Life Sciences              1   
1                    8          1     Life Sciences              1   
2                    2          2             Other              1   
3                    3          4     Life Sciences              1   
4                    2          1           Medical              1   
5                    2          2     Life Sciences              1   
6                    3          3           Medical              1   
7                   24          1     Life Sciences              1   
8                   23          3     Life Sciences              1   
9                   27          3           Medical              1   
10                  16          3           Medical              1   
11                  15          2     Life Sciences              1   
12                  26          1     Life Sciences              1   
13                  19          2           Medical              1   
14                  24          3     Life Sciences              1   
15                  21          4     Life Sciences              1   
16                   5          2     Life Sciences              1   
17                  16          2           Medical              1   
18                   2          4     Life Sciences              1   
19                   2          3     Life Sciences              1   
20                  11          2             Other              1   
21                   9          4     Life Sciences              1   
22                   7          4     Life Sciences              1   
23                  15          2     Life Sciences              1   
24                   6          1           Medical              1   
25                   5          3             Other              1   
26                  16          1     Life Sciences              1   
27                   8          4         Marketing              1   
28                   7          4           Medical              1   
29                   2          4         Marketing              1   
{\ldots}                {\ldots}        {\ldots}               {\ldots}            {\ldots}   
1440                 4          2     Life Sciences              1   
1441                 1          4     Life Sciences              1   
1442                 1          4           Medical              1   
1443                 2          3     Life Sciences              1   
1444                 7          2  Technical Degree              1   
1445                28          4     Life Sciences              1   
1446                28          3         Marketing              1   
1447                15          4         Marketing              1   
1448                 3          3     Life Sciences              1   
1449                 2          3  Technical Degree              1   
1450                26          4     Life Sciences              1   
1451                10          2     Life Sciences              1   
1452                 1          4     Life Sciences              1   
1453                11          4         Marketing              1   
1454                20          3     Life Sciences              1   
1455                 2          4     Life Sciences              1   
1456                18          4     Life Sciences              1   
1457                 2          4           Medical              1   
1458                 1          4     Life Sciences              1   
1459                13          2             Other              1   
1460                28          4           Medical              1   
1461                28          3         Marketing              1   
1462                24          1         Marketing              1   
1463                 5          3           Medical              1   
1464                 5          3             Other              1   
1465                23          2           Medical              1   
1466                 6          1           Medical              1   
1467                 4          3     Life Sciences              1   
1468                 2          3           Medical              1   
1469                 8          3           Medical              1   

      EmployeeNumber          {\ldots}           RelationshipSatisfaction  \textbackslash{}
0                  1          {\ldots}                                  1   
1                  2          {\ldots}                                  4   
2                  4          {\ldots}                                  2   
3                  5          {\ldots}                                  3   
4                  7          {\ldots}                                  4   
5                  8          {\ldots}                                  3   
6                 10          {\ldots}                                  1   
7                 11          {\ldots}                                  2   
8                 12          {\ldots}                                  2   
9                 13          {\ldots}                                  2   
10                14          {\ldots}                                  3   
11                15          {\ldots}                                  4   
12                16          {\ldots}                                  4   
13                18          {\ldots}                                  3   
14                19          {\ldots}                                  2   
15                20          {\ldots}                                  3   
16                21          {\ldots}                                  4   
17                22          {\ldots}                                  2   
18                23          {\ldots}                                  3   
19                24          {\ldots}                                  3   
20                26          {\ldots}                                  4   
21                27          {\ldots}                                  2   
22                28          {\ldots}                                  3   
23                30          {\ldots}                                  4   
24                31          {\ldots}                                  3   
25                32          {\ldots}                                  4   
26                33          {\ldots}                                  2   
27                35          {\ldots}                                  4   
28                36          {\ldots}                                  4   
29                38          {\ldots}                                  4   
{\ldots}              {\ldots}          {\ldots}                                {\ldots}   
1440            2025          {\ldots}                                  2   
1441            2026          {\ldots}                                  1   
1442            2027          {\ldots}                                  2   
1443            2031          {\ldots}                                  1   
1444            2032          {\ldots}                                  4   
1445            2034          {\ldots}                                  3   
1446            2035          {\ldots}                                  4   
1447            2036          {\ldots}                                  1   
1448            2037          {\ldots}                                  3   
1449            2038          {\ldots}                                  4   
1450            2040          {\ldots}                                  3   
1451            2041          {\ldots}                                  3   
1452            2044          {\ldots}                                  4   
1453            2045          {\ldots}                                  1   
1454            2046          {\ldots}                                  3   
1455            2048          {\ldots}                                  4   
1456            2049          {\ldots}                                  4   
1457            2051          {\ldots}                                  2   
1458            2052          {\ldots}                                  4   
1459            2053          {\ldots}                                  1   
1460            2054          {\ldots}                                  2   
1461            2055          {\ldots}                                  2   
1462            2056          {\ldots}                                  1   
1463            2057          {\ldots}                                  2   
1464            2060          {\ldots}                                  4   
1465            2061          {\ldots}                                  3   
1466            2062          {\ldots}                                  1   
1467            2064          {\ldots}                                  2   
1468            2065          {\ldots}                                  4   
1469            2068          {\ldots}                                  1   

     StandardHours  StockOptionLevel  TotalWorkingYears  \textbackslash{}
0               80                 0                  8   
1               80                 1                 10   
2               80                 0                  7   
3               80                 0                  8   
4               80                 1                  6   
5               80                 0                  8   
6               80                 3                 12   
7               80                 1                  1   
8               80                 0                 10   
9               80                 2                 17   
10              80                 1                  6   
11              80                 0                 10   
12              80                 1                  5   
13              80                 1                  3   
14              80                 0                  6   
15              80                 1                 10   
16              80                 2                  7   
17              80                 2                  1   
18              80                 0                 31   
19              80                 0                  6   
20              80                 1                  5   
21              80                 0                 10   
22              80                 0                 13   
23              80                 0                  0   
24              80                 0                  8   
25              80                 1                 26   
26              80                 0                 10   
27              80                 1                 10   
28              80                 1                 24   
29              80                 0                 22   
{\ldots}            {\ldots}               {\ldots}                {\ldots}   
1440            80                 3                 18   
1441            80                 1                 13   
1442            80                 3                  4   
1443            80                 0                 24   
1444            80                 1                 14   
1445            80                 1                 21   
1446            80                 2                  8   
1447            80                 1                 15   
1448            80                 1                 14   
1449            80                 0                  4   
1450            80                 0                  9   
1451            80                 1                 10   
1452            80                 2                 12   
1453            80                 1                  8   
1454            80                 0                  8   
1455            80                 0                  8   
1456            80                 2                 10   
1457            80                 3                 20   
1458            80                 1                  4   
1459            80                 1                 10   
1460            80                 0                  5   
1461            80                 1                 20   
1462            80                 1                 21   
1463            80                 0                 10   
1464            80                 0                  5   
1465            80                 1                 17   
1466            80                 1                  9   
1467            80                 1                  6   
1468            80                 0                 17   
1469            80                 0                  6   

      TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \textbackslash{}
0                         0               1               6   
1                         3               3              10   
2                         3               3               0   
3                         3               3               8   
4                         3               3               2   
5                         2               2               7   
6                         3               2               1   
7                         2               3               1   
8                         2               3               9   
9                         3               2               7   
10                        5               3               5   
11                        3               3               9   
12                        1               2               5   
13                        2               3               2   
14                        4               3               4   
15                        1               3              10   
16                        5               2               6   
17                        2               2               1   
18                        3               3              25   
19                        3               3               3   
20                        5               2               4   
21                        4               3               5   
22                        4               3              12   
23                        6               3               0   
24                        2               3               4   
25                        3               2              14   
26                        5               3              10   
27                        2               3               9   
28                        4               3              22   
29                        2               2               2   
{\ldots}                     {\ldots}             {\ldots}             {\ldots}   
1440                      3               3               4   
1441                      2               2              13   
1442                      3               4               2   
1443                      2               2              22   
1444                      4               1              10   
1445                      3               3              20   
1446                      2               3               8   
1447                      4               2              15   
1448                      5               3               5   
1449                      4               3               4   
1450                      2               3               9   
1451                      1               3              10   
1452                      3               3               6   
1453                      2               2               6   
1454                      3               3               5   
1455                      2               3               2   
1456                      2               4              10   
1457                      2               3               5   
1458                      5               3               4   
1459                      2               3               4   
1460                      3               1               5   
1461                      3               3               3   
1462                      2               2              20   
1463                      2               3               9   
1464                      2               3               4   
1465                      3               3               5   
1466                      5               3               7   
1467                      0               3               6   
1468                      3               2               9   
1469                      3               4               4   

     YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  
0                     4                        0                     5  
1                     7                        1                     7  
2                     0                        0                     0  
3                     7                        3                     0  
4                     2                        2                     2  
5                     7                        3                     6  
6                     0                        0                     0  
7                     0                        0                     0  
8                     7                        1                     8  
9                     7                        7                     7  
10                    4                        0                     3  
11                    5                        0                     8  
12                    2                        4                     3  
13                    2                        1                     2  
14                    2                        0                     3  
15                    9                        8                     8  
16                    2                        0                     5  
17                    0                        0                     0  
18                    8                        3                     7  
19                    2                        1                     2  
20                    2                        1                     3  
21                    3                        0                     3  
22                    6                        2                    11  
23                    0                        0                     0  
24                    2                        1                     3  
25                   13                        4                     8  
26                    2                        6                     7  
27                    7                        4                     2  
28                    6                        5                    17  
29                    2                        2                     1  
{\ldots}                 {\ldots}                      {\ldots}                   {\ldots}  
1440                  2                        0                     2  
1441                 12                        1                     9  
1442                  2                        2                     2  
1443                  6                        4                    14  
1444                  9                        9                     8  
1445                  7                        0                    10  
1446                  7                        1                     7  
1447                 12                       11                    11  
1448                  4                        0                     4  
1449                  2                        1                     2  
1450                  0                        1                     7  
1451                  7                        1                     9  
1452                  3                        0                     1  
1453                  3                        0                     0  
1454                  3                        0                     1  
1455                  2                        2                     2  
1456                  2                        0                     2  
1457                  3                        0                     2  
1458                  3                        1                     1  
1459                  3                        0                     3  
1460                  4                        0                     4  
1461                  2                        2                     0  
1462                  9                        9                     6  
1463                  4                        1                     7  
1464                  2                        0                     0  
1465                  2                        0                     3  
1466                  7                        1                     7  
1467                  2                        0                     3  
1468                  6                        0                     8  
1469                  3                        1                     2  

[1470 rows x 35 columns]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
         \PY{k+kn}{import} \PY{n+nn}{findspark}
         \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k+kn}{import} \PY{n+nn}{pyspark}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
         \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{basics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{n}{dataset} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{c+c1}{\PYZsh{} The show method allows you visualise DataFrames. We can see that there are two columns. }
         \PY{n}{dataset}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} You could also try this. }
         \PY{n}{dataset}\PY{o}{.}\PY{n}{columns}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+--------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+--------------------+-------------+----------------+-----------------+--------------------+---------------+--------------+------------------+--------------------+--------------------+
|\_c0|      \_c1|              \_c2|      \_c3|                 \_c4|             \_c5|      \_c6|           \_c7|          \_c8|           \_c9|                \_c10|  \_c11|      \_c12|          \_c13|    \_c14|                \_c15|           \_c16|         \_c17|         \_c18|       \_c19|              \_c20|  \_c21|    \_c22|             \_c23|             \_c24|                \_c25|         \_c26|            \_c27|             \_c28|                \_c29|           \_c30|          \_c31|              \_c32|                \_c33|                \_c34|
+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+--------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+--------------------+-------------+----------------+-----------------+--------------------+---------------+--------------+------------------+--------------------+--------------------+
|Age|Attrition|   BusinessTravel|DailyRate|          Department|DistanceFromHome|Education|EducationField|EmployeeCount|EmployeeNumber|EnvironmentSatisf{\ldots}|Gender|HourlyRate|JobInvolvement|JobLevel|             JobRole|JobSatisfaction|MaritalStatus|MonthlyIncome|MonthlyRate|NumCompaniesWorked|Over18|OverTime|PercentSalaryHike|PerformanceRating|RelationshipSatis{\ldots}|StandardHours|StockOptionLevel|TotalWorkingYears|TrainingTimesLast{\ldots}|WorkLifeBalance|YearsAtCompany|YearsInCurrentRole|YearsSinceLastPro{\ldots}|YearsWithCurrManager|
| 41|      Yes|    Travel\_Rarely|     1102|               Sales|               1|        2| Life Sciences|            1|             1|                   2|Female|        94|             3|       2|     Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                   1|           80|               0|                8|                   0|              1|             6|                 4|                   0|                   5|
| 49|       No|Travel\_Frequently|      279|Research \& Develo{\ldots}|               8|        1| Life Sciences|            1|             2|                   3|  Male|        61|             2|       2|  Research Scientist|              2|      Married|         5130|      24907|                 1|     Y|      No|               23|                4|                   4|           80|               1|               10|                   3|              3|            10|                 7|                   1|                   7|
| 37|      Yes|    Travel\_Rarely|     1373|Research \& Develo{\ldots}|               2|        2|         Other|            1|             4|                   4|  Male|        92|             2|       1|Laboratory Techni{\ldots}|              3|       Single|         2090|       2396|                 6|     Y|     Yes|               15|                3|                   2|           80|               0|                7|                   3|              3|             0|                 0|                   0|                   0|
| 33|       No|Travel\_Frequently|     1392|Research \& Develo{\ldots}|               3|        4| Life Sciences|            1|             5|                   4|Female|        56|             3|       1|  Research Scientist|              3|      Married|         2909|      23159|                 1|     Y|     Yes|               11|                3|                   3|           80|               0|                8|                   3|              3|             8|                 7|                   3|                   0|
| 27|       No|    Travel\_Rarely|      591|Research \& Develo{\ldots}|               2|        1|       Medical|            1|             7|                   1|  Male|        40|             3|       1|Laboratory Techni{\ldots}|              2|      Married|         3468|      16632|                 9|     Y|      No|               12|                3|                   4|           80|               1|                6|                   3|              3|             2|                 2|                   2|                   2|
| 32|       No|Travel\_Frequently|     1005|Research \& Develo{\ldots}|               2|        2| Life Sciences|            1|             8|                   4|  Male|        79|             3|       1|Laboratory Techni{\ldots}|              4|       Single|         3068|      11864|                 0|     Y|      No|               13|                3|                   3|           80|               0|                8|                   2|              2|             7|                 7|                   3|                   6|
| 59|       No|    Travel\_Rarely|     1324|Research \& Develo{\ldots}|               3|        3|       Medical|            1|            10|                   3|Female|        81|             4|       1|Laboratory Techni{\ldots}|              1|      Married|         2670|       9964|                 4|     Y|     Yes|               20|                4|                   1|           80|               3|               12|                   3|              2|             1|                 0|                   0|                   0|
| 30|       No|    Travel\_Rarely|     1358|Research \& Develo{\ldots}|              24|        1| Life Sciences|            1|            11|                   4|  Male|        67|             3|       1|Laboratory Techni{\ldots}|              3|     Divorced|         2693|      13335|                 1|     Y|      No|               22|                4|                   2|           80|               1|                1|                   2|              3|             1|                 0|                   0|                   0|
| 38|       No|Travel\_Frequently|      216|Research \& Develo{\ldots}|              23|        3| Life Sciences|            1|            12|                   4|  Male|        44|             2|       3|Manufacturing Dir{\ldots}|              3|       Single|         9526|       8787|                 0|     Y|      No|               21|                4|                   2|           80|               0|               10|                   2|              3|             9|                 7|                   1|                   8|
| 36|       No|    Travel\_Rarely|     1299|Research \& Develo{\ldots}|              27|        3|       Medical|            1|            13|                   3|  Male|        94|             3|       2|Healthcare Repres{\ldots}|              3|      Married|         5237|      16577|                 6|     Y|      No|               13|                3|                   2|           80|               2|               17|                   3|              2|             7|                 7|                   7|                   7|
| 35|       No|    Travel\_Rarely|      809|Research \& Develo{\ldots}|              16|        3|       Medical|            1|            14|                   1|  Male|        84|             4|       1|Laboratory Techni{\ldots}|              2|      Married|         2426|      16479|                 0|     Y|      No|               13|                3|                   3|           80|               1|                6|                   5|              3|             5|                 4|                   0|                   3|
| 29|       No|    Travel\_Rarely|      153|Research \& Develo{\ldots}|              15|        2| Life Sciences|            1|            15|                   4|Female|        49|             2|       2|Laboratory Techni{\ldots}|              3|       Single|         4193|      12682|                 0|     Y|     Yes|               12|                3|                   4|           80|               0|               10|                   3|              3|             9|                 5|                   0|                   8|
| 31|       No|    Travel\_Rarely|      670|Research \& Develo{\ldots}|              26|        1| Life Sciences|            1|            16|                   1|  Male|        31|             3|       1|  Research Scientist|              3|     Divorced|         2911|      15170|                 1|     Y|      No|               17|                3|                   4|           80|               1|                5|                   1|              2|             5|                 2|                   4|                   3|
| 34|       No|    Travel\_Rarely|     1346|Research \& Develo{\ldots}|              19|        2|       Medical|            1|            18|                   2|  Male|        93|             3|       1|Laboratory Techni{\ldots}|              4|     Divorced|         2661|       8758|                 0|     Y|      No|               11|                3|                   3|           80|               1|                3|                   2|              3|             2|                 2|                   1|                   2|
| 28|      Yes|    Travel\_Rarely|      103|Research \& Develo{\ldots}|              24|        3| Life Sciences|            1|            19|                   3|  Male|        50|             2|       1|Laboratory Techni{\ldots}|              3|       Single|         2028|      12947|                 5|     Y|     Yes|               14|                3|                   2|           80|               0|                6|                   4|              3|             4|                 2|                   0|                   3|
| 29|       No|    Travel\_Rarely|     1389|Research \& Develo{\ldots}|              21|        4| Life Sciences|            1|            20|                   2|Female|        51|             4|       3|Manufacturing Dir{\ldots}|              1|     Divorced|         9980|      10195|                 1|     Y|      No|               11|                3|                   3|           80|               1|               10|                   1|              3|            10|                 9|                   8|                   8|
| 32|       No|    Travel\_Rarely|      334|Research \& Develo{\ldots}|               5|        2| Life Sciences|            1|            21|                   1|  Male|        80|             4|       1|  Research Scientist|              2|     Divorced|         3298|      15053|                 0|     Y|     Yes|               12|                3|                   4|           80|               2|                7|                   5|              2|             6|                 2|                   0|                   5|
| 22|       No|       Non-Travel|     1123|Research \& Develo{\ldots}|              16|        2|       Medical|            1|            22|                   4|  Male|        96|             4|       1|Laboratory Techni{\ldots}|              4|     Divorced|         2935|       7324|                 1|     Y|     Yes|               13|                3|                   2|           80|               2|                1|                   2|              2|             1|                 0|                   0|                   0|
| 53|       No|    Travel\_Rarely|     1219|               Sales|               2|        4| Life Sciences|            1|            23|                   1|Female|        78|             2|       4|             Manager|              4|      Married|        15427|      22021|                 2|     Y|      No|               16|                3|                   3|           80|               0|               31|                   3|              3|            25|                 8|                   3|                   7|
+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+--------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+--------------------+-------------+----------------+-----------------+--------------------+---------------+--------------+------------------+--------------------+--------------------+
only showing top 20 rows


    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}19}]:} ['\_c0',
          '\_c1',
          '\_c2',
          '\_c3',
          '\_c4',
          '\_c5',
          '\_c6',
          '\_c7',
          '\_c8',
          '\_c9',
          '\_c10',
          '\_c11',
          '\_c12',
          '\_c13',
          '\_c14',
          '\_c15',
          '\_c16',
          '\_c17',
          '\_c18',
          '\_c19',
          '\_c20',
          '\_c21',
          '\_c22',
          '\_c23',
          '\_c24',
          '\_c25',
          '\_c26',
          '\_c27',
          '\_c28',
          '\_c29',
          '\_c30',
          '\_c31',
          '\_c32',
          '\_c33',
          '\_c34']
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{c+c1}{\PYZsh{} We can use the describe method get some general statistics on our data too. Remember to show the DataFrame!}
         \PY{c+c1}{\PYZsh{} But what about data type?}
         \PY{n}{dataset}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
+-------+------------------+---------+--------------+------------------+----------+----------------+------------------+----------------+-------------+-----------------+--------------------+------+------------------+------------------+------------------+--------------------+------------------+--------+-----------------+------------------+------------------+------+----+------------------+-------------------+--------------------+-------------+------------------+------------------+--------------------+------------------+------------------+------------------+--------------------+--------------------+
|summary|               \_c0|      \_c1|           \_c2|               \_c3|       \_c4|             \_c5|               \_c6|             \_c7|          \_c8|              \_c9|                \_c10|  \_c11|              \_c12|              \_c13|              \_c14|                \_c15|              \_c16|    \_c17|             \_c18|              \_c19|              \_c20|  \_c21|\_c22|              \_c23|               \_c24|                \_c25|         \_c26|              \_c27|              \_c28|                \_c29|              \_c30|              \_c31|              \_c32|                \_c33|                \_c34|
+-------+------------------+---------+--------------+------------------+----------+----------------+------------------+----------------+-------------+-----------------+--------------------+------+------------------+------------------+------------------+--------------------+------------------+--------+-----------------+------------------+------------------+------+----+------------------+-------------------+--------------------+-------------+------------------+------------------+--------------------+------------------+------------------+------------------+--------------------+--------------------+
|  count|              1471|     1471|          1471|              1471|      1471|            1471|              1471|            1471|         1471|             1471|                1471|  1471|              1471|              1471|              1471|                1471|              1471|    1471|             1471|              1471|              1471|  1471|1471|              1471|               1471|                1471|         1471|              1471|              1471|                1471|              1471|              1471|              1471|                1471|                1471|
|   mean|36.923809523809524|     null|          null| 802.4857142857143|      null|9.19251700680272| 2.912925170068027|            null|          1.0|1024.865306122449|   2.721768707482993|  null| 65.89115646258503|2.7299319727891156|2.0639455782312925|                null|2.7285714285714286|    null|6502.931292517007|14313.103401360544|2.6931972789115646|  null|null|15.209523809523809| 3.1537414965986397|  2.7122448979591836|         80.0|0.7938775510204081|11.279591836734694|  2.7993197278911564|2.7612244897959184|7.0081632653061225| 4.229251700680272|  2.1877551020408164|    4.12312925170068|
| stddev| 9.135373489136729|     null|          null|403.50909994352804|      null|8.10686443566608|1.0241649445978718|            null|          0.0|602.0243348474752|  1.0930822146350003|  null|20.329427593996176|0.7115611429632297|1.1069398989351202|                null|1.1028461230547213|    null|4707.956783097992| 7117.786044059972|2.4980090060707463|  null|null|3.6599377165396385|0.36082352460434397|  1.0812088864403517|          0.0|0.8520766679308381| 7.780781675514995|  1.2892706207958466|0.7064758297141507| 6.126525152403571| 3.623137034670627|  3.2224302791379693|  3.5681361205404363|
|    min|                18|Attrition|BusinessTravel|              1001|Department|               1|                 1|  EducationField|            1|                1|                   1|Female|               100|                 1|                 1|Healthcare Repres{\ldots}|                 1|Divorced|            10008|             10007|                 0|Over18|  No|                11|                  3|                   1|           80|                 0|                 0|                   0|                 1|                 0|                 0|                   0|                   0|
|    max|               Age|      Yes| Travel\_Rarely|         DailyRate|     Sales|DistanceFromHome|         Education|Technical Degree|EmployeeCount|   EmployeeNumber|EnvironmentSatisf{\ldots}|  Male|        HourlyRate|    JobInvolvement|          JobLevel|Sales Representative|   JobSatisfaction|  Single|    MonthlyIncome|       MonthlyRate|NumCompaniesWorked|     Y| Yes| PercentSalaryHike|  PerformanceRating|RelationshipSatis{\ldots}|StandardHours|  StockOptionLevel| TotalWorkingYears|TrainingTimesLast{\ldots}|   WorkLifeBalance|    YearsAtCompany|YearsInCurrentRole|YearsSinceLastPro{\ldots}|YearsWithCurrManager|
+-------+------------------+---------+--------------+------------------+----------+----------------+------------------+----------------+-------------+-----------------+--------------------+------+------------------+------------------+------------------+--------------------+------------------+--------+-----------------+------------------+------------------+------+----+------------------+-------------------+--------------------+-------------+------------------+------------------+--------------------+------------------+------------------+------------------+--------------------+--------------------+


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
         \PY{n}{dataset}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{n}{n}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}22}]:} [Row(\_c0='Age', \_c1='Attrition', \_c2='BusinessTravel', \_c3='DailyRate', \_c4='Department', \_c5='DistanceFromHome', \_c6='Education', \_c7='EducationField', \_c8='EmployeeCount', \_c9='EmployeeNumber', \_c10='EnvironmentSatisfaction', \_c11='Gender', \_c12='HourlyRate', \_c13='JobInvolvement', \_c14='JobLevel', \_c15='JobRole', \_c16='JobSatisfaction', \_c17='MaritalStatus', \_c18='MonthlyIncome', \_c19='MonthlyRate', \_c20='NumCompaniesWorked', \_c21='Over18', \_c22='OverTime', \_c23='PercentSalaryHike', \_c24='PerformanceRating', \_c25='RelationshipSatisfaction', \_c26='StandardHours', \_c27='StockOptionLevel', \_c28='TotalWorkingYears', \_c29='TrainingTimesLastYear', \_c30='WorkLifeBalance', \_c31='YearsAtCompany', \_c32='YearsInCurrentRole', \_c33='YearsSinceLastPromotion', \_c34='YearsWithCurrManager'),
          Row(\_c0='41', \_c1='Yes', \_c2='Travel\_Rarely', \_c3='1102', \_c4='Sales', \_c5='1', \_c6='2', \_c7='Life Sciences', \_c8='1', \_c9='1', \_c10='2', \_c11='Female', \_c12='94', \_c13='3', \_c14='2', \_c15='Sales Executive', \_c16='4', \_c17='Single', \_c18='5993', \_c19='19479', \_c20='8', \_c21='Y', \_c22='Yes', \_c23='11', \_c24='3', \_c25='1', \_c26='80', \_c27='0', \_c28='8', \_c29='0', \_c30='1', \_c31='6', \_c32='4', \_c33='0', \_c34='5')]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s import in the relevant types.}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql}\PY{n+nn}{.}\PY{n+nn}{types} \PY{k}{import} \PY{p}{(}\PY{n}{StructField}\PY{p}{,}\PY{n}{StringType}\PY{p}{,}\PY{n}{IntegerType}\PY{p}{,}\PY{n}{StructType}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{c+c1}{\PYZsh{} Then create a variable with the correct structure.}
         \PY{n}{data\PYZus{}schema} \PY{o}{=} \PY{p}{[}\PY{n}{StructField}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{IntegerType}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{k+kc}{True}\PY{p}{)}\PY{p}{,}
                       \PY{n}{StructField}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{StringType}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{k+kc}{True}\PY{p}{)}\PY{p}{]}
         
         \PY{n}{final\PYZus{}struct} \PY{o}{=} \PY{n}{StructType}\PY{p}{(}\PY{n}{fields}\PY{o}{=}\PY{n}{data\PYZus{}schema}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{c+c1}{\PYZsh{} And now we can read in the data using that schema. If we print the schema, we can see that age is now an integer. }
         \PY{n}{dataset} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{schema}\PY{o}{=}\PY{n}{final\PYZus{}struct}\PY{p}{)}
         
         \PY{n}{dataset}\PY{o}{.}\PY{n}{printSchema}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
root
 |-- Attrition: integer (nullable = true)
 |-- MonthlyIncome: string (nullable = true)


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{c+c1}{\PYZsh{} We can also select various columns from a DataFrame. }
         \PY{n}{dataset}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} We could split up these steps, first assigning the output to a variable, then showing that variable. As you see, the output is the same.}
         \PY{n}{MonthlyIncomeColumn} \PY{o}{=} \PY{n}{dataset}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{MonthlyIncomeColumn}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
+-------------+
|MonthlyIncome|
+-------------+
|    Attrition|
|          Yes|
|           No|
|          Yes|
|           No|
|           No|
|           No|
|           No|
|           No|
|           No|
|           No|
|           No|
|           No|
|           No|
|           No|
|          Yes|
|           No|
|           No|
|           No|
|           No|
+-------------+
only showing top 20 rows

+-------------+
|MonthlyIncome|
+-------------+
|    Attrition|
|          Yes|
|           No|
|          Yes|
|           No|
|           No|
|           No|
|           No|
|           No|
|           No|
|           No|
|           No|
|           No|
|           No|
|           No|
|          Yes|
|           No|
|           No|
|           No|
|           No|
+-------------+
only showing top 20 rows


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}33}]:} \PY{c+c1}{\PYZsh{} We can also add columns, manipulating the DataFrame.}
         
         \PY{n}{dataset}\PY{o}{.}\PY{n}{withColumn}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{*}\PY{l+m+mi}{2}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} But note that this doesn\PYZsq{}t alter the original DataFrame. You need to assign the output to a new variable in order to do so.}
         \PY{n}{dataset}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
+---------+-------------+
|Attrition|MonthlyIncome|
+---------+-------------+
|     null|    Attrition|
|     null|          Yes|
|     null|           No|
|     null|          Yes|
|     null|           No|
|     null|           No|
|     null|           No|
|     null|           No|
|     null|           No|
|     null|           No|
|     null|           No|
|     null|           No|
|     null|           No|
|     null|           No|
|     null|           No|
|     null|          Yes|
|     null|           No|
|     null|           No|
|     null|           No|
|     null|           No|
+---------+-------------+
only showing top 20 rows


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        Py4JJavaError                             Traceback (most recent call last)

        <ipython-input-33-b025a9d7e6c2> in <module>()
          4 
          5 \# But note that this doesn't alter the original DataFrame. You need to assign the output to a new variable in order to do so.
    ----> 6 dataset.show()
    

        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py in show(self, n, truncate)
        316         """
        317         if isinstance(truncate, bool) and truncate:
    --> 318             print(self.\_jdf.showString(n, 20))
        319         else:
        320             print(self.\_jdf.showString(n, int(truncate)))


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java\_gateway.py in \_\_call\_\_(self, *args)
       1131         answer = self.gateway\_client.send\_command(command)
       1132         return\_value = get\_return\_value(
    -> 1133             answer, self.gateway\_client, self.target\_id, self.name)
       1134 
       1135         for temp\_arg in temp\_args:


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw)
         61     def deco(*a, **kw):
         62         try:
    ---> 63             return f(*a, **kw)
         64         except py4j.protocol.Py4JJavaError as e:
         65             s = e.java\_exception.toString()


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get\_return\_value(answer, gateway\_client, target\_id, name)
        317                 raise Py4JJavaError(
        318                     "An error occurred while calling \{0\}\{1\}\{2\}.\textbackslash{}n".
    --> 319                     format(target\_id, ".", name), value)
        320             else:
        321                 raise Py4JError(


        Py4JJavaError: An error occurred while calling o154.showString.
    : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 17.0 failed 1 times, most recent failure: Lost task 0.0 in stage 17.0 (TID 17, localhost, executor driver): java.lang.NumberFormatException: For input string: "Age"
    	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
    	at java.lang.Integer.parseInt(Integer.java:580)
    	at java.lang.Integer.parseInt(Integer.java:615)
    	at scala.collection.immutable.StringLike\$class.toInt(StringLike.scala:272)
    	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
    	at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast\$.castTo(CSVInferSchema.scala:252)
    	at org.apache.spark.sql.execution.datasources.csv.CSVRelation\$\$anonfun\$csvParser\$3.apply(CSVRelation.scala:125)
    	at org.apache.spark.sql.execution.datasources.csv.CSVRelation\$\$anonfun\$csvParser\$3.apply(CSVRelation.scala:94)
    	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\$\$anonfun\$buildReader\$1\$\$anonfun\$apply\$2.apply(CSVFileFormat.scala:167)
    	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\$\$anonfun\$buildReader\$1\$\$anonfun\$apply\$2.apply(CSVFileFormat.scala:166)
    	at scala.collection.Iterator\$\$anon\$12.nextCur(Iterator.scala:434)
    	at scala.collection.Iterator\$\$anon\$12.hasNext(Iterator.scala:440)
    	at scala.collection.Iterator\$\$anon\$11.hasNext(Iterator.scala:408)
    	at org.apache.spark.sql.execution.datasources.FileScanRDD\$\$anon\$1.hasNext(FileScanRDD.scala:109)
    	at org.apache.spark.sql.execution.datasources.FileScanRDD\$\$anon\$1.nextIterator(FileScanRDD.scala:184)
    	at org.apache.spark.sql.execution.datasources.FileScanRDD\$\$anon\$1.hasNext(FileScanRDD.scala:109)
    	at org.apache.spark.sql.catalyst.expressions.GeneratedClass\$GeneratedIterator.processNext(Unknown Source)
    	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
    	at org.apache.spark.sql.execution.WholeStageCodegenExec\$\$anonfun\$8\$\$anon\$1.hasNext(WholeStageCodegenExec.scala:377)
    	at org.apache.spark.sql.execution.SparkPlan\$\$anonfun\$2.apply(SparkPlan.scala:231)
    	at org.apache.spark.sql.execution.SparkPlan\$\$anonfun\$2.apply(SparkPlan.scala:225)
    	at org.apache.spark.rdd.RDD\$\$anonfun\$mapPartitionsInternal\$1\$\$anonfun\$apply\$25.apply(RDD.scala:827)
    	at org.apache.spark.rdd.RDD\$\$anonfun\$mapPartitionsInternal\$1\$\$anonfun\$apply\$25.apply(RDD.scala:827)
    	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
    	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
    	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
    	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
    	at org.apache.spark.scheduler.Task.run(Task.scala:99)
    	at org.apache.spark.executor.Executor\$TaskRunner.run(Executor.scala:322)
    	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    	at java.util.concurrent.ThreadPoolExecutor\$Worker.run(ThreadPoolExecutor.java:624)
    	at java.lang.Thread.run(Thread.java:748)
    
    Driver stacktrace:
    	at org.apache.spark.scheduler.DAGScheduler.org\$apache\$spark\$scheduler\$DAGScheduler\$\$failJobAndIndependentStages(DAGScheduler.scala:1435)
    	at org.apache.spark.scheduler.DAGScheduler\$\$anonfun\$abortStage\$1.apply(DAGScheduler.scala:1423)
    	at org.apache.spark.scheduler.DAGScheduler\$\$anonfun\$abortStage\$1.apply(DAGScheduler.scala:1422)
    	at scala.collection.mutable.ResizableArray\$class.foreach(ResizableArray.scala:59)
    	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
    	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)
    	at org.apache.spark.scheduler.DAGScheduler\$\$anonfun\$handleTaskSetFailed\$1.apply(DAGScheduler.scala:802)
    	at org.apache.spark.scheduler.DAGScheduler\$\$anonfun\$handleTaskSetFailed\$1.apply(DAGScheduler.scala:802)
    	at scala.Option.foreach(Option.scala:257)
    	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)
    	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)
    	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
    	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
    	at org.apache.spark.util.EventLoop\$\$anon\$1.run(EventLoop.scala:48)
    	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
    	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1925)
    	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1938)
    	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951)
    	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:333)
    	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)
    	at org.apache.spark.sql.Dataset\$\$anonfun\$org\$apache\$spark\$sql\$Dataset\$\$execute\$1\$1.apply(Dataset.scala:2386)
    	at org.apache.spark.sql.execution.SQLExecution\$.withNewExecutionId(SQLExecution.scala:57)
    	at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2788)
    	at org.apache.spark.sql.Dataset.org\$apache\$spark\$sql\$Dataset\$\$execute\$1(Dataset.scala:2385)
    	at org.apache.spark.sql.Dataset.org\$apache\$spark\$sql\$Dataset\$\$collect(Dataset.scala:2392)
    	at org.apache.spark.sql.Dataset\$\$anonfun\$head\$1.apply(Dataset.scala:2128)
    	at org.apache.spark.sql.Dataset\$\$anonfun\$head\$1.apply(Dataset.scala:2127)
    	at org.apache.spark.sql.Dataset.withTypedCallback(Dataset.scala:2818)
    	at org.apache.spark.sql.Dataset.head(Dataset.scala:2127)
    	at org.apache.spark.sql.Dataset.take(Dataset.scala:2342)
    	at org.apache.spark.sql.Dataset.showString(Dataset.scala:248)
    	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.lang.reflect.Method.invoke(Method.java:498)
    	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
    	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
    	at py4j.Gateway.invoke(Gateway.java:280)
    	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
    	at py4j.commands.CallCommand.execute(CallCommand.java:79)
    	at py4j.GatewayConnection.run(GatewayConnection.java:214)
    	at java.lang.Thread.run(Thread.java:748)
    Caused by: java.lang.NumberFormatException: For input string: "Age"
    	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
    	at java.lang.Integer.parseInt(Integer.java:580)
    	at java.lang.Integer.parseInt(Integer.java:615)
    	at scala.collection.immutable.StringLike\$class.toInt(StringLike.scala:272)
    	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
    	at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast\$.castTo(CSVInferSchema.scala:252)
    	at org.apache.spark.sql.execution.datasources.csv.CSVRelation\$\$anonfun\$csvParser\$3.apply(CSVRelation.scala:125)
    	at org.apache.spark.sql.execution.datasources.csv.CSVRelation\$\$anonfun\$csvParser\$3.apply(CSVRelation.scala:94)
    	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\$\$anonfun\$buildReader\$1\$\$anonfun\$apply\$2.apply(CSVFileFormat.scala:167)
    	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\$\$anonfun\$buildReader\$1\$\$anonfun\$apply\$2.apply(CSVFileFormat.scala:166)
    	at scala.collection.Iterator\$\$anon\$12.nextCur(Iterator.scala:434)
    	at scala.collection.Iterator\$\$anon\$12.hasNext(Iterator.scala:440)
    	at scala.collection.Iterator\$\$anon\$11.hasNext(Iterator.scala:408)
    	at org.apache.spark.sql.execution.datasources.FileScanRDD\$\$anon\$1.hasNext(FileScanRDD.scala:109)
    	at org.apache.spark.sql.execution.datasources.FileScanRDD\$\$anon\$1.nextIterator(FileScanRDD.scala:184)
    	at org.apache.spark.sql.execution.datasources.FileScanRDD\$\$anon\$1.hasNext(FileScanRDD.scala:109)
    	at org.apache.spark.sql.catalyst.expressions.GeneratedClass\$GeneratedIterator.processNext(Unknown Source)
    	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
    	at org.apache.spark.sql.execution.WholeStageCodegenExec\$\$anonfun\$8\$\$anon\$1.hasNext(WholeStageCodegenExec.scala:377)
    	at org.apache.spark.sql.execution.SparkPlan\$\$anonfun\$2.apply(SparkPlan.scala:231)
    	at org.apache.spark.sql.execution.SparkPlan\$\$anonfun\$2.apply(SparkPlan.scala:225)
    	at org.apache.spark.rdd.RDD\$\$anonfun\$mapPartitionsInternal\$1\$\$anonfun\$apply\$25.apply(RDD.scala:827)
    	at org.apache.spark.rdd.RDD\$\$anonfun\$mapPartitionsInternal\$1\$\$anonfun\$apply\$25.apply(RDD.scala:827)
    	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
    	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
    	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
    	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
    	at org.apache.spark.scheduler.Task.run(Task.scala:99)
    	at org.apache.spark.executor.Executor\$TaskRunner.run(Executor.scala:322)
    	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    	at java.util.concurrent.ThreadPoolExecutor\$Worker.run(ThreadPoolExecutor.java:624)
    	{\ldots} 1 more


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}35}]:} \PY{c+c1}{\PYZsh{} First, we have to register the DataFrame as a SQL temporary view.}
         \PY{n}{dataset}\PY{o}{.}\PY{n}{createOrReplaceTempView}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} After that, we can use the SQL programming language for queries. }
         \PY{n}{results} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{sql}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SELECT * FROM Attrition}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}45}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
         \PY{k+kn}{import} \PY{n+nn}{findspark}
         \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k+kn}{import} \PY{n+nn}{pyspark}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
         \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{missing}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}49}]:} \PY{c+c1}{\PYZsh{} Importing data which has a header. Schema is automatically configured.}
         \PY{n}{dataset} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Let\PYZsq{}s see the data. You\PYZsq{}ll notice nulls.}
         \PY{n}{dataset}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+
|Age|Attrition|   BusinessTravel|DailyRate|          Department|DistanceFromHome|Education|EducationField|EmployeeCount|EmployeeNumber|EnvironmentSatisfaction|Gender|HourlyRate|JobInvolvement|JobLevel|             JobRole|JobSatisfaction|MaritalStatus|MonthlyIncome|MonthlyRate|NumCompaniesWorked|Over18|OverTime|PercentSalaryHike|PerformanceRating|RelationshipSatisfaction|StandardHours|StockOptionLevel|TotalWorkingYears|TrainingTimesLastYear|WorkLifeBalance|YearsAtCompany|YearsInCurrentRole|YearsSinceLastPromotion|YearsWithCurrManager|
+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+
| 41|      Yes|    Travel\_Rarely|     1102|               Sales|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|     Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|
| 49|       No|Travel\_Frequently|      279|Research \& Develo{\ldots}|               8|        1| Life Sciences|            1|             2|                      3|  Male|        61|             2|       2|  Research Scientist|              2|      Married|         5130|      24907|                 1|     Y|      No|               23|                4|                       4|           80|               1|               10|                    3|              3|            10|                 7|                      1|                   7|
| 37|      Yes|    Travel\_Rarely|     1373|Research \& Develo{\ldots}|               2|        2|         Other|            1|             4|                      4|  Male|        92|             2|       1|Laboratory Techni{\ldots}|              3|       Single|         2090|       2396|                 6|     Y|     Yes|               15|                3|                       2|           80|               0|                7|                    3|              3|             0|                 0|                      0|                   0|
| 33|       No|Travel\_Frequently|     1392|Research \& Develo{\ldots}|               3|        4| Life Sciences|            1|             5|                      4|Female|        56|             3|       1|  Research Scientist|              3|      Married|         2909|      23159|                 1|     Y|     Yes|               11|                3|                       3|           80|               0|                8|                    3|              3|             8|                 7|                      3|                   0|
| 27|       No|    Travel\_Rarely|      591|Research \& Develo{\ldots}|               2|        1|       Medical|            1|             7|                      1|  Male|        40|             3|       1|Laboratory Techni{\ldots}|              2|      Married|         3468|      16632|                 9|     Y|      No|               12|                3|                       4|           80|               1|                6|                    3|              3|             2|                 2|                      2|                   2|
| 32|       No|Travel\_Frequently|     1005|Research \& Develo{\ldots}|               2|        2| Life Sciences|            1|             8|                      4|  Male|        79|             3|       1|Laboratory Techni{\ldots}|              4|       Single|         3068|      11864|                 0|     Y|      No|               13|                3|                       3|           80|               0|                8|                    2|              2|             7|                 7|                      3|                   6|
| 59|       No|    Travel\_Rarely|     1324|Research \& Develo{\ldots}|               3|        3|       Medical|            1|            10|                      3|Female|        81|             4|       1|Laboratory Techni{\ldots}|              1|      Married|         2670|       9964|                 4|     Y|     Yes|               20|                4|                       1|           80|               3|               12|                    3|              2|             1|                 0|                      0|                   0|
| 30|       No|    Travel\_Rarely|     1358|Research \& Develo{\ldots}|              24|        1| Life Sciences|            1|            11|                      4|  Male|        67|             3|       1|Laboratory Techni{\ldots}|              3|     Divorced|         2693|      13335|                 1|     Y|      No|               22|                4|                       2|           80|               1|                1|                    2|              3|             1|                 0|                      0|                   0|
| 38|       No|Travel\_Frequently|      216|Research \& Develo{\ldots}|              23|        3| Life Sciences|            1|            12|                      4|  Male|        44|             2|       3|Manufacturing Dir{\ldots}|              3|       Single|         9526|       8787|                 0|     Y|      No|               21|                4|                       2|           80|               0|               10|                    2|              3|             9|                 7|                      1|                   8|
| 36|       No|    Travel\_Rarely|     1299|Research \& Develo{\ldots}|              27|        3|       Medical|            1|            13|                      3|  Male|        94|             3|       2|Healthcare Repres{\ldots}|              3|      Married|         5237|      16577|                 6|     Y|      No|               13|                3|                       2|           80|               2|               17|                    3|              2|             7|                 7|                      7|                   7|
| 35|       No|    Travel\_Rarely|      809|Research \& Develo{\ldots}|              16|        3|       Medical|            1|            14|                      1|  Male|        84|             4|       1|Laboratory Techni{\ldots}|              2|      Married|         2426|      16479|                 0|     Y|      No|               13|                3|                       3|           80|               1|                6|                    5|              3|             5|                 4|                      0|                   3|
| 29|       No|    Travel\_Rarely|      153|Research \& Develo{\ldots}|              15|        2| Life Sciences|            1|            15|                      4|Female|        49|             2|       2|Laboratory Techni{\ldots}|              3|       Single|         4193|      12682|                 0|     Y|     Yes|               12|                3|                       4|           80|               0|               10|                    3|              3|             9|                 5|                      0|                   8|
| 31|       No|    Travel\_Rarely|      670|Research \& Develo{\ldots}|              26|        1| Life Sciences|            1|            16|                      1|  Male|        31|             3|       1|  Research Scientist|              3|     Divorced|         2911|      15170|                 1|     Y|      No|               17|                3|                       4|           80|               1|                5|                    1|              2|             5|                 2|                      4|                   3|
| 34|       No|    Travel\_Rarely|     1346|Research \& Develo{\ldots}|              19|        2|       Medical|            1|            18|                      2|  Male|        93|             3|       1|Laboratory Techni{\ldots}|              4|     Divorced|         2661|       8758|                 0|     Y|      No|               11|                3|                       3|           80|               1|                3|                    2|              3|             2|                 2|                      1|                   2|
| 28|      Yes|    Travel\_Rarely|      103|Research \& Develo{\ldots}|              24|        3| Life Sciences|            1|            19|                      3|  Male|        50|             2|       1|Laboratory Techni{\ldots}|              3|       Single|         2028|      12947|                 5|     Y|     Yes|               14|                3|                       2|           80|               0|                6|                    4|              3|             4|                 2|                      0|                   3|
| 29|       No|    Travel\_Rarely|     1389|Research \& Develo{\ldots}|              21|        4| Life Sciences|            1|            20|                      2|Female|        51|             4|       3|Manufacturing Dir{\ldots}|              1|     Divorced|         9980|      10195|                 1|     Y|      No|               11|                3|                       3|           80|               1|               10|                    1|              3|            10|                 9|                      8|                   8|
| 32|       No|    Travel\_Rarely|      334|Research \& Develo{\ldots}|               5|        2| Life Sciences|            1|            21|                      1|  Male|        80|             4|       1|  Research Scientist|              2|     Divorced|         3298|      15053|                 0|     Y|     Yes|               12|                3|                       4|           80|               2|                7|                    5|              2|             6|                 2|                      0|                   5|
| 22|       No|       Non-Travel|     1123|Research \& Develo{\ldots}|              16|        2|       Medical|            1|            22|                      4|  Male|        96|             4|       1|Laboratory Techni{\ldots}|              4|     Divorced|         2935|       7324|                 1|     Y|     Yes|               13|                3|                       2|           80|               2|                1|                    2|              2|             1|                 0|                      0|                   0|
| 53|       No|    Travel\_Rarely|     1219|               Sales|               2|        4| Life Sciences|            1|            23|                      1|Female|        78|             2|       4|             Manager|              4|      Married|        15427|      22021|                 2|     Y|      No|               16|                3|                       3|           80|               0|               31|                    3|              3|            25|                 8|                      3|                   7|
| 38|       No|    Travel\_Rarely|      371|Research \& Develo{\ldots}|               2|        3| Life Sciences|            1|            24|                      4|  Male|        45|             3|       1|  Research Scientist|              4|       Single|         3944|       4306|                 5|     Y|     Yes|               11|                3|                       3|           80|               0|                6|                    3|              3|             3|                 2|                      1|                   2|
+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+
only showing top 20 rows


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np} \PY{c+c1}{\PYZsh{} linear algebra}
         \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{delimiter} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}24}]:}       Age Attrition     BusinessTravel  DailyRate              Department  \textbackslash{}
         0      41       Yes      Travel\_Rarely       1102                   Sales   
         1      49        No  Travel\_Frequently        279  Research \& Development   
         2      37       Yes      Travel\_Rarely       1373  Research \& Development   
         3      33        No  Travel\_Frequently       1392  Research \& Development   
         4      27        No      Travel\_Rarely        591  Research \& Development   
         5      32        No  Travel\_Frequently       1005  Research \& Development   
         6      59        No      Travel\_Rarely       1324  Research \& Development   
         7      30        No      Travel\_Rarely       1358  Research \& Development   
         8      38        No  Travel\_Frequently        216  Research \& Development   
         9      36        No      Travel\_Rarely       1299  Research \& Development   
         10     35        No      Travel\_Rarely        809  Research \& Development   
         11     29        No      Travel\_Rarely        153  Research \& Development   
         12     31        No      Travel\_Rarely        670  Research \& Development   
         13     34        No      Travel\_Rarely       1346  Research \& Development   
         14     28       Yes      Travel\_Rarely        103  Research \& Development   
         15     29        No      Travel\_Rarely       1389  Research \& Development   
         16     32        No      Travel\_Rarely        334  Research \& Development   
         17     22        No         Non-Travel       1123  Research \& Development   
         18     53        No      Travel\_Rarely       1219                   Sales   
         19     38        No      Travel\_Rarely        371  Research \& Development   
         20     24        No         Non-Travel        673  Research \& Development   
         21     36       Yes      Travel\_Rarely       1218                   Sales   
         22     34        No      Travel\_Rarely        419  Research \& Development   
         23     21        No      Travel\_Rarely        391  Research \& Development   
         24     34       Yes      Travel\_Rarely        699  Research \& Development   
         25     53        No      Travel\_Rarely       1282  Research \& Development   
         26     32       Yes  Travel\_Frequently       1125  Research \& Development   
         27     42        No      Travel\_Rarely        691                   Sales   
         28     44        No      Travel\_Rarely        477  Research \& Development   
         29     46        No      Travel\_Rarely        705                   Sales   
         {\ldots}   {\ldots}       {\ldots}                {\ldots}        {\ldots}                     {\ldots}   
         1440   36        No  Travel\_Frequently        688  Research \& Development   
         1441   56        No         Non-Travel        667  Research \& Development   
         1442   29       Yes      Travel\_Rarely       1092  Research \& Development   
         1443   42        No      Travel\_Rarely        300  Research \& Development   
         1444   56       Yes      Travel\_Rarely        310  Research \& Development   
         1445   41        No      Travel\_Rarely        582  Research \& Development   
         1446   34        No      Travel\_Rarely        704                   Sales   
         1447   36        No         Non-Travel        301                   Sales   
         1448   41        No      Travel\_Rarely        930                   Sales   
         1449   32        No      Travel\_Rarely        529  Research \& Development   
         1450   35        No      Travel\_Rarely       1146         Human Resources   
         1451   38        No      Travel\_Rarely        345                   Sales   
         1452   50       Yes  Travel\_Frequently        878                   Sales   
         1453   36        No      Travel\_Rarely       1120                   Sales   
         1454   45        No      Travel\_Rarely        374                   Sales   
         1455   40        No      Travel\_Rarely       1322  Research \& Development   
         1456   35        No  Travel\_Frequently       1199  Research \& Development   
         1457   40        No      Travel\_Rarely       1194  Research \& Development   
         1458   35        No      Travel\_Rarely        287  Research \& Development   
         1459   29        No      Travel\_Rarely       1378  Research \& Development   
         1460   29        No      Travel\_Rarely        468  Research \& Development   
         1461   50       Yes      Travel\_Rarely        410                   Sales   
         1462   39        No      Travel\_Rarely        722                   Sales   
         1463   31        No         Non-Travel        325  Research \& Development   
         1464   26        No      Travel\_Rarely       1167                   Sales   
         1465   36        No  Travel\_Frequently        884  Research \& Development   
         1466   39        No      Travel\_Rarely        613  Research \& Development   
         1467   27        No      Travel\_Rarely        155  Research \& Development   
         1468   49        No  Travel\_Frequently       1023                   Sales   
         1469   34        No      Travel\_Rarely        628  Research \& Development   
         
               DistanceFromHome  Education    EducationField  EmployeeCount  \textbackslash{}
         0                    1          2     Life Sciences              1   
         1                    8          1     Life Sciences              1   
         2                    2          2             Other              1   
         3                    3          4     Life Sciences              1   
         4                    2          1           Medical              1   
         5                    2          2     Life Sciences              1   
         6                    3          3           Medical              1   
         7                   24          1     Life Sciences              1   
         8                   23          3     Life Sciences              1   
         9                   27          3           Medical              1   
         10                  16          3           Medical              1   
         11                  15          2     Life Sciences              1   
         12                  26          1     Life Sciences              1   
         13                  19          2           Medical              1   
         14                  24          3     Life Sciences              1   
         15                  21          4     Life Sciences              1   
         16                   5          2     Life Sciences              1   
         17                  16          2           Medical              1   
         18                   2          4     Life Sciences              1   
         19                   2          3     Life Sciences              1   
         20                  11          2             Other              1   
         21                   9          4     Life Sciences              1   
         22                   7          4     Life Sciences              1   
         23                  15          2     Life Sciences              1   
         24                   6          1           Medical              1   
         25                   5          3             Other              1   
         26                  16          1     Life Sciences              1   
         27                   8          4         Marketing              1   
         28                   7          4           Medical              1   
         29                   2          4         Marketing              1   
         {\ldots}                {\ldots}        {\ldots}               {\ldots}            {\ldots}   
         1440                 4          2     Life Sciences              1   
         1441                 1          4     Life Sciences              1   
         1442                 1          4           Medical              1   
         1443                 2          3     Life Sciences              1   
         1444                 7          2  Technical Degree              1   
         1445                28          4     Life Sciences              1   
         1446                28          3         Marketing              1   
         1447                15          4         Marketing              1   
         1448                 3          3     Life Sciences              1   
         1449                 2          3  Technical Degree              1   
         1450                26          4     Life Sciences              1   
         1451                10          2     Life Sciences              1   
         1452                 1          4     Life Sciences              1   
         1453                11          4         Marketing              1   
         1454                20          3     Life Sciences              1   
         1455                 2          4     Life Sciences              1   
         1456                18          4     Life Sciences              1   
         1457                 2          4           Medical              1   
         1458                 1          4     Life Sciences              1   
         1459                13          2             Other              1   
         1460                28          4           Medical              1   
         1461                28          3         Marketing              1   
         1462                24          1         Marketing              1   
         1463                 5          3           Medical              1   
         1464                 5          3             Other              1   
         1465                23          2           Medical              1   
         1466                 6          1           Medical              1   
         1467                 4          3     Life Sciences              1   
         1468                 2          3           Medical              1   
         1469                 8          3           Medical              1   
         
               EmployeeNumber          {\ldots}           RelationshipSatisfaction  \textbackslash{}
         0                  1          {\ldots}                                  1   
         1                  2          {\ldots}                                  4   
         2                  4          {\ldots}                                  2   
         3                  5          {\ldots}                                  3   
         4                  7          {\ldots}                                  4   
         5                  8          {\ldots}                                  3   
         6                 10          {\ldots}                                  1   
         7                 11          {\ldots}                                  2   
         8                 12          {\ldots}                                  2   
         9                 13          {\ldots}                                  2   
         10                14          {\ldots}                                  3   
         11                15          {\ldots}                                  4   
         12                16          {\ldots}                                  4   
         13                18          {\ldots}                                  3   
         14                19          {\ldots}                                  2   
         15                20          {\ldots}                                  3   
         16                21          {\ldots}                                  4   
         17                22          {\ldots}                                  2   
         18                23          {\ldots}                                  3   
         19                24          {\ldots}                                  3   
         20                26          {\ldots}                                  4   
         21                27          {\ldots}                                  2   
         22                28          {\ldots}                                  3   
         23                30          {\ldots}                                  4   
         24                31          {\ldots}                                  3   
         25                32          {\ldots}                                  4   
         26                33          {\ldots}                                  2   
         27                35          {\ldots}                                  4   
         28                36          {\ldots}                                  4   
         29                38          {\ldots}                                  4   
         {\ldots}              {\ldots}          {\ldots}                                {\ldots}   
         1440            2025          {\ldots}                                  2   
         1441            2026          {\ldots}                                  1   
         1442            2027          {\ldots}                                  2   
         1443            2031          {\ldots}                                  1   
         1444            2032          {\ldots}                                  4   
         1445            2034          {\ldots}                                  3   
         1446            2035          {\ldots}                                  4   
         1447            2036          {\ldots}                                  1   
         1448            2037          {\ldots}                                  3   
         1449            2038          {\ldots}                                  4   
         1450            2040          {\ldots}                                  3   
         1451            2041          {\ldots}                                  3   
         1452            2044          {\ldots}                                  4   
         1453            2045          {\ldots}                                  1   
         1454            2046          {\ldots}                                  3   
         1455            2048          {\ldots}                                  4   
         1456            2049          {\ldots}                                  4   
         1457            2051          {\ldots}                                  2   
         1458            2052          {\ldots}                                  4   
         1459            2053          {\ldots}                                  1   
         1460            2054          {\ldots}                                  2   
         1461            2055          {\ldots}                                  2   
         1462            2056          {\ldots}                                  1   
         1463            2057          {\ldots}                                  2   
         1464            2060          {\ldots}                                  4   
         1465            2061          {\ldots}                                  3   
         1466            2062          {\ldots}                                  1   
         1467            2064          {\ldots}                                  2   
         1468            2065          {\ldots}                                  4   
         1469            2068          {\ldots}                                  1   
         
              StandardHours  StockOptionLevel  TotalWorkingYears  \textbackslash{}
         0               80                 0                  8   
         1               80                 1                 10   
         2               80                 0                  7   
         3               80                 0                  8   
         4               80                 1                  6   
         5               80                 0                  8   
         6               80                 3                 12   
         7               80                 1                  1   
         8               80                 0                 10   
         9               80                 2                 17   
         10              80                 1                  6   
         11              80                 0                 10   
         12              80                 1                  5   
         13              80                 1                  3   
         14              80                 0                  6   
         15              80                 1                 10   
         16              80                 2                  7   
         17              80                 2                  1   
         18              80                 0                 31   
         19              80                 0                  6   
         20              80                 1                  5   
         21              80                 0                 10   
         22              80                 0                 13   
         23              80                 0                  0   
         24              80                 0                  8   
         25              80                 1                 26   
         26              80                 0                 10   
         27              80                 1                 10   
         28              80                 1                 24   
         29              80                 0                 22   
         {\ldots}            {\ldots}               {\ldots}                {\ldots}   
         1440            80                 3                 18   
         1441            80                 1                 13   
         1442            80                 3                  4   
         1443            80                 0                 24   
         1444            80                 1                 14   
         1445            80                 1                 21   
         1446            80                 2                  8   
         1447            80                 1                 15   
         1448            80                 1                 14   
         1449            80                 0                  4   
         1450            80                 0                  9   
         1451            80                 1                 10   
         1452            80                 2                 12   
         1453            80                 1                  8   
         1454            80                 0                  8   
         1455            80                 0                  8   
         1456            80                 2                 10   
         1457            80                 3                 20   
         1458            80                 1                  4   
         1459            80                 1                 10   
         1460            80                 0                  5   
         1461            80                 1                 20   
         1462            80                 1                 21   
         1463            80                 0                 10   
         1464            80                 0                  5   
         1465            80                 1                 17   
         1466            80                 1                  9   
         1467            80                 1                  6   
         1468            80                 0                 17   
         1469            80                 0                  6   
         
               TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \textbackslash{}
         0                         0               1               6   
         1                         3               3              10   
         2                         3               3               0   
         3                         3               3               8   
         4                         3               3               2   
         5                         2               2               7   
         6                         3               2               1   
         7                         2               3               1   
         8                         2               3               9   
         9                         3               2               7   
         10                        5               3               5   
         11                        3               3               9   
         12                        1               2               5   
         13                        2               3               2   
         14                        4               3               4   
         15                        1               3              10   
         16                        5               2               6   
         17                        2               2               1   
         18                        3               3              25   
         19                        3               3               3   
         20                        5               2               4   
         21                        4               3               5   
         22                        4               3              12   
         23                        6               3               0   
         24                        2               3               4   
         25                        3               2              14   
         26                        5               3              10   
         27                        2               3               9   
         28                        4               3              22   
         29                        2               2               2   
         {\ldots}                     {\ldots}             {\ldots}             {\ldots}   
         1440                      3               3               4   
         1441                      2               2              13   
         1442                      3               4               2   
         1443                      2               2              22   
         1444                      4               1              10   
         1445                      3               3              20   
         1446                      2               3               8   
         1447                      4               2              15   
         1448                      5               3               5   
         1449                      4               3               4   
         1450                      2               3               9   
         1451                      1               3              10   
         1452                      3               3               6   
         1453                      2               2               6   
         1454                      3               3               5   
         1455                      2               3               2   
         1456                      2               4              10   
         1457                      2               3               5   
         1458                      5               3               4   
         1459                      2               3               4   
         1460                      3               1               5   
         1461                      3               3               3   
         1462                      2               2              20   
         1463                      2               3               9   
         1464                      2               3               4   
         1465                      3               3               5   
         1466                      5               3               7   
         1467                      0               3               6   
         1468                      3               2               9   
         1469                      3               4               4   
         
              YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  
         0                     4                        0                     5  
         1                     7                        1                     7  
         2                     0                        0                     0  
         3                     7                        3                     0  
         4                     2                        2                     2  
         5                     7                        3                     6  
         6                     0                        0                     0  
         7                     0                        0                     0  
         8                     7                        1                     8  
         9                     7                        7                     7  
         10                    4                        0                     3  
         11                    5                        0                     8  
         12                    2                        4                     3  
         13                    2                        1                     2  
         14                    2                        0                     3  
         15                    9                        8                     8  
         16                    2                        0                     5  
         17                    0                        0                     0  
         18                    8                        3                     7  
         19                    2                        1                     2  
         20                    2                        1                     3  
         21                    3                        0                     3  
         22                    6                        2                    11  
         23                    0                        0                     0  
         24                    2                        1                     3  
         25                   13                        4                     8  
         26                    2                        6                     7  
         27                    7                        4                     2  
         28                    6                        5                    17  
         29                    2                        2                     1  
         {\ldots}                 {\ldots}                      {\ldots}                   {\ldots}  
         1440                  2                        0                     2  
         1441                 12                        1                     9  
         1442                  2                        2                     2  
         1443                  6                        4                    14  
         1444                  9                        9                     8  
         1445                  7                        0                    10  
         1446                  7                        1                     7  
         1447                 12                       11                    11  
         1448                  4                        0                     4  
         1449                  2                        1                     2  
         1450                  0                        1                     7  
         1451                  7                        1                     9  
         1452                  3                        0                     1  
         1453                  3                        0                     0  
         1454                  3                        0                     1  
         1455                  2                        2                     2  
         1456                  2                        0                     2  
         1457                  3                        0                     2  
         1458                  3                        1                     1  
         1459                  3                        0                     3  
         1460                  4                        0                     4  
         1461                  2                        2                     0  
         1462                  9                        9                     6  
         1463                  4                        1                     7  
         1464                  2                        0                     0  
         1465                  2                        0                     3  
         1466                  7                        1                     7  
         1467                  2                        0                     3  
         1468                  6                        0                     8  
         1469                  3                        1                     2  
         
         [1470 rows x 35 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{n}{Dataset}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}29}]:}   Attrition
         0       Yes
         1        No
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}31}]:} \PY{n}{Dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}31}]:} count      2
         unique     2
         top       No
         freq       1
         Name: Attrition, dtype: object
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{n}{Dataset} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Yes}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{No}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Percentage calculation}
         \PY{p}{(}\PY{n}{Dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{/}\PY{n}{Dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{count}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}27}]:} No     50.0
         Yes    50.0
         Name: Attrition, dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{n}{Dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}28}]:} No     1
         Yes    1
         Name: Attrition, dtype: int64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{n}{colors\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{}5cb85c}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{}5bc0de}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{}d9534f}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{c+c1}{\PYZsh{} Change this line to plot percentages instead of absolute values}
         \PY{n}{ax} \PY{o}{=} \PY{p}{(}\PY{n}{Dataset}\PY{o}{.}\PY{n}{div}\PY{p}{(}\PY{n}{Dataset}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{kind}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bar}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{,}\PY{n}{width} \PY{o}{=} \PY{l+m+mf}{0.8}\PY{p}{,}\PY{n}{color} \PY{o}{=} \PY{n}{colors\PYZus{}list}\PY{p}{,}\PY{n}{edgecolor}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{labels}\PY{o}{=}\PY{n}{Dataset}\PY{o}{.}\PY{n}{columns}\PY{p}{,}\PY{n}{fontsize}\PY{o}{=} \PY{l+m+mi}{14}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Percentage of Attrition}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{fontsize}\PY{o}{=} \PY{l+m+mi}{16}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{14}\PY{p}{)}
         \PY{k}{for} \PY{n}{spine} \PY{o+ow}{in} \PY{n}{plt}\PY{o}{.}\PY{n}{gca}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{spines}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{n}{spine}\PY{o}{.}\PY{n}{set\PYZus{}visible}\PY{p}{(}\PY{k+kc}{False}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{p}{[}\PY{p}{]}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Add this loop to add the annotations}
         \PY{k}{for} \PY{n}{p} \PY{o+ow}{in} \PY{n}{ax}\PY{o}{.}\PY{n}{patches}\PY{p}{:}
             \PY{n}{width}\PY{p}{,} \PY{n}{height} \PY{o}{=} \PY{n}{p}\PY{o}{.}\PY{n}{get\PYZus{}width}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{p}\PY{o}{.}\PY{n}{get\PYZus{}height}\PY{p}{(}\PY{p}{)}
             \PY{n}{x}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n}{p}\PY{o}{.}\PY{n}{get\PYZus{}xy}\PY{p}{(}\PY{p}{)} 
             \PY{n}{ax}\PY{o}{.}\PY{n}{annotate}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}:.0\PYZpc{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{height}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y} \PY{o}{+} \PY{n}{height} \PY{o}{+} \PY{l+m+mf}{0.01}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_20_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}59}]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
         
         \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
         
         \PY{n}{Dataset} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Yes}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{No}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Percentage of Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Percentage}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{total} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{Dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{k}{for} \PY{n}{p} \PY{o+ow}{in} \PY{n}{ax}\PY{o}{.}\PY{n}{patches}\PY{p}{:}
                 \PY{n}{percentage} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}:.1f\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+m+mi}{100} \PY{o}{*} \PY{n}{p}\PY{o}{.}\PY{n}{get\PYZus{}width}\PY{p}{(}\PY{p}{)}\PY{o}{/}\PY{n}{total}\PY{p}{)}
                 \PY{n}{x} \PY{o}{=} \PY{n}{p}\PY{o}{.}\PY{n}{get\PYZus{}x}\PY{p}{(}\PY{p}{)} \PY{o}{+} \PY{n}{p}\PY{o}{.}\PY{n}{get\PYZus{}width}\PY{p}{(}\PY{p}{)} \PY{o}{+} \PY{l+m+mf}{0.02}
                 \PY{n}{y} \PY{o}{=} \PY{n}{p}\PY{o}{.}\PY{n}{get\PYZus{}y}\PY{p}{(}\PY{p}{)} \PY{o}{+} \PY{n}{p}\PY{o}{.}\PY{n}{get\PYZus{}height}\PY{p}{(}\PY{p}{)}\PY{o}{/}\PY{l+m+mi}{2}
                 \PY{n}{ax}\PY{o}{.}\PY{n}{annotate}\PY{p}{(}\PY{n}{percentage}\PY{p}{,} \PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_21_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         \PY{n}{Dataset}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}39}]:}        Attrition
         count          2
         unique         2
         top           No
         freq           1
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}48}]:} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{delimiter} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}48}]:}       Age Attrition     BusinessTravel  DailyRate              Department  \textbackslash{}
         0      41       Yes      Travel\_Rarely       1102                   Sales   
         1      49        No  Travel\_Frequently        279  Research \& Development   
         2      37       Yes      Travel\_Rarely       1373  Research \& Development   
         3      33        No  Travel\_Frequently       1392  Research \& Development   
         4      27        No      Travel\_Rarely        591  Research \& Development   
         5      32        No  Travel\_Frequently       1005  Research \& Development   
         6      59        No      Travel\_Rarely       1324  Research \& Development   
         7      30        No      Travel\_Rarely       1358  Research \& Development   
         8      38        No  Travel\_Frequently        216  Research \& Development   
         9      36        No      Travel\_Rarely       1299  Research \& Development   
         10     35        No      Travel\_Rarely        809  Research \& Development   
         11     29        No      Travel\_Rarely        153  Research \& Development   
         12     31        No      Travel\_Rarely        670  Research \& Development   
         13     34        No      Travel\_Rarely       1346  Research \& Development   
         14     28       Yes      Travel\_Rarely        103  Research \& Development   
         15     29        No      Travel\_Rarely       1389  Research \& Development   
         16     32        No      Travel\_Rarely        334  Research \& Development   
         17     22        No         Non-Travel       1123  Research \& Development   
         18     53        No      Travel\_Rarely       1219                   Sales   
         19     38        No      Travel\_Rarely        371  Research \& Development   
         20     24        No         Non-Travel        673  Research \& Development   
         21     36       Yes      Travel\_Rarely       1218                   Sales   
         22     34        No      Travel\_Rarely        419  Research \& Development   
         23     21        No      Travel\_Rarely        391  Research \& Development   
         24     34       Yes      Travel\_Rarely        699  Research \& Development   
         25     53        No      Travel\_Rarely       1282  Research \& Development   
         26     32       Yes  Travel\_Frequently       1125  Research \& Development   
         27     42        No      Travel\_Rarely        691                   Sales   
         28     44        No      Travel\_Rarely        477  Research \& Development   
         29     46        No      Travel\_Rarely        705                   Sales   
         {\ldots}   {\ldots}       {\ldots}                {\ldots}        {\ldots}                     {\ldots}   
         1440   36        No  Travel\_Frequently        688  Research \& Development   
         1441   56        No         Non-Travel        667  Research \& Development   
         1442   29       Yes      Travel\_Rarely       1092  Research \& Development   
         1443   42        No      Travel\_Rarely        300  Research \& Development   
         1444   56       Yes      Travel\_Rarely        310  Research \& Development   
         1445   41        No      Travel\_Rarely        582  Research \& Development   
         1446   34        No      Travel\_Rarely        704                   Sales   
         1447   36        No         Non-Travel        301                   Sales   
         1448   41        No      Travel\_Rarely        930                   Sales   
         1449   32        No      Travel\_Rarely        529  Research \& Development   
         1450   35        No      Travel\_Rarely       1146         Human Resources   
         1451   38        No      Travel\_Rarely        345                   Sales   
         1452   50       Yes  Travel\_Frequently        878                   Sales   
         1453   36        No      Travel\_Rarely       1120                   Sales   
         1454   45        No      Travel\_Rarely        374                   Sales   
         1455   40        No      Travel\_Rarely       1322  Research \& Development   
         1456   35        No  Travel\_Frequently       1199  Research \& Development   
         1457   40        No      Travel\_Rarely       1194  Research \& Development   
         1458   35        No      Travel\_Rarely        287  Research \& Development   
         1459   29        No      Travel\_Rarely       1378  Research \& Development   
         1460   29        No      Travel\_Rarely        468  Research \& Development   
         1461   50       Yes      Travel\_Rarely        410                   Sales   
         1462   39        No      Travel\_Rarely        722                   Sales   
         1463   31        No         Non-Travel        325  Research \& Development   
         1464   26        No      Travel\_Rarely       1167                   Sales   
         1465   36        No  Travel\_Frequently        884  Research \& Development   
         1466   39        No      Travel\_Rarely        613  Research \& Development   
         1467   27        No      Travel\_Rarely        155  Research \& Development   
         1468   49        No  Travel\_Frequently       1023                   Sales   
         1469   34        No      Travel\_Rarely        628  Research \& Development   
         
               DistanceFromHome  Education    EducationField  EmployeeCount  \textbackslash{}
         0                    1          2     Life Sciences              1   
         1                    8          1     Life Sciences              1   
         2                    2          2             Other              1   
         3                    3          4     Life Sciences              1   
         4                    2          1           Medical              1   
         5                    2          2     Life Sciences              1   
         6                    3          3           Medical              1   
         7                   24          1     Life Sciences              1   
         8                   23          3     Life Sciences              1   
         9                   27          3           Medical              1   
         10                  16          3           Medical              1   
         11                  15          2     Life Sciences              1   
         12                  26          1     Life Sciences              1   
         13                  19          2           Medical              1   
         14                  24          3     Life Sciences              1   
         15                  21          4     Life Sciences              1   
         16                   5          2     Life Sciences              1   
         17                  16          2           Medical              1   
         18                   2          4     Life Sciences              1   
         19                   2          3     Life Sciences              1   
         20                  11          2             Other              1   
         21                   9          4     Life Sciences              1   
         22                   7          4     Life Sciences              1   
         23                  15          2     Life Sciences              1   
         24                   6          1           Medical              1   
         25                   5          3             Other              1   
         26                  16          1     Life Sciences              1   
         27                   8          4         Marketing              1   
         28                   7          4           Medical              1   
         29                   2          4         Marketing              1   
         {\ldots}                {\ldots}        {\ldots}               {\ldots}            {\ldots}   
         1440                 4          2     Life Sciences              1   
         1441                 1          4     Life Sciences              1   
         1442                 1          4           Medical              1   
         1443                 2          3     Life Sciences              1   
         1444                 7          2  Technical Degree              1   
         1445                28          4     Life Sciences              1   
         1446                28          3         Marketing              1   
         1447                15          4         Marketing              1   
         1448                 3          3     Life Sciences              1   
         1449                 2          3  Technical Degree              1   
         1450                26          4     Life Sciences              1   
         1451                10          2     Life Sciences              1   
         1452                 1          4     Life Sciences              1   
         1453                11          4         Marketing              1   
         1454                20          3     Life Sciences              1   
         1455                 2          4     Life Sciences              1   
         1456                18          4     Life Sciences              1   
         1457                 2          4           Medical              1   
         1458                 1          4     Life Sciences              1   
         1459                13          2             Other              1   
         1460                28          4           Medical              1   
         1461                28          3         Marketing              1   
         1462                24          1         Marketing              1   
         1463                 5          3           Medical              1   
         1464                 5          3             Other              1   
         1465                23          2           Medical              1   
         1466                 6          1           Medical              1   
         1467                 4          3     Life Sciences              1   
         1468                 2          3           Medical              1   
         1469                 8          3           Medical              1   
         
               EmployeeNumber          {\ldots}           RelationshipSatisfaction  \textbackslash{}
         0                  1          {\ldots}                                  1   
         1                  2          {\ldots}                                  4   
         2                  4          {\ldots}                                  2   
         3                  5          {\ldots}                                  3   
         4                  7          {\ldots}                                  4   
         5                  8          {\ldots}                                  3   
         6                 10          {\ldots}                                  1   
         7                 11          {\ldots}                                  2   
         8                 12          {\ldots}                                  2   
         9                 13          {\ldots}                                  2   
         10                14          {\ldots}                                  3   
         11                15          {\ldots}                                  4   
         12                16          {\ldots}                                  4   
         13                18          {\ldots}                                  3   
         14                19          {\ldots}                                  2   
         15                20          {\ldots}                                  3   
         16                21          {\ldots}                                  4   
         17                22          {\ldots}                                  2   
         18                23          {\ldots}                                  3   
         19                24          {\ldots}                                  3   
         20                26          {\ldots}                                  4   
         21                27          {\ldots}                                  2   
         22                28          {\ldots}                                  3   
         23                30          {\ldots}                                  4   
         24                31          {\ldots}                                  3   
         25                32          {\ldots}                                  4   
         26                33          {\ldots}                                  2   
         27                35          {\ldots}                                  4   
         28                36          {\ldots}                                  4   
         29                38          {\ldots}                                  4   
         {\ldots}              {\ldots}          {\ldots}                                {\ldots}   
         1440            2025          {\ldots}                                  2   
         1441            2026          {\ldots}                                  1   
         1442            2027          {\ldots}                                  2   
         1443            2031          {\ldots}                                  1   
         1444            2032          {\ldots}                                  4   
         1445            2034          {\ldots}                                  3   
         1446            2035          {\ldots}                                  4   
         1447            2036          {\ldots}                                  1   
         1448            2037          {\ldots}                                  3   
         1449            2038          {\ldots}                                  4   
         1450            2040          {\ldots}                                  3   
         1451            2041          {\ldots}                                  3   
         1452            2044          {\ldots}                                  4   
         1453            2045          {\ldots}                                  1   
         1454            2046          {\ldots}                                  3   
         1455            2048          {\ldots}                                  4   
         1456            2049          {\ldots}                                  4   
         1457            2051          {\ldots}                                  2   
         1458            2052          {\ldots}                                  4   
         1459            2053          {\ldots}                                  1   
         1460            2054          {\ldots}                                  2   
         1461            2055          {\ldots}                                  2   
         1462            2056          {\ldots}                                  1   
         1463            2057          {\ldots}                                  2   
         1464            2060          {\ldots}                                  4   
         1465            2061          {\ldots}                                  3   
         1466            2062          {\ldots}                                  1   
         1467            2064          {\ldots}                                  2   
         1468            2065          {\ldots}                                  4   
         1469            2068          {\ldots}                                  1   
         
              StandardHours  StockOptionLevel  TotalWorkingYears  \textbackslash{}
         0               80                 0                  8   
         1               80                 1                 10   
         2               80                 0                  7   
         3               80                 0                  8   
         4               80                 1                  6   
         5               80                 0                  8   
         6               80                 3                 12   
         7               80                 1                  1   
         8               80                 0                 10   
         9               80                 2                 17   
         10              80                 1                  6   
         11              80                 0                 10   
         12              80                 1                  5   
         13              80                 1                  3   
         14              80                 0                  6   
         15              80                 1                 10   
         16              80                 2                  7   
         17              80                 2                  1   
         18              80                 0                 31   
         19              80                 0                  6   
         20              80                 1                  5   
         21              80                 0                 10   
         22              80                 0                 13   
         23              80                 0                  0   
         24              80                 0                  8   
         25              80                 1                 26   
         26              80                 0                 10   
         27              80                 1                 10   
         28              80                 1                 24   
         29              80                 0                 22   
         {\ldots}            {\ldots}               {\ldots}                {\ldots}   
         1440            80                 3                 18   
         1441            80                 1                 13   
         1442            80                 3                  4   
         1443            80                 0                 24   
         1444            80                 1                 14   
         1445            80                 1                 21   
         1446            80                 2                  8   
         1447            80                 1                 15   
         1448            80                 1                 14   
         1449            80                 0                  4   
         1450            80                 0                  9   
         1451            80                 1                 10   
         1452            80                 2                 12   
         1453            80                 1                  8   
         1454            80                 0                  8   
         1455            80                 0                  8   
         1456            80                 2                 10   
         1457            80                 3                 20   
         1458            80                 1                  4   
         1459            80                 1                 10   
         1460            80                 0                  5   
         1461            80                 1                 20   
         1462            80                 1                 21   
         1463            80                 0                 10   
         1464            80                 0                  5   
         1465            80                 1                 17   
         1466            80                 1                  9   
         1467            80                 1                  6   
         1468            80                 0                 17   
         1469            80                 0                  6   
         
               TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \textbackslash{}
         0                         0               1               6   
         1                         3               3              10   
         2                         3               3               0   
         3                         3               3               8   
         4                         3               3               2   
         5                         2               2               7   
         6                         3               2               1   
         7                         2               3               1   
         8                         2               3               9   
         9                         3               2               7   
         10                        5               3               5   
         11                        3               3               9   
         12                        1               2               5   
         13                        2               3               2   
         14                        4               3               4   
         15                        1               3              10   
         16                        5               2               6   
         17                        2               2               1   
         18                        3               3              25   
         19                        3               3               3   
         20                        5               2               4   
         21                        4               3               5   
         22                        4               3              12   
         23                        6               3               0   
         24                        2               3               4   
         25                        3               2              14   
         26                        5               3              10   
         27                        2               3               9   
         28                        4               3              22   
         29                        2               2               2   
         {\ldots}                     {\ldots}             {\ldots}             {\ldots}   
         1440                      3               3               4   
         1441                      2               2              13   
         1442                      3               4               2   
         1443                      2               2              22   
         1444                      4               1              10   
         1445                      3               3              20   
         1446                      2               3               8   
         1447                      4               2              15   
         1448                      5               3               5   
         1449                      4               3               4   
         1450                      2               3               9   
         1451                      1               3              10   
         1452                      3               3               6   
         1453                      2               2               6   
         1454                      3               3               5   
         1455                      2               3               2   
         1456                      2               4              10   
         1457                      2               3               5   
         1458                      5               3               4   
         1459                      2               3               4   
         1460                      3               1               5   
         1461                      3               3               3   
         1462                      2               2              20   
         1463                      2               3               9   
         1464                      2               3               4   
         1465                      3               3               5   
         1466                      5               3               7   
         1467                      0               3               6   
         1468                      3               2               9   
         1469                      3               4               4   
         
              YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  
         0                     4                        0                     5  
         1                     7                        1                     7  
         2                     0                        0                     0  
         3                     7                        3                     0  
         4                     2                        2                     2  
         5                     7                        3                     6  
         6                     0                        0                     0  
         7                     0                        0                     0  
         8                     7                        1                     8  
         9                     7                        7                     7  
         10                    4                        0                     3  
         11                    5                        0                     8  
         12                    2                        4                     3  
         13                    2                        1                     2  
         14                    2                        0                     3  
         15                    9                        8                     8  
         16                    2                        0                     5  
         17                    0                        0                     0  
         18                    8                        3                     7  
         19                    2                        1                     2  
         20                    2                        1                     3  
         21                    3                        0                     3  
         22                    6                        2                    11  
         23                    0                        0                     0  
         24                    2                        1                     3  
         25                   13                        4                     8  
         26                    2                        6                     7  
         27                    7                        4                     2  
         28                    6                        5                    17  
         29                    2                        2                     1  
         {\ldots}                 {\ldots}                      {\ldots}                   {\ldots}  
         1440                  2                        0                     2  
         1441                 12                        1                     9  
         1442                  2                        2                     2  
         1443                  6                        4                    14  
         1444                  9                        9                     8  
         1445                  7                        0                    10  
         1446                  7                        1                     7  
         1447                 12                       11                    11  
         1448                  4                        0                     4  
         1449                  2                        1                     2  
         1450                  0                        1                     7  
         1451                  7                        1                     9  
         1452                  3                        0                     1  
         1453                  3                        0                     0  
         1454                  3                        0                     1  
         1455                  2                        2                     2  
         1456                  2                        0                     2  
         1457                  3                        0                     2  
         1458                  3                        1                     1  
         1459                  3                        0                     3  
         1460                  4                        0                     4  
         1461                  2                        2                     0  
         1462                  9                        9                     6  
         1463                  4                        1                     7  
         1464                  2                        0                     0  
         1465                  2                        0                     3  
         1466                  7                        1                     7  
         1467                  2                        0                     3  
         1468                  6                        0                     8  
         1469                  3                        1                     2  
         
         [1470 rows x 35 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}66}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}66}]:} DataFrame[summary: string, \_c0: string, \_c1: string, \_c2: string, \_c3: string, \_c4: string, \_c5: string, \_c6: string, \_c7: string, \_c8: string, \_c9: string, \_c10: string, \_c11: string, \_c12: string, \_c13: string, \_c14: string, \_c15: string, \_c16: string, \_c17: string, \_c18: string, \_c19: string, \_c20: string, \_c21: string, \_c22: string, \_c23: string, \_c24: string, \_c25: string, \_c26: string, \_c27: string, \_c28: string, \_c29: string, \_c30: string, \_c31: string, \_c32: string, \_c33: string, \_c34: string]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}64}]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         \PY{n}{purchase\PYZus{}plot} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}
         \PY{n}{purchase\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Attrition }\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{purchase\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Attrition}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{purchase\PYZus{}plot}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MonthlyIncome}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        Py4JJavaError                             Traceback (most recent call last)

        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw)
         62         try:
    ---> 63             return f(*a, **kw)
         64         except py4j.protocol.Py4JJavaError as e:


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get\_return\_value(answer, gateway\_client, target\_id, name)
        318                     "An error occurred while calling \{0\}\{1\}\{2\}.\textbackslash{}n".
    --> 319                     format(target\_id, ".", name), value)
        320             else:


        Py4JJavaError: An error occurred while calling o28.apply.
    : org.apache.spark.sql.AnalysisException: Cannot resolve column name "MonthlyIncome" among (\_c0, \_c1, \_c2, \_c3, \_c4, \_c5, \_c6, \_c7, \_c8, \_c9, \_c10, \_c11, \_c12, \_c13, \_c14, \_c15, \_c16, \_c17, \_c18, \_c19, \_c20, \_c21, \_c22, \_c23, \_c24, \_c25, \_c26, \_c27, \_c28, \_c29, \_c30, \_c31, \_c32, \_c33, \_c34);
    	at org.apache.spark.sql.Dataset\$\$anonfun\$resolve\$1.apply(Dataset.scala:219)
    	at org.apache.spark.sql.Dataset\$\$anonfun\$resolve\$1.apply(Dataset.scala:219)
    	at scala.Option.getOrElse(Option.scala:121)
    	at org.apache.spark.sql.Dataset.resolve(Dataset.scala:218)
    	at org.apache.spark.sql.Dataset.col(Dataset.scala:1083)
    	at org.apache.spark.sql.Dataset.apply(Dataset.scala:1069)
    	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.lang.reflect.Method.invoke(Method.java:498)
    	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
    	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
    	at py4j.Gateway.invoke(Gateway.java:280)
    	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
    	at py4j.commands.CallCommand.execute(CallCommand.java:79)
    	at py4j.GatewayConnection.run(GatewayConnection.java:214)
    	at java.lang.Thread.run(Thread.java:748)


        
    During handling of the above exception, another exception occurred:


        AnalysisException                         Traceback (most recent call last)

        <ipython-input-64-3dd45f20ffa5> in <module>()
          1 import matplotlib.pyplot as plt
          2 import numpy as np
    ----> 3 purchase\_plot = dataset['MonthlyIncome'].hist(bins=20)
          4 purchase\_plot.set\_title("Attrition \%")
          5 purchase\_plot.set\_xlabel("Attrition")


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py in \_\_getitem\_\_(self, item)
        950         """
        951         if isinstance(item, basestring):
    --> 952             jc = self.\_jdf.apply(item)
        953             return Column(jc)
        954         elif isinstance(item, Column):


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java\_gateway.py in \_\_call\_\_(self, *args)
       1131         answer = self.gateway\_client.send\_command(command)
       1132         return\_value = get\_return\_value(
    -> 1133             answer, self.gateway\_client, self.target\_id, self.name)
       1134 
       1135         for temp\_arg in temp\_args:


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw)
         67                                              e.java\_exception.getStackTrace()))
         68             if s.startswith('org.apache.spark.sql.AnalysisException: '):
    ---> 69                 raise AnalysisException(s.split(': ', 1)[1], stackTrace)
         70             if s.startswith('org.apache.spark.sql.catalyst.analysis'):
         71                 raise AnalysisException(s.split(': ', 1)[1], stackTrace)


        AnalysisException: 'Cannot resolve column name "MonthlyIncome" among (\_c0, \_c1, \_c2, \_c3, \_c4, \_c5, \_c6, \_c7, \_c8, \_c9, \_c10, \_c11, \_c12, \_c13, \_c14, \_c15, \_c16, \_c17, \_c18, \_c19, \_c20, \_c21, \_c22, \_c23, \_c24, \_c25, \_c26, \_c27, \_c28, \_c29, \_c30, \_c31, \_c32, \_c33, \_c34);'

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}67}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
         \PY{k+kn}{import} \PY{n+nn}{findspark}
         \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k+kn}{import} \PY{n+nn}{pyspark}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
         \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{basics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}69}]:} \PY{n}{df} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}73}]:} \PY{n}{df}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
         \PY{n}{df}\PY{o}{.}\PY{n}{columns}
         \PY{n}{df}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
         \PY{n}{df}\PY{o}{.}\PY{n}{printSchema}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+--------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+--------------------+-------------+----------------+-----------------+--------------------+---------------+--------------+------------------+--------------------+--------------------+
|\_c0|      \_c1|              \_c2|      \_c3|                 \_c4|             \_c5|      \_c6|           \_c7|          \_c8|           \_c9|                \_c10|  \_c11|      \_c12|          \_c13|    \_c14|                \_c15|           \_c16|         \_c17|         \_c18|       \_c19|              \_c20|  \_c21|    \_c22|             \_c23|             \_c24|                \_c25|         \_c26|            \_c27|             \_c28|                \_c29|           \_c30|          \_c31|              \_c32|                \_c33|                \_c34|
+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+--------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+--------------------+-------------+----------------+-----------------+--------------------+---------------+--------------+------------------+--------------------+--------------------+
|Age|Attrition|   BusinessTravel|DailyRate|          Department|DistanceFromHome|Education|EducationField|EmployeeCount|EmployeeNumber|EnvironmentSatisf{\ldots}|Gender|HourlyRate|JobInvolvement|JobLevel|             JobRole|JobSatisfaction|MaritalStatus|MonthlyIncome|MonthlyRate|NumCompaniesWorked|Over18|OverTime|PercentSalaryHike|PerformanceRating|RelationshipSatis{\ldots}|StandardHours|StockOptionLevel|TotalWorkingYears|TrainingTimesLast{\ldots}|WorkLifeBalance|YearsAtCompany|YearsInCurrentRole|YearsSinceLastPro{\ldots}|YearsWithCurrManager|
| 41|      Yes|    Travel\_Rarely|     1102|               Sales|               1|        2| Life Sciences|            1|             1|                   2|Female|        94|             3|       2|     Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                   1|           80|               0|                8|                   0|              1|             6|                 4|                   0|                   5|
| 49|       No|Travel\_Frequently|      279|Research \& Develo{\ldots}|               8|        1| Life Sciences|            1|             2|                   3|  Male|        61|             2|       2|  Research Scientist|              2|      Married|         5130|      24907|                 1|     Y|      No|               23|                4|                   4|           80|               1|               10|                   3|              3|            10|                 7|                   1|                   7|
| 37|      Yes|    Travel\_Rarely|     1373|Research \& Develo{\ldots}|               2|        2|         Other|            1|             4|                   4|  Male|        92|             2|       1|Laboratory Techni{\ldots}|              3|       Single|         2090|       2396|                 6|     Y|     Yes|               15|                3|                   2|           80|               0|                7|                   3|              3|             0|                 0|                   0|                   0|
| 33|       No|Travel\_Frequently|     1392|Research \& Develo{\ldots}|               3|        4| Life Sciences|            1|             5|                   4|Female|        56|             3|       1|  Research Scientist|              3|      Married|         2909|      23159|                 1|     Y|     Yes|               11|                3|                   3|           80|               0|                8|                   3|              3|             8|                 7|                   3|                   0|
| 27|       No|    Travel\_Rarely|      591|Research \& Develo{\ldots}|               2|        1|       Medical|            1|             7|                   1|  Male|        40|             3|       1|Laboratory Techni{\ldots}|              2|      Married|         3468|      16632|                 9|     Y|      No|               12|                3|                   4|           80|               1|                6|                   3|              3|             2|                 2|                   2|                   2|
| 32|       No|Travel\_Frequently|     1005|Research \& Develo{\ldots}|               2|        2| Life Sciences|            1|             8|                   4|  Male|        79|             3|       1|Laboratory Techni{\ldots}|              4|       Single|         3068|      11864|                 0|     Y|      No|               13|                3|                   3|           80|               0|                8|                   2|              2|             7|                 7|                   3|                   6|
| 59|       No|    Travel\_Rarely|     1324|Research \& Develo{\ldots}|               3|        3|       Medical|            1|            10|                   3|Female|        81|             4|       1|Laboratory Techni{\ldots}|              1|      Married|         2670|       9964|                 4|     Y|     Yes|               20|                4|                   1|           80|               3|               12|                   3|              2|             1|                 0|                   0|                   0|
| 30|       No|    Travel\_Rarely|     1358|Research \& Develo{\ldots}|              24|        1| Life Sciences|            1|            11|                   4|  Male|        67|             3|       1|Laboratory Techni{\ldots}|              3|     Divorced|         2693|      13335|                 1|     Y|      No|               22|                4|                   2|           80|               1|                1|                   2|              3|             1|                 0|                   0|                   0|
| 38|       No|Travel\_Frequently|      216|Research \& Develo{\ldots}|              23|        3| Life Sciences|            1|            12|                   4|  Male|        44|             2|       3|Manufacturing Dir{\ldots}|              3|       Single|         9526|       8787|                 0|     Y|      No|               21|                4|                   2|           80|               0|               10|                   2|              3|             9|                 7|                   1|                   8|
| 36|       No|    Travel\_Rarely|     1299|Research \& Develo{\ldots}|              27|        3|       Medical|            1|            13|                   3|  Male|        94|             3|       2|Healthcare Repres{\ldots}|              3|      Married|         5237|      16577|                 6|     Y|      No|               13|                3|                   2|           80|               2|               17|                   3|              2|             7|                 7|                   7|                   7|
| 35|       No|    Travel\_Rarely|      809|Research \& Develo{\ldots}|              16|        3|       Medical|            1|            14|                   1|  Male|        84|             4|       1|Laboratory Techni{\ldots}|              2|      Married|         2426|      16479|                 0|     Y|      No|               13|                3|                   3|           80|               1|                6|                   5|              3|             5|                 4|                   0|                   3|
| 29|       No|    Travel\_Rarely|      153|Research \& Develo{\ldots}|              15|        2| Life Sciences|            1|            15|                   4|Female|        49|             2|       2|Laboratory Techni{\ldots}|              3|       Single|         4193|      12682|                 0|     Y|     Yes|               12|                3|                   4|           80|               0|               10|                   3|              3|             9|                 5|                   0|                   8|
| 31|       No|    Travel\_Rarely|      670|Research \& Develo{\ldots}|              26|        1| Life Sciences|            1|            16|                   1|  Male|        31|             3|       1|  Research Scientist|              3|     Divorced|         2911|      15170|                 1|     Y|      No|               17|                3|                   4|           80|               1|                5|                   1|              2|             5|                 2|                   4|                   3|
| 34|       No|    Travel\_Rarely|     1346|Research \& Develo{\ldots}|              19|        2|       Medical|            1|            18|                   2|  Male|        93|             3|       1|Laboratory Techni{\ldots}|              4|     Divorced|         2661|       8758|                 0|     Y|      No|               11|                3|                   3|           80|               1|                3|                   2|              3|             2|                 2|                   1|                   2|
| 28|      Yes|    Travel\_Rarely|      103|Research \& Develo{\ldots}|              24|        3| Life Sciences|            1|            19|                   3|  Male|        50|             2|       1|Laboratory Techni{\ldots}|              3|       Single|         2028|      12947|                 5|     Y|     Yes|               14|                3|                   2|           80|               0|                6|                   4|              3|             4|                 2|                   0|                   3|
| 29|       No|    Travel\_Rarely|     1389|Research \& Develo{\ldots}|              21|        4| Life Sciences|            1|            20|                   2|Female|        51|             4|       3|Manufacturing Dir{\ldots}|              1|     Divorced|         9980|      10195|                 1|     Y|      No|               11|                3|                   3|           80|               1|               10|                   1|              3|            10|                 9|                   8|                   8|
| 32|       No|    Travel\_Rarely|      334|Research \& Develo{\ldots}|               5|        2| Life Sciences|            1|            21|                   1|  Male|        80|             4|       1|  Research Scientist|              2|     Divorced|         3298|      15053|                 0|     Y|     Yes|               12|                3|                   4|           80|               2|                7|                   5|              2|             6|                 2|                   0|                   5|
| 22|       No|       Non-Travel|     1123|Research \& Develo{\ldots}|              16|        2|       Medical|            1|            22|                   4|  Male|        96|             4|       1|Laboratory Techni{\ldots}|              4|     Divorced|         2935|       7324|                 1|     Y|     Yes|               13|                3|                   2|           80|               2|                1|                   2|              2|             1|                 0|                   0|                   0|
| 53|       No|    Travel\_Rarely|     1219|               Sales|               2|        4| Life Sciences|            1|            23|                   1|Female|        78|             2|       4|             Manager|              4|      Married|        15427|      22021|                 2|     Y|      No|               16|                3|                   3|           80|               0|               31|                   3|              3|            25|                 8|                   3|                   7|
+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+--------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+--------------------+-------------+----------------+-----------------+--------------------+---------------+--------------+------------------+--------------------+--------------------+
only showing top 20 rows

+-------+------------------+---------+--------------+------------------+----------+----------------+------------------+----------------+-------------+-----------------+--------------------+------+------------------+------------------+------------------+--------------------+------------------+--------+-----------------+------------------+------------------+------+----+------------------+-------------------+--------------------+-------------+------------------+------------------+--------------------+------------------+------------------+------------------+--------------------+--------------------+
|summary|               \_c0|      \_c1|           \_c2|               \_c3|       \_c4|             \_c5|               \_c6|             \_c7|          \_c8|              \_c9|                \_c10|  \_c11|              \_c12|              \_c13|              \_c14|                \_c15|              \_c16|    \_c17|             \_c18|              \_c19|              \_c20|  \_c21|\_c22|              \_c23|               \_c24|                \_c25|         \_c26|              \_c27|              \_c28|                \_c29|              \_c30|              \_c31|              \_c32|                \_c33|                \_c34|
+-------+------------------+---------+--------------+------------------+----------+----------------+------------------+----------------+-------------+-----------------+--------------------+------+------------------+------------------+------------------+--------------------+------------------+--------+-----------------+------------------+------------------+------+----+------------------+-------------------+--------------------+-------------+------------------+------------------+--------------------+------------------+------------------+------------------+--------------------+--------------------+
|  count|              1471|     1471|          1471|              1471|      1471|            1471|              1471|            1471|         1471|             1471|                1471|  1471|              1471|              1471|              1471|                1471|              1471|    1471|             1471|              1471|              1471|  1471|1471|              1471|               1471|                1471|         1471|              1471|              1471|                1471|              1471|              1471|              1471|                1471|                1471|
|   mean|36.923809523809524|     null|          null| 802.4857142857143|      null|9.19251700680272| 2.912925170068027|            null|          1.0|1024.865306122449|   2.721768707482993|  null| 65.89115646258503|2.7299319727891156|2.0639455782312925|                null|2.7285714285714286|    null|6502.931292517007|14313.103401360544|2.6931972789115646|  null|null|15.209523809523809| 3.1537414965986397|  2.7122448979591836|         80.0|0.7938775510204081|11.279591836734694|  2.7993197278911564|2.7612244897959184|7.0081632653061225| 4.229251700680272|  2.1877551020408164|    4.12312925170068|
| stddev| 9.135373489136729|     null|          null|403.50909994352804|      null|8.10686443566608|1.0241649445978718|            null|          0.0|602.0243348474752|  1.0930822146350003|  null|20.329427593996176|0.7115611429632297|1.1069398989351202|                null|1.1028461230547213|    null|4707.956783097992| 7117.786044059972|2.4980090060707463|  null|null|3.6599377165396385|0.36082352460434397|  1.0812088864403517|          0.0|0.8520766679308381| 7.780781675514995|  1.2892706207958466|0.7064758297141507| 6.126525152403571| 3.623137034670627|  3.2224302791379693|  3.5681361205404363|
|    min|                18|Attrition|BusinessTravel|              1001|Department|               1|                 1|  EducationField|            1|                1|                   1|Female|               100|                 1|                 1|Healthcare Repres{\ldots}|                 1|Divorced|            10008|             10007|                 0|Over18|  No|                11|                  3|                   1|           80|                 0|                 0|                   0|                 1|                 0|                 0|                   0|                   0|
|    max|               Age|      Yes| Travel\_Rarely|         DailyRate|     Sales|DistanceFromHome|         Education|Technical Degree|EmployeeCount|   EmployeeNumber|EnvironmentSatisf{\ldots}|  Male|        HourlyRate|    JobInvolvement|          JobLevel|Sales Representative|   JobSatisfaction|  Single|    MonthlyIncome|       MonthlyRate|NumCompaniesWorked|     Y| Yes| PercentSalaryHike|  PerformanceRating|RelationshipSatis{\ldots}|StandardHours|  StockOptionLevel| TotalWorkingYears|TrainingTimesLast{\ldots}|   WorkLifeBalance|    YearsAtCompany|YearsInCurrentRole|YearsSinceLastPro{\ldots}|YearsWithCurrManager|
+-------+------------------+---------+--------------+------------------+----------+----------------+------------------+----------------+-------------+-----------------+--------------------+------+------------------+------------------+------------------+--------------------+------------------+--------+-----------------+------------------+------------------+------+----+------------------+-------------------+--------------------+-------------+------------------+------------------+--------------------+------------------+------------------+------------------+--------------------+--------------------+

root
 |-- \_c0: string (nullable = true)
 |-- \_c1: string (nullable = true)
 |-- \_c2: string (nullable = true)
 |-- \_c3: string (nullable = true)
 |-- \_c4: string (nullable = true)
 |-- \_c5: string (nullable = true)
 |-- \_c6: string (nullable = true)
 |-- \_c7: string (nullable = true)
 |-- \_c8: string (nullable = true)
 |-- \_c9: string (nullable = true)
 |-- \_c10: string (nullable = true)
 |-- \_c11: string (nullable = true)
 |-- \_c12: string (nullable = true)
 |-- \_c13: string (nullable = true)
 |-- \_c14: string (nullable = true)
 |-- \_c15: string (nullable = true)
 |-- \_c16: string (nullable = true)
 |-- \_c17: string (nullable = true)
 |-- \_c18: string (nullable = true)
 |-- \_c19: string (nullable = true)
 |-- \_c20: string (nullable = true)
 |-- \_c21: string (nullable = true)
 |-- \_c22: string (nullable = true)
 |-- \_c23: string (nullable = true)
 |-- \_c24: string (nullable = true)
 |-- \_c25: string (nullable = true)
 |-- \_c26: string (nullable = true)
 |-- \_c27: string (nullable = true)
 |-- \_c28: string (nullable = true)
 |-- \_c29: string (nullable = true)
 |-- \_c30: string (nullable = true)
 |-- \_c31: string (nullable = true)
 |-- \_c32: string (nullable = true)
 |-- \_c33: string (nullable = true)
 |-- \_c34: string (nullable = true)


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}75}]:} \PY{n}{df}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        Py4JJavaError                             Traceback (most recent call last)

        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw)
         62         try:
    ---> 63             return f(*a, **kw)
         64         except py4j.protocol.Py4JJavaError as e:


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get\_return\_value(answer, gateway\_client, target\_id, name)
        318                     "An error occurred while calling \{0\}\{1\}\{2\}.\textbackslash{}n".
    --> 319                     format(target\_id, ".", name), value)
        320             else:


        Py4JJavaError: An error occurred while calling o277.select.
    : org.apache.spark.sql.AnalysisException: cannot resolve '`Attrition`' given input columns: [\_c33, \_c34, \_c7, \_c31, \_c12, \_c10, \_c14, \_c30, \_c24, \_c26, \_c16, \_c2, \_c23, \_c27, \_c13, \_c25, \_c28, \_c1, \_c4, \_c22, \_c11, \_c32, \_c8, \_c9, \_c29, \_c6, \_c18, \_c3, \_c20, \_c17, \_c19, \_c0, \_c21, \_c5, \_c15];;
    'Project ['Attrition]
    +- Relation[\_c0\#5834,\_c1\#5835,\_c2\#5836,\_c3\#5837,\_c4\#5838,\_c5\#5839,\_c6\#5840,\_c7\#5841,\_c8\#5842,\_c9\#5843,\_c10\#5844,\_c11\#5845,\_c12\#5846,\_c13\#5847,\_c14\#5848,\_c15\#5849,\_c16\#5850,\_c17\#5851,\_c18\#5852,\_c19\#5853,\_c20\#5854,\_c21\#5855,\_c22\#5856,\_c23\#5857,{\ldots} 11 more fields] csv
    
    	at org.apache.spark.sql.catalyst.analysis.package\$AnalysisErrorAt.failAnalysis(package.scala:42)
    	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis\$\$anonfun\$checkAnalysis\$1\$\$anonfun\$apply\$2.applyOrElse(CheckAnalysis.scala:86)
    	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis\$\$anonfun\$checkAnalysis\$1\$\$anonfun\$apply\$2.applyOrElse(CheckAnalysis.scala:83)
    	at org.apache.spark.sql.catalyst.trees.TreeNode\$\$anonfun\$transformUp\$1.apply(TreeNode.scala:290)
    	at org.apache.spark.sql.catalyst.trees.TreeNode\$\$anonfun\$transformUp\$1.apply(TreeNode.scala:290)
    	at org.apache.spark.sql.catalyst.trees.CurrentOrigin\$.withOrigin(TreeNode.scala:70)
    	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:289)
    	at org.apache.spark.sql.catalyst.plans.QueryPlan\$\$anonfun\$transformExpressionsUp\$1.apply(QueryPlan.scala:255)
    	at org.apache.spark.sql.catalyst.plans.QueryPlan\$\$anonfun\$transformExpressionsUp\$1.apply(QueryPlan.scala:255)
    	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression\$1(QueryPlan.scala:266)
    	at org.apache.spark.sql.catalyst.plans.QueryPlan.org\$apache\$spark\$sql\$catalyst\$plans\$QueryPlan\$\$recursiveTransform\$1(QueryPlan.scala:276)
    	at org.apache.spark.sql.catalyst.plans.QueryPlan\$\$anonfun\$org\$apache\$spark\$sql\$catalyst\$plans\$QueryPlan\$\$recursiveTransform\$1\$1.apply(QueryPlan.scala:280)
    	at scala.collection.TraversableLike\$\$anonfun\$map\$1.apply(TraversableLike.scala:234)
    	at scala.collection.TraversableLike\$\$anonfun\$map\$1.apply(TraversableLike.scala:234)
    	at scala.collection.mutable.ResizableArray\$class.foreach(ResizableArray.scala:59)
    	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
    	at scala.collection.TraversableLike\$class.map(TraversableLike.scala:234)
    	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
    	at org.apache.spark.sql.catalyst.plans.QueryPlan.org\$apache\$spark\$sql\$catalyst\$plans\$QueryPlan\$\$recursiveTransform\$1(QueryPlan.scala:280)
    	at org.apache.spark.sql.catalyst.plans.QueryPlan\$\$anonfun\$6.apply(QueryPlan.scala:285)
    	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)
    	at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:285)
    	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:255)
    	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis\$\$anonfun\$checkAnalysis\$1.apply(CheckAnalysis.scala:83)
    	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis\$\$anonfun\$checkAnalysis\$1.apply(CheckAnalysis.scala:76)
    	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:128)
    	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis\$class.checkAnalysis(CheckAnalysis.scala:76)
    	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:57)
    	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:52)
    	at org.apache.spark.sql.Dataset\$.ofRows(Dataset.scala:63)
    	at org.apache.spark.sql.Dataset.org\$apache\$spark\$sql\$Dataset\$\$withPlan(Dataset.scala:2845)
    	at org.apache.spark.sql.Dataset.select(Dataset.scala:1131)
    	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.lang.reflect.Method.invoke(Method.java:498)
    	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
    	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
    	at py4j.Gateway.invoke(Gateway.java:280)
    	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
    	at py4j.commands.CallCommand.execute(CallCommand.java:79)
    	at py4j.GatewayConnection.run(GatewayConnection.java:214)
    	at java.lang.Thread.run(Thread.java:748)


        
    During handling of the above exception, another exception occurred:


        AnalysisException                         Traceback (most recent call last)

        <ipython-input-75-61b56090c555> in <module>()
    ----> 1 df.select('Attrition').show()
    

        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py in select(self, *cols)
        991         [Row(name=u'Alice', age=12), Row(name=u'Bob', age=15)]
        992         """
    --> 993         jdf = self.\_jdf.select(self.\_jcols(*cols))
        994         return DataFrame(jdf, self.sql\_ctx)
        995 


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java\_gateway.py in \_\_call\_\_(self, *args)
       1131         answer = self.gateway\_client.send\_command(command)
       1132         return\_value = get\_return\_value(
    -> 1133             answer, self.gateway\_client, self.target\_id, self.name)
       1134 
       1135         for temp\_arg in temp\_args:


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw)
         67                                              e.java\_exception.getStackTrace()))
         68             if s.startswith('org.apache.spark.sql.AnalysisException: '):
    ---> 69                 raise AnalysisException(s.split(': ', 1)[1], stackTrace)
         70             if s.startswith('org.apache.spark.sql.catalyst.analysis'):
         71                 raise AnalysisException(s.split(': ', 1)[1], stackTrace)


        AnalysisException: "cannot resolve '`Attrition`' given input columns: [\_c33, \_c34, \_c7, \_c31, \_c12, \_c10, \_c14, \_c30, \_c24, \_c26, \_c16, \_c2, \_c23, \_c27, \_c13, \_c25, \_c28, \_c1, \_c4, \_c22, \_c11, \_c32, \_c8, \_c9, \_c29, \_c6, \_c18, \_c3, \_c20, \_c17, \_c19, \_c0, \_c21, \_c5, \_c15];;\textbackslash{}n'Project ['Attrition]\textbackslash{}n+- Relation[\_c0\#5834,\_c1\#5835,\_c2\#5836,\_c3\#5837,\_c4\#5838,\_c5\#5839,\_c6\#5840,\_c7\#5841,\_c8\#5842,\_c9\#5843,\_c10\#5844,\_c11\#5845,\_c12\#5846,\_c13\#5847,\_c14\#5848,\_c15\#5849,\_c16\#5850,\_c17\#5851,\_c18\#5852,\_c19\#5853,\_c20\#5854,\_c21\#5855,\_c22\#5856,\_c23\#5857,{\ldots} 11 more fields] csv\textbackslash{}n"

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}76}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
         \PY{k+kn}{import} \PY{n+nn}{findspark}
         \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k+kn}{import} \PY{n+nn}{pyspark}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
         \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{missing}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}80}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}80}]:} Row(Age=41, Attrition='Yes', BusinessTravel='Travel\_Rarely', DailyRate=1102, Department='Sales', DistanceFromHome=1, Education=2, EducationField='Life Sciences', EmployeeCount=1, EmployeeNumber=1, EnvironmentSatisfaction=2, Gender='Female', HourlyRate=94, JobInvolvement=3, JobLevel=2, JobRole='Sales Executive', JobSatisfaction=4, MaritalStatus='Single', MonthlyIncome=5993, MonthlyRate=19479, NumCompaniesWorked=8, Over18='Y', OverTime='Yes', PercentSalaryHike=11, PerformanceRating=3, RelationshipSatisfaction=1, StandardHours=80, StockOptionLevel=0, TotalWorkingYears=8, TrainingTimesLastYear=0, WorkLifeBalance=1, YearsAtCompany=6, YearsInCurrentRole=4, YearsSinceLastPromotion=0, YearsWithCurrManager=5)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}81}]:} \PY{k}{for} \PY{n}{item} \PY{o+ow}{in} \PY{n}{dataset}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{item}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
41
Yes
Travel\_Rarely
1102
Sales
1
2
Life Sciences
1
1
2
Female
94
3
2
Sales Executive
4
Single
5993
19479
8
Y
Yes
11
3
1
80
0
8
0
1
6
4
0
5

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}85}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
         
         \PY{c+c1}{\PYZsh{} Generate data on commute times.}
         \PY{n}{size}\PY{p}{,} \PY{n}{scale} \PY{o}{=} \PY{l+m+mi}{1000}\PY{p}{,} \PY{l+m+mi}{10}
         \PY{n}{commutes} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{gamma}\PY{p}{(}\PY{n}{scale}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{size}\PY{p}{)} \PY{o}{*}\PY{o}{*} \PY{l+m+mf}{1.5}\PY{p}{)}
         
         \PY{n}{commutes}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{grid}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{rwidth}\PY{o}{=}\PY{l+m+mf}{0.9}\PY{p}{,}
                            \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{}607c8e}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Commute Times for 1,000 Commuters}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{grid}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.75}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_33_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}94}]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{rcdefaults}\PY{p}{(}\PY{p}{)}
         \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}96}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{printSchema}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
root
 |-- Age: integer (nullable = true)
 |-- Attrition: string (nullable = true)
 |-- BusinessTravel: string (nullable = true)
 |-- DailyRate: integer (nullable = true)
 |-- Department: string (nullable = true)
 |-- DistanceFromHome: integer (nullable = true)
 |-- Education: integer (nullable = true)
 |-- EducationField: string (nullable = true)
 |-- EmployeeCount: integer (nullable = true)
 |-- EmployeeNumber: integer (nullable = true)
 |-- EnvironmentSatisfaction: integer (nullable = true)
 |-- Gender: string (nullable = true)
 |-- HourlyRate: integer (nullable = true)
 |-- JobInvolvement: integer (nullable = true)
 |-- JobLevel: integer (nullable = true)
 |-- JobRole: string (nullable = true)
 |-- JobSatisfaction: integer (nullable = true)
 |-- MaritalStatus: string (nullable = true)
 |-- MonthlyIncome: integer (nullable = true)
 |-- MonthlyRate: integer (nullable = true)
 |-- NumCompaniesWorked: integer (nullable = true)
 |-- Over18: string (nullable = true)
 |-- OverTime: string (nullable = true)
 |-- PercentSalaryHike: integer (nullable = true)
 |-- PerformanceRating: integer (nullable = true)
 |-- RelationshipSatisfaction: integer (nullable = true)
 |-- StandardHours: integer (nullable = true)
 |-- StockOptionLevel: integer (nullable = true)
 |-- TotalWorkingYears: integer (nullable = true)
 |-- TrainingTimesLastYear: integer (nullable = true)
 |-- WorkLifeBalance: integer (nullable = true)
 |-- YearsAtCompany: integer (nullable = true)
 |-- YearsInCurrentRole: integer (nullable = true)
 |-- YearsSinceLastPromotion: integer (nullable = true)
 |-- YearsWithCurrManager: integer (nullable = true)


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}97}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}97}]:} Row(Age=41, Attrition='Yes', BusinessTravel='Travel\_Rarely', DailyRate=1102, Department='Sales', DistanceFromHome=1, Education=2, EducationField='Life Sciences', EmployeeCount=1, EmployeeNumber=1, EnvironmentSatisfaction=2, Gender='Female', HourlyRate=94, JobInvolvement=3, JobLevel=2, JobRole='Sales Executive', JobSatisfaction=4, MaritalStatus='Single', MonthlyIncome=5993, MonthlyRate=19479, NumCompaniesWorked=8, Over18='Y', OverTime='Yes', PercentSalaryHike=11, PerformanceRating=3, RelationshipSatisfaction=1, StandardHours=80, StockOptionLevel=0, TotalWorkingYears=8, TrainingTimesLastYear=0, WorkLifeBalance=1, YearsAtCompany=6, YearsInCurrentRole=4, YearsSinceLastPromotion=0, YearsWithCurrManager=5)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}98}]:} \PY{c+c1}{\PYZsh{} A simple for loop allows us to make it even clearer. }
         \PY{k}{for} \PY{n}{item} \PY{o+ow}{in} \PY{n}{dataset}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{item}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
41
Yes
Travel\_Rarely
1102
Sales
1
2
Life Sciences
1
1
2
Female
94
3
2
Sales Executive
4
Single
5993
19479
8
Y
Yes
11
3
1
80
0
8
0
1
6
4
0
5

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}99}]:} \PY{c+c1}{\PYZsh{} Import VectorAssembler and Vectors}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{linalg} \PY{k}{import} \PY{n}{Vectors}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{feature} \PY{k}{import} \PY{n}{VectorAssembler}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}116}]:} \PY{c+c1}{\PYZsh{} The input columns are the feature column names, and the output column is what you\PYZsq{}d like the new column to be named. }
          \PY{n}{assembler} \PY{o}{=} \PY{n}{VectorAssembler}\PY{p}{(}
              \PY{n}{inputCols}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Age}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
              \PY{n}{outputCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MonthlyIncome}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          \PY{n}{output} \PY{o}{=} \PY{n}{assembler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{dataset}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        Py4JJavaError                             Traceback (most recent call last)

        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw)
         62         try:
    ---> 63             return f(*a, **kw)
         64         except py4j.protocol.Py4JJavaError as e:


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get\_return\_value(answer, gateway\_client, target\_id, name)
        318                     "An error occurred while calling \{0\}\{1\}\{2\}.\textbackslash{}n".
    --> 319                     format(target\_id, ".", name), value)
        320             else:


        Py4JJavaError: An error occurred while calling o656.transform.
    : java.lang.IllegalArgumentException: Output column MonthlyIncome already exists.
    	at org.apache.spark.ml.feature.VectorAssembler.transformSchema(VectorAssembler.scala:124)
    	at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)
    	at org.apache.spark.ml.feature.VectorAssembler.transform(VectorAssembler.scala:54)
    	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.lang.reflect.Method.invoke(Method.java:498)
    	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
    	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
    	at py4j.Gateway.invoke(Gateway.java:280)
    	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
    	at py4j.commands.CallCommand.execute(CallCommand.java:79)
    	at py4j.GatewayConnection.run(GatewayConnection.java:214)
    	at java.lang.Thread.run(Thread.java:748)


        
    During handling of the above exception, another exception occurred:


        IllegalArgumentException                  Traceback (most recent call last)

        <ipython-input-116-e01a3073e62b> in <module>()
          3     inputCols=["Age"],
          4     outputCol="MonthlyIncome")
    ----> 5 output = assembler.transform(dataset)
    

        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py in transform(self, dataset, params)
        103                 return self.copy(params).\_transform(dataset)
        104             else:
    --> 105                 return self.\_transform(dataset)
        106         else:
        107             raise ValueError("Params must be a param map but got \%s." \% type(params))


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py in \_transform(self, dataset)
        250     def \_transform(self, dataset):
        251         self.\_transfer\_params\_to\_java()
    --> 252         return DataFrame(self.\_java\_obj.transform(dataset.\_jdf), dataset.sql\_ctx)
        253 
        254 


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java\_gateway.py in \_\_call\_\_(self, *args)
       1131         answer = self.gateway\_client.send\_command(command)
       1132         return\_value = get\_return\_value(
    -> 1133             answer, self.gateway\_client, self.target\_id, self.name)
       1134 
       1135         for temp\_arg in temp\_args:


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw)
         77                 raise QueryExecutionException(s.split(': ', 1)[1], stackTrace)
         78             if s.startswith('java.lang.IllegalArgumentException: '):
    ---> 79                 raise IllegalArgumentException(s.split(': ', 1)[1], stackTrace)
         80             raise
         81     return deco


        IllegalArgumentException: 'Output column MonthlyIncome already exists.'

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}117}]:} \PY{c+c1}{\PYZsh{} Now that we\PYZsq{}ve created the assembler variable, let\PYZsq{}s actually transform the data.}
          \PY{n}{output} \PY{o}{=} \PY{n}{assembler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{dataset}\PY{p}{)}
          \PY{c+c1}{\PYZsh{} Using print schema, you see that the features output column has been added. }
          \PY{n}{output}\PY{o}{.}\PY{n}{printSchema}\PY{p}{(}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} You can see that the features column is a dense vector that combines the various features as expected.}
          \PY{n}{output}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        Py4JJavaError                             Traceback (most recent call last)

        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw)
         62         try:
    ---> 63             return f(*a, **kw)
         64         except py4j.protocol.Py4JJavaError as e:


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get\_return\_value(answer, gateway\_client, target\_id, name)
        318                     "An error occurred while calling \{0\}\{1\}\{2\}.\textbackslash{}n".
    --> 319                     format(target\_id, ".", name), value)
        320             else:


        Py4JJavaError: An error occurred while calling o656.transform.
    : java.lang.IllegalArgumentException: Output column MonthlyIncome already exists.
    	at org.apache.spark.ml.feature.VectorAssembler.transformSchema(VectorAssembler.scala:124)
    	at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)
    	at org.apache.spark.ml.feature.VectorAssembler.transform(VectorAssembler.scala:54)
    	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.lang.reflect.Method.invoke(Method.java:498)
    	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
    	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
    	at py4j.Gateway.invoke(Gateway.java:280)
    	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
    	at py4j.commands.CallCommand.execute(CallCommand.java:79)
    	at py4j.GatewayConnection.run(GatewayConnection.java:214)
    	at java.lang.Thread.run(Thread.java:748)


        
    During handling of the above exception, another exception occurred:


        IllegalArgumentException                  Traceback (most recent call last)

        <ipython-input-117-380df5f877a1> in <module>()
          1 \# Now that we've created the assembler variable, let's actually transform the data.
    ----> 2 output = assembler.transform(dataset)
          3 \# Using print schema, you see that the features output column has been added.
          4 output.printSchema()
          5 


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py in transform(self, dataset, params)
        103                 return self.copy(params).\_transform(dataset)
        104             else:
    --> 105                 return self.\_transform(dataset)
        106         else:
        107             raise ValueError("Params must be a param map but got \%s." \% type(params))


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py in \_transform(self, dataset)
        250     def \_transform(self, dataset):
        251         self.\_transfer\_params\_to\_java()
    --> 252         return DataFrame(self.\_java\_obj.transform(dataset.\_jdf), dataset.sql\_ctx)
        253 
        254 


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java\_gateway.py in \_\_call\_\_(self, *args)
       1131         answer = self.gateway\_client.send\_command(command)
       1132         return\_value = get\_return\_value(
    -> 1133             answer, self.gateway\_client, self.target\_id, self.name)
       1134 
       1135         for temp\_arg in temp\_args:


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw)
         77                 raise QueryExecutionException(s.split(': ', 1)[1], stackTrace)
         78             if s.startswith('java.lang.IllegalArgumentException: '):
    ---> 79                 raise IllegalArgumentException(s.split(': ', 1)[1], stackTrace)
         80             raise
         81     return deco


        IllegalArgumentException: 'Output column MonthlyIncome already exists.'

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}130}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s select two columns (the feature and predictor).}
          \PY{c+c1}{\PYZsh{} This is now in the appropriate format to be processed by Spark.}
          \PY{n}{final\PYZus{}data} \PY{o}{=} \PY{n}{dataset}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Attrition}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Gender}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YearsAtCompany}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MaritalStatus}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YearsSinceLastPromotion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{final\PYZus{}data}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
+---------+------+---+--------------+-------------+-----------------------+-------------+
|Attrition|Gender|Age|YearsAtCompany|MaritalStatus|YearsSinceLastPromotion|MonthlyIncome|
+---------+------+---+--------------+-------------+-----------------------+-------------+
|      Yes|Female| 41|             6|       Single|                      0|         5993|
|       No|  Male| 49|            10|      Married|                      1|         5130|
|      Yes|  Male| 37|             0|       Single|                      0|         2090|
|       No|Female| 33|             8|      Married|                      3|         2909|
|       No|  Male| 27|             2|      Married|                      2|         3468|
|       No|  Male| 32|             7|       Single|                      3|         3068|
|       No|Female| 59|             1|      Married|                      0|         2670|
|       No|  Male| 30|             1|     Divorced|                      0|         2693|
|       No|  Male| 38|             9|       Single|                      1|         9526|
|       No|  Male| 36|             7|      Married|                      7|         5237|
|       No|  Male| 35|             5|      Married|                      0|         2426|
|       No|Female| 29|             9|       Single|                      0|         4193|
|       No|  Male| 31|             5|     Divorced|                      4|         2911|
|       No|  Male| 34|             2|     Divorced|                      1|         2661|
|      Yes|  Male| 28|             4|       Single|                      0|         2028|
|       No|Female| 29|            10|     Divorced|                      8|         9980|
|       No|  Male| 32|             6|     Divorced|                      0|         3298|
|       No|  Male| 22|             1|     Divorced|                      0|         2935|
|       No|Female| 53|            25|      Married|                      3|        15427|
|       No|  Male| 38|             3|       Single|                      1|         3944|
+---------+------+---+--------------+-------------+-----------------------+-------------+
only showing top 20 rows


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}131}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s do a randomised 70/30 split. }
          \PY{c+c1}{\PYZsh{} Remember, you can use other splits depending on how easy/difficult it is to train your model.}
          \PY{n}{train\PYZus{}data}\PY{p}{,}\PY{n}{test\PYZus{}data} \PY{o}{=} \PY{n}{final\PYZus{}data}\PY{o}{.}\PY{n}{randomSplit}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.7}\PY{p}{,}\PY{l+m+mf}{0.3}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}132}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s see our training data.}
          \PY{n}{train\PYZus{}data}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} And our testing data.}
          \PY{n}{test\PYZus{}data}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
+-------+---------+------+-----------------+-----------------+-------------+-----------------------+-----------------+
|summary|Attrition|Gender|              Age|   YearsAtCompany|MaritalStatus|YearsSinceLastPromotion|    MonthlyIncome|
+-------+---------+------+-----------------+-----------------+-------------+-----------------------+-----------------+
|  count|     1032|  1032|             1032|             1032|         1032|                   1032|             1032|
|   mean|     null|  null|37.14050387596899|6.979651162790698|         null|      2.248062015503876|6585.885658914729|
| stddev|     null|  null|9.175444126340752|6.068040706515157|         null|      3.318597644184573|4771.205803068593|
|    min|       No|Female|               18|                0|     Divorced|                      0|             1051|
|    max|      Yes|  Male|               60|               37|       Single|                     15|            19999|
+-------+---------+------+-----------------+-----------------+-------------+-----------------------+-----------------+

+-------+---------+------+-----------------+------------------+-------------+-----------------------+-----------------+
|summary|Attrition|Gender|              Age|    YearsAtCompany|MaritalStatus|YearsSinceLastPromotion|    MonthlyIncome|
+-------+---------+------+-----------------+------------------+-------------+-----------------------+-----------------+
|  count|      438|   438|              438|               438|          438|                    438|              438|
|   mean|     null|  null|36.41324200913242| 7.075342465753424|         null|      2.045662100456621|6307.477168949772|
| stddev|     null|  null| 9.03010515311472|6.2686816811630015|         null|     2.9824378238241294|4554.837352950656|
|    min|       No|Female|               18|                 0|     Divorced|                      0|             1009|
|    max|      Yes|  Male|               60|                40|       Single|                     15|            19926|
+-------+---------+------+-----------------+------------------+-------------+-----------------------+-----------------+


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}123}]:} \PY{n}{lr} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{n}{labelCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        NameError                                 Traceback (most recent call last)

        <ipython-input-123-e78215182df0> in <module>()
    ----> 1 lr = LinearRegression(labelCol='dataset')
    

        NameError: name 'LinearRegression' is not defined

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}133}]:} \PY{n}{final\PYZus{}data}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
+-------+---------+------+------------------+------------------+-------------+-----------------------+-----------------+
|summary|Attrition|Gender|               Age|    YearsAtCompany|MaritalStatus|YearsSinceLastPromotion|    MonthlyIncome|
+-------+---------+------+------------------+------------------+-------------+-----------------------+-----------------+
|  count|     1470|  1470|              1470|              1470|         1470|                   1470|             1470|
|   mean|     null|  null|36.923809523809524|7.0081632653061225|         null|     2.1877551020408164|6502.931292517007|
| stddev|     null|  null| 9.135373489136729| 6.126525152403571|         null|     3.2224302791379693|4707.956783097992|
|    min|       No|Female|                18|                 0|     Divorced|                      0|             1009|
|    max|      Yes|  Male|                60|                40|       Single|                     15|            19999|
+-------+---------+------+------------------+------------------+-------------+-----------------------+-----------------+


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         
        \PY{c+c1}{\PYZsh{}Create a DataFrame}
        \PY{n}{df1} \PY{o}{=} \PY{p}{\PYZob{}}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Yes}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{No}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
        \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{is\PYZus{}promoted}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}
         
        \PY{n}{df1} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{df1}\PY{p}{,}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{is\PYZus{}promoted}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{df1}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
  Attrition is\_promoted
0       Yes           1
1        No           0

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} importing pandas package  }
         \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}  
             
         \PY{c+c1}{\PYZsh{} making data frame from csv file  }
         \PY{n}{dataset} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dataset.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}  
             
         \PY{c+c1}{\PYZsh{} creating bool series True for NaN values  }
         \PY{n}{bool\PYZus{}series} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{n}{data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Attrition}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}  
             
         \PY{c+c1}{\PYZsh{} filtering data  }
         \PY{c+c1}{\PYZsh{} displaying data only with Gender = NaN  }
         \PY{n}{data}\PY{p}{[}\PY{n}{bool\PYZus{}series}\PY{p}{]}  
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}14}]:} Empty DataFrame
         Columns: [Age, Attrition, BusinessTravel, DailyRate, Department, DistanceFromHome, Education, EducationField, EmployeeCount, EmployeeNumber, EnvironmentSatisfaction, Gender, HourlyRate, JobInvolvement, JobLevel, JobRole, JobSatisfaction, MaritalStatus, MonthlyIncome, MonthlyRate, NumCompaniesWorked, Over18, OverTime, PercentSalaryHike, PerformanceRating, RelationshipSatisfaction, StandardHours, StockOptionLevel, TotalWorkingYears, TrainingTimesLastYear, WorkLifeBalance, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager]
         Index: []
         
         [0 rows x 35 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{c+c1}{\PYZsh{} importing pandas package  }
         \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}  
             
         \PY{c+c1}{\PYZsh{} making data frame from csv file  }
         \PY{n}{dataset} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dataset.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}  
             
         \PY{c+c1}{\PYZsh{} creating bool series True for NaN values  }
         \PY{n}{bool\PYZus{}series} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{n}{data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{YearsAtCompany}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}  
             
         \PY{c+c1}{\PYZsh{} filtering data  }
         \PY{c+c1}{\PYZsh{} displaying data only with Gender = NaN  }
         \PY{n}{data}\PY{p}{[}\PY{n}{bool\PYZus{}series}\PY{p}{]}  
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}17}]:} Empty DataFrame
         Columns: [Age, Attrition, BusinessTravel, DailyRate, Department, DistanceFromHome, Education, EducationField, EmployeeCount, EmployeeNumber, EnvironmentSatisfaction, Gender, HourlyRate, JobInvolvement, JobLevel, JobRole, JobSatisfaction, MaritalStatus, MonthlyIncome, MonthlyRate, NumCompaniesWorked, Over18, OverTime, PercentSalaryHike, PerformanceRating, RelationshipSatisfaction, StandardHours, StockOptionLevel, TotalWorkingYears, TrainingTimesLastYear, WorkLifeBalance, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager]
         Index: []
         
         [0 rows x 35 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
         \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
          
         \PY{c+c1}{\PYZsh{}Create a DataFrame}
         \PY{n}{df2} \PY{o}{=} \PY{p}{\PYZob{}}
         \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{OverTime}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Yes}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{No}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
         \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{is\PYZus{}promoted}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}
          
         \PY{n}{df2} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{df2}\PY{p}{,}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{OverTime}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{is\PYZus{}promoted}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{df2}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
  OverTime is\_promoted
0      Yes           1
1       No           0

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{n}{target}\PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MonthlyIncome}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
         \PY{n}{data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}25}]:}    Age Attrition     BusinessTravel  DailyRate              Department  \textbackslash{}
         0   41       Yes      Travel\_Rarely       1102                   Sales   
         1   49        No  Travel\_Frequently        279  Research \& Development   
         2   37       Yes      Travel\_Rarely       1373  Research \& Development   
         3   33        No  Travel\_Frequently       1392  Research \& Development   
         4   27        No      Travel\_Rarely        591  Research \& Development   
         
            DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \textbackslash{}
         0                 1          2  Life Sciences              1               1   
         1                 8          1  Life Sciences              1               2   
         2                 2          2          Other              1               4   
         3                 3          4  Life Sciences              1               5   
         4                 2          1        Medical              1               7   
         
                    {\ldots}           RelationshipSatisfaction StandardHours  \textbackslash{}
         0          {\ldots}                                  1            80   
         1          {\ldots}                                  4            80   
         2          {\ldots}                                  2            80   
         3          {\ldots}                                  3            80   
         4          {\ldots}                                  4            80   
         
            StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \textbackslash{}
         0                 0                  8                      0               1   
         1                 1                 10                      3               3   
         2                 0                  7                      3               3   
         3                 0                  8                      3               3   
         4                 1                  6                      3               3   
         
            YearsAtCompany YearsInCurrentRole  YearsSinceLastPromotion  \textbackslash{}
         0               6                  4                        0   
         1              10                  7                        1   
         2               0                  0                        0   
         3               8                  7                        3   
         4               2                  2                        2   
         
            YearsWithCurrManager  
         0                     5  
         1                     7  
         2                     0  
         3                     0  
         4                     2  
         
         [5 rows x 35 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{dataset}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MonthlyIncome}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
(1470, 35)

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_51_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}30}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}30}]:} (array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),
          array([-0.5, -0.4, -0.3, -0.2, -0.1,  0. ,  0.1,  0.2,  0.3,  0.4,  0.5]),
          <a list of 10 Patch objects>)
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_52_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}31}]:} \PY{c+c1}{\PYZsh{} Python program showing }
         \PY{c+c1}{\PYZsh{} Graphical representation   }
         \PY{c+c1}{\PYZsh{} of log() function }
         \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np} 
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt} 
           
         \PY{n}{in\PYZus{}array} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} 
         \PY{n}{out\PYZus{}array} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{in\PYZus{}array}\PY{p}{)} 
           
         \PY{n+nb}{print} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{out\PYZus{}array : }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{out\PYZus{}array}\PY{p}{)} 
           
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{in\PYZus{}array}\PY{p}{,} \PY{n}{in\PYZus{}array}\PY{p}{,}  
                  \PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{marker} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{*}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} 
           
         \PY{c+c1}{\PYZsh{} red for numpy.log() }
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{out\PYZus{}array}\PY{p}{,} \PY{n}{in\PYZus{}array}\PY{p}{,}  
                  \PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{marker} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{o}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} 
                    
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{numpy.log()}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{out\PYZus{}array}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{in\PYZus{}array}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}  
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
out\_array :  0       8.698347
1       8.542861
2       7.644919
3       7.975565
4       8.151333
5       8.028781
6       7.889834
7       7.898411
8       9.161780
9       8.563504
10      7.793999
11      8.341172
12      7.976252
13      7.886457
14      7.614805
15      9.208338
16      8.101072
17      7.984463
18      9.643875
19      8.279951
20      8.296796
21      8.133587
22      9.392162
23      7.116394
24      7.992945
25      9.857129
26      8.273592
27      8.828348
28      9.234838
29      9.849401
          {\ldots}   
1440    8.543056
1441    8.749257
1442    8.473659
1443    9.845858
1444    7.757479
1445    9.515617
1446    8.811652
1447    8.595265
1448    9.098067
1449    7.799343
1450    9.086703
1451    8.583543
1452    8.814033
1453    8.802673
1454    8.486734
1455    7.940584
1456    8.646290
1457    7.601402
1458    7.998671
1459    8.300280
1460    8.238801
1461    9.292289
1462    9.395242
1463    9.203920
1464    7.994970
1465    7.852050
1466    9.209440
1467    8.722906
1468    8.592301
1469    8.390268
Name: MonthlyIncome, Length: 1470, dtype: float64

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_53_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}35}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
         \PY{k+kn}{import} \PY{n+nn}{findspark}
         \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k+kn}{import} \PY{n+nn}{pyspark}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
         \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{linear\PYZus{}regression\PYZus{}adv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}36}]:} \PY{c+c1}{\PYZsh{} If you\PYZsq{}re getting an error with numpy, please type \PYZsq{}sudo pip install numpy \PYZhy{}\PYZhy{}user\PYZsq{} into the EC2 console.}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{regression} \PY{k}{import} \PY{n}{LinearRegression}
         \PY{c+c1}{\PYZsh{} Import VectorAssembler and Vectors}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{linalg} \PY{k}{import} \PY{n}{Vectors}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{feature} \PY{k}{import} \PY{n}{VectorAssembler}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}98}]:} \PY{c+c1}{\PYZsh{} The input columns are the feature column names, and the output column is what you\PYZsq{}d like the new column to be named. }
         \PY{n}{assembler} \PY{o}{=} \PY{n}{VectorAssembler}\PY{p}{(}
             \PY{n}{inputCols}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MonthlyIncome}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Age}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} 
                        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{YearsAtCompany}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
             \PY{n}{outputCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}60}]:} \PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dataset.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
         \PY{n}{data}\PY{o}{.}\PY{n}{printSchema}\PY{p}{(}\PY{p}{)}
         \PY{n}{data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
         \PY{k}{for} \PY{n}{item} \PY{o+ow}{in} \PY{n}{data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{item}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
root
 |-- Age: integer (nullable = true)
 |-- Attrition: string (nullable = true)
 |-- BusinessTravel: string (nullable = true)
 |-- DailyRate: integer (nullable = true)
 |-- Department: string (nullable = true)
 |-- DistanceFromHome: integer (nullable = true)
 |-- Education: integer (nullable = true)
 |-- EducationField: string (nullable = true)
 |-- EmployeeCount: integer (nullable = true)
 |-- EmployeeNumber: integer (nullable = true)
 |-- EnvironmentSatisfaction: integer (nullable = true)
 |-- Gender: string (nullable = true)
 |-- HourlyRate: integer (nullable = true)
 |-- JobInvolvement: integer (nullable = true)
 |-- JobLevel: integer (nullable = true)
 |-- JobRole: string (nullable = true)
 |-- JobSatisfaction: integer (nullable = true)
 |-- MaritalStatus: string (nullable = true)
 |-- MonthlyIncome: integer (nullable = true)
 |-- MonthlyRate: integer (nullable = true)
 |-- NumCompaniesWorked: integer (nullable = true)
 |-- Over18: string (nullable = true)
 |-- OverTime: string (nullable = true)
 |-- PercentSalaryHike: integer (nullable = true)
 |-- PerformanceRating: integer (nullable = true)
 |-- RelationshipSatisfaction: integer (nullable = true)
 |-- StandardHours: integer (nullable = true)
 |-- StockOptionLevel: integer (nullable = true)
 |-- TotalWorkingYears: integer (nullable = true)
 |-- TrainingTimesLastYear: integer (nullable = true)
 |-- WorkLifeBalance: integer (nullable = true)
 |-- YearsAtCompany: integer (nullable = true)
 |-- YearsInCurrentRole: integer (nullable = true)
 |-- YearsSinceLastPromotion: integer (nullable = true)
 |-- YearsWithCurrManager: integer (nullable = true)

41
Yes
Travel\_Rarely
1102
Sales
1
2
Life Sciences
1
1
2
Female
94
3
2
Sales Executive
4
Single
5993
19479
8
Y
Yes
11
3
1
80
0
8
0
1
6
4
0
5

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}70}]:} \PY{c+c1}{\PYZsh{} Import VectorAssembler and Vectors}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{linalg} \PY{k}{import} \PY{n}{Vectors}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{feature} \PY{k}{import} \PY{n}{VectorAssembler}
         \PY{c+c1}{\PYZsh{} The input columns are the feature column names, and the output column is what you\PYZsq{}d like the new column to be named. }
         \PY{n}{assembler} \PY{o}{=} \PY{n}{VectorAssembler}\PY{p}{(}
             \PY{n}{inputCols}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MonthlyIncome}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{YearsAtCompany}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Age}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
             \PY{n}{outputCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}73}]:} \PY{n}{output} \PY{o}{=} \PY{n}{assembler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{data}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Using print schema, you see that the features output column has been added. }
         \PY{n}{output}\PY{o}{.}\PY{n}{printSchema}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} You can see that the features column is a dense vector that combines the various features as expected.}
         \PY{n}{output}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
root
 |-- Age: integer (nullable = true)
 |-- Attrition: string (nullable = true)
 |-- BusinessTravel: string (nullable = true)
 |-- DailyRate: integer (nullable = true)
 |-- Department: string (nullable = true)
 |-- DistanceFromHome: integer (nullable = true)
 |-- Education: integer (nullable = true)
 |-- EducationField: string (nullable = true)
 |-- EmployeeCount: integer (nullable = true)
 |-- EmployeeNumber: integer (nullable = true)
 |-- EnvironmentSatisfaction: integer (nullable = true)
 |-- Gender: string (nullable = true)
 |-- HourlyRate: integer (nullable = true)
 |-- JobInvolvement: integer (nullable = true)
 |-- JobLevel: integer (nullable = true)
 |-- JobRole: string (nullable = true)
 |-- JobSatisfaction: integer (nullable = true)
 |-- MaritalStatus: string (nullable = true)
 |-- MonthlyIncome: integer (nullable = true)
 |-- MonthlyRate: integer (nullable = true)
 |-- NumCompaniesWorked: integer (nullable = true)
 |-- Over18: string (nullable = true)
 |-- OverTime: string (nullable = true)
 |-- PercentSalaryHike: integer (nullable = true)
 |-- PerformanceRating: integer (nullable = true)
 |-- RelationshipSatisfaction: integer (nullable = true)
 |-- StandardHours: integer (nullable = true)
 |-- StockOptionLevel: integer (nullable = true)
 |-- TotalWorkingYears: integer (nullable = true)
 |-- TrainingTimesLastYear: integer (nullable = true)
 |-- WorkLifeBalance: integer (nullable = true)
 |-- YearsAtCompany: integer (nullable = true)
 |-- YearsInCurrentRole: integer (nullable = true)
 |-- YearsSinceLastPromotion: integer (nullable = true)
 |-- YearsWithCurrManager: integer (nullable = true)
 |-- features: vector (nullable = true)


    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}73}]:} [Row(Age=41, Attrition='Yes', BusinessTravel='Travel\_Rarely', DailyRate=1102, Department='Sales', DistanceFromHome=1, Education=2, EducationField='Life Sciences', EmployeeCount=1, EmployeeNumber=1, EnvironmentSatisfaction=2, Gender='Female', HourlyRate=94, JobInvolvement=3, JobLevel=2, JobRole='Sales Executive', JobSatisfaction=4, MaritalStatus='Single', MonthlyIncome=5993, MonthlyRate=19479, NumCompaniesWorked=8, Over18='Y', OverTime='Yes', PercentSalaryHike=11, PerformanceRating=3, RelationshipSatisfaction=1, StandardHours=80, StockOptionLevel=0, TotalWorkingYears=8, TrainingTimesLastYear=0, WorkLifeBalance=1, YearsAtCompany=6, YearsInCurrentRole=4, YearsSinceLastPromotion=0, YearsWithCurrManager=5, features=DenseVector([5993.0, 6.0, 41.0]))]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}78}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s select two columns (the feature and predictor).}
         \PY{c+c1}{\PYZsh{} This is now in the appropriate format to be processed by Spark.}
         \PY{n}{final\PYZus{}data} \PY{o}{=} \PY{n}{output}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{final\PYZus{}data}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
+-------------------+-------------+
|           features|MonthlyIncome|
+-------------------+-------------+
|  [5993.0,6.0,41.0]|         5993|
| [5130.0,10.0,49.0]|         5130|
|  [2090.0,0.0,37.0]|         2090|
|  [2909.0,8.0,33.0]|         2909|
|  [3468.0,2.0,27.0]|         3468|
|  [3068.0,7.0,32.0]|         3068|
|  [2670.0,1.0,59.0]|         2670|
|  [2693.0,1.0,30.0]|         2693|
|  [9526.0,9.0,38.0]|         9526|
|  [5237.0,7.0,36.0]|         5237|
|  [2426.0,5.0,35.0]|         2426|
|  [4193.0,9.0,29.0]|         4193|
|  [2911.0,5.0,31.0]|         2911|
|  [2661.0,2.0,34.0]|         2661|
|  [2028.0,4.0,28.0]|         2028|
| [9980.0,10.0,29.0]|         9980|
|  [3298.0,6.0,32.0]|         3298|
|  [2935.0,1.0,22.0]|         2935|
|[15427.0,25.0,53.0]|        15427|
|  [3944.0,3.0,38.0]|         3944|
+-------------------+-------------+
only showing top 20 rows


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}93}]:} \PY{n}{dataset}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}93}]:}                Age    DailyRate  DistanceFromHome    Education  EmployeeCount  \textbackslash{}
         count  1470.000000  1470.000000       1470.000000  1470.000000         1470.0   
         mean     36.923810   802.485714          9.192517     2.912925            1.0   
         std       9.135373   403.509100          8.106864     1.024165            0.0   
         min      18.000000   102.000000          1.000000     1.000000            1.0   
         25\%      30.000000   465.000000          2.000000     2.000000            1.0   
         50\%      36.000000   802.000000          7.000000     3.000000            1.0   
         75\%      43.000000  1157.000000         14.000000     4.000000            1.0   
         max      60.000000  1499.000000         29.000000     5.000000            1.0   
         
                EmployeeNumber  EnvironmentSatisfaction   HourlyRate  JobInvolvement  \textbackslash{}
         count     1470.000000              1470.000000  1470.000000     1470.000000   
         mean      1024.865306                 2.721769    65.891156        2.729932   
         std        602.024335                 1.093082    20.329428        0.711561   
         min          1.000000                 1.000000    30.000000        1.000000   
         25\%        491.250000                 2.000000    48.000000        2.000000   
         50\%       1020.500000                 3.000000    66.000000        3.000000   
         75\%       1555.750000                 4.000000    83.750000        3.000000   
         max       2068.000000                 4.000000   100.000000        4.000000   
         
                   JobLevel          {\ldots}           RelationshipSatisfaction  \textbackslash{}
         count  1470.000000          {\ldots}                        1470.000000   
         mean      2.063946          {\ldots}                           2.712245   
         std       1.106940          {\ldots}                           1.081209   
         min       1.000000          {\ldots}                           1.000000   
         25\%       1.000000          {\ldots}                           2.000000   
         50\%       2.000000          {\ldots}                           3.000000   
         75\%       3.000000          {\ldots}                           4.000000   
         max       5.000000          {\ldots}                           4.000000   
         
                StandardHours  StockOptionLevel  TotalWorkingYears  \textbackslash{}
         count         1470.0       1470.000000        1470.000000   
         mean            80.0          0.793878          11.279592   
         std              0.0          0.852077           7.780782   
         min             80.0          0.000000           0.000000   
         25\%             80.0          0.000000           6.000000   
         50\%             80.0          1.000000          10.000000   
         75\%             80.0          1.000000          15.000000   
         max             80.0          3.000000          40.000000   
         
                TrainingTimesLastYear  WorkLifeBalance  YearsAtCompany  \textbackslash{}
         count            1470.000000      1470.000000     1470.000000   
         mean                2.799320         2.761224        7.008163   
         std                 1.289271         0.706476        6.126525   
         min                 0.000000         1.000000        0.000000   
         25\%                 2.000000         2.000000        3.000000   
         50\%                 3.000000         3.000000        5.000000   
         75\%                 3.000000         3.000000        9.000000   
         max                 6.000000         4.000000       40.000000   
         
                YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  
         count         1470.000000              1470.000000           1470.000000  
         mean             4.229252                 2.187755              4.123129  
         std              3.623137                 3.222430              3.568136  
         min              0.000000                 0.000000              0.000000  
         25\%              2.000000                 0.000000              2.000000  
         50\%              3.000000                 1.000000              3.000000  
         75\%              7.000000                 3.000000              7.000000  
         max             18.000000                15.000000             17.000000  
         
         [8 rows x 26 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}108}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s import the string indexer (similar to the logistic regression exercises).}
          \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{feature} \PY{k}{import} \PY{n}{StringIndexer}
          
          \PY{n}{indexer} \PY{o}{=} \PY{n}{StringIndexer}\PY{p}{(}\PY{n}{inputCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MonthlyIncome}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{outputCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MonthlyIncomeIndex}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          \PY{n}{output\PYZus{}fixed} \PY{o}{=} \PY{n}{indexer}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{output}\PY{p}{)}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{output}\PY{p}{)}
          \PY{c+c1}{\PYZsh{} Let\PYZsq{}s select the two columns we want. Features (which contains vectors), and the predictor.}
          \PY{n}{final\PYZus{}data} \PY{o}{=} \PY{n}{output\PYZus{}fixed}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncomeIndex}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}109}]:} \PY{c+c1}{\PYZsh{} Split the training and testing set.}
          \PY{n}{train\PYZus{}data}\PY{p}{,}\PY{n}{test\PYZus{}data} \PY{o}{=} \PY{n}{final\PYZus{}data}\PY{o}{.}\PY{n}{randomSplit}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.7}\PY{p}{,}\PY{l+m+mf}{0.3}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
        \PY{k+kn}{import} \PY{n+nn}{findspark}
        \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{pyspark}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{o}{*}
        \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{logistic\PYZus{}regression\PYZus{}adv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} If you\PYZsq{}re getting an error with numpy, please type \PYZsq{}sudo pip install numpy \PYZhy{}\PYZhy{}user\PYZsq{} into the EC2 console.}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{classification} \PY{k}{import} \PY{n}{LogisticRegression}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} Read in the CSV data.}
        \PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} Import the relevant Python libraries.}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        
        \PY{c+c1}{\PYZsh{} Convert sex to an array using Numpy and plot it using pyplot. }
        \PY{n}{AttritionArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{AttritionArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Because you can interact with Spark using SQL, you can also filter the data you see. }
        \PY{c+c1}{\PYZsh{} For example, age has some null values. We can remove all null values before visualising the data.}
        \PY{n}{AttritionArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{filter}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition \PYZgt{} 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{AttritionArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_66_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_66_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml} \PY{k}{import} \PY{n}{Pipeline}
        \PY{c+c1}{\PYZsh{} Note that survived is a categorial variable but didn\PYZsq{}t require any transformation.}
        \PY{c+c1}{\PYZsh{} That\PYZsq{}s because it\PYZsq{}s already in the format of 1\PYZsq{}s and 0\PYZsq{}s. }
        \PY{n}{log\PYZus{}reg\PYZus{}Attrition} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{n}{featuresCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{labelCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} First create a string indexer (convert every string into a number, such as male = 0 and female = 1).}
        \PY{c+c1}{\PYZsh{} A number will be assigned to every category in the column.}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{feature} \PY{k}{import} \PY{p}{(}\PY{n}{VectorAssembler}\PY{p}{,}\PY{n}{VectorIndexer}\PY{p}{,}
                                        \PY{n}{OneHotEncoder}\PY{p}{,}\PY{n}{StringIndexer}\PY{p}{)}
        \PY{n}{Attrition\PYZus{}indexer} \PY{o}{=} \PY{n}{StringIndexer}\PY{p}{(}\PY{n}{inputCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Attrition}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{outputCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AttritionIndex}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Now we can one hot encode these numbers. This converts the various outputs into a single vector.}
        \PY{c+c1}{\PYZsh{} This makes it easier to process when you have multiple classes.}
        \PY{n}{Attrition\PYZus{}encoder} \PY{o}{=} \PY{n}{OneHotEncoder}\PY{p}{(}\PY{n}{inputCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIndex}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{outputCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncomeVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        ImportError                               Traceback (most recent call last)

        <ipython-input-3-e79e6cd1899f> in <module>()
    ----> 1 from pyspark.ml import Pipeline
          2 \# Note that survived is a categorial variable but didn't require any transformation.
          3 \# That's because it's already in the format of 1's and 0's.
          4 log\_reg\_Attrition = LogisticRegression(featuresCol='features',labelCol='Attrition')
          5 \# First create a string indexer (convert every string into a number, such as male = 0 and female = 1).


        ImportError: No module named 'pyspark'

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} Similar to the above.}
        \PY{n}{embark\PYZus{}indexer} \PY{o}{=} \PY{n}{StringIndexer}\PY{p}{(}\PY{n}{inputCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{outputCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AgeIndex}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{embark\PYZus{}encoder} \PY{o}{=} \PY{n}{OneHotEncoder}\PY{p}{(}\PY{n}{inputCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YearsAtCompanyIndex}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{outputCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YearsAtCompanyVec}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Note that survived is a categorial variable but didn\PYZsq{}t require any transformation.}
        \PY{c+c1}{\PYZsh{} That\PYZsq{}s because it\PYZsq{}s already in the format of 1\PYZsq{}s and 0\PYZsq{}s. }
        \PY{n}{log\PYZus{}reg\PYZus{}Attrition} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{n}{featuresCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{labelCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Lists everything we want to do. Index data, encode data, assemble data and then pass in the actual model.}
        \PY{n}{pipeline} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{n}{stages}\PY{o}{=}\PY{p}{[}\PY{n}{Attrition\PYZus{}indexer}\PY{p}{,}\PY{n}{embark\PYZus{}indexer}\PY{p}{,}
                                   \PY{n}{embark\PYZus{}encoder}\PY{p}{,}
                                   \PY{n}{log\PYZus{}reg\PYZus{}Attrition}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        NameError                                 Traceback (most recent call last)

        <ipython-input-4-28c6352d6db0> in <module>()
          1 \# Similar to the above.
    ----> 2 embark\_indexer = StringIndexer(inputCol='Age',outputCol='AgeIndex')
          3 embark\_encoder = OneHotEncoder(inputCol='YearsAtCompanyIndex',outputCol='YearsAtCompanyVec')
          4 \# Note that survived is a categorial variable but didn't require any transformation.
          5 \# That's because it's already in the format of 1's and 0's.


        NameError: name 'StringIndexer' is not defined

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{c+c1}{\PYZsh{} Import VectorAssembler and Vectors}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{linalg} \PY{k}{import} \PY{n}{Vectors}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{feature} \PY{k}{import} \PY{n}{VectorAssembler}
         \PY{c+c1}{\PYZsh{} The input columns are the feature column names, and the output column is what you\PYZsq{}d like the new column to be named. }
         \PY{n}{assembler} \PY{o}{=} \PY{n}{VectorAssembler}\PY{p}{(}
             \PY{n}{inputCols}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MonthlyIncome}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{YearsAtCompany}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Age}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
             \PY{n}{outputCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{output} \PY{o}{=} \PY{n}{assembler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{data}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Using print schema, you see that the features output column has been added. }
         \PY{n}{output}\PY{o}{.}\PY{n}{printSchema}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} You can see that the features column is a dense vector that combines the various features as expected.}
         \PY{n}{output}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Let\PYZsq{}s select two columns (the feature and predictor).}
         \PY{c+c1}{\PYZsh{} This is now in the appropriate format to be processed by Spark.}
         \PY{n}{final\PYZus{}data} \PY{o}{=} \PY{n}{output}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{final\PYZus{}data}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Let\PYZsq{}s import the string indexer (similar to the logistic regression exercises).}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{feature} \PY{k}{import} \PY{n}{StringIndexer}
         
         \PY{n}{indexer} \PY{o}{=} \PY{n}{StringIndexer}\PY{p}{(}\PY{n}{inputCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MonthlyIncome}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{outputCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MonthlyIncomeIndex}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{output\PYZus{}fixed} \PY{o}{=} \PY{n}{indexer}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{output}\PY{p}{)}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{output}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Let\PYZsq{}s select the two columns we want. Features (which contains vectors), and the predictor.}
         \PY{n}{final\PYZus{}data} \PY{o}{=} \PY{n}{output\PYZus{}fixed}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncomeIndex}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
root
 |-- Age: integer (nullable = true)
 |-- Attrition: string (nullable = true)
 |-- BusinessTravel: string (nullable = true)
 |-- DailyRate: integer (nullable = true)
 |-- Department: string (nullable = true)
 |-- DistanceFromHome: integer (nullable = true)
 |-- Education: integer (nullable = true)
 |-- EducationField: string (nullable = true)
 |-- EmployeeCount: integer (nullable = true)
 |-- EmployeeNumber: integer (nullable = true)
 |-- EnvironmentSatisfaction: integer (nullable = true)
 |-- Gender: string (nullable = true)
 |-- HourlyRate: integer (nullable = true)
 |-- JobInvolvement: integer (nullable = true)
 |-- JobLevel: integer (nullable = true)
 |-- JobRole: string (nullable = true)
 |-- JobSatisfaction: integer (nullable = true)
 |-- MaritalStatus: string (nullable = true)
 |-- MonthlyIncome: integer (nullable = true)
 |-- MonthlyRate: integer (nullable = true)
 |-- NumCompaniesWorked: integer (nullable = true)
 |-- Over18: string (nullable = true)
 |-- OverTime: string (nullable = true)
 |-- PercentSalaryHike: integer (nullable = true)
 |-- PerformanceRating: integer (nullable = true)
 |-- RelationshipSatisfaction: integer (nullable = true)
 |-- StandardHours: integer (nullable = true)
 |-- StockOptionLevel: integer (nullable = true)
 |-- TotalWorkingYears: integer (nullable = true)
 |-- TrainingTimesLastYear: integer (nullable = true)
 |-- WorkLifeBalance: integer (nullable = true)
 |-- YearsAtCompany: integer (nullable = true)
 |-- YearsInCurrentRole: integer (nullable = true)
 |-- YearsSinceLastPromotion: integer (nullable = true)
 |-- YearsWithCurrManager: integer (nullable = true)
 |-- features: vector (nullable = true)

+-------------------+-------------+
|           features|MonthlyIncome|
+-------------------+-------------+
|  [5993.0,6.0,41.0]|         5993|
| [5130.0,10.0,49.0]|         5130|
|  [2090.0,0.0,37.0]|         2090|
|  [2909.0,8.0,33.0]|         2909|
|  [3468.0,2.0,27.0]|         3468|
|  [3068.0,7.0,32.0]|         3068|
|  [2670.0,1.0,59.0]|         2670|
|  [2693.0,1.0,30.0]|         2693|
|  [9526.0,9.0,38.0]|         9526|
|  [5237.0,7.0,36.0]|         5237|
|  [2426.0,5.0,35.0]|         2426|
|  [4193.0,9.0,29.0]|         4193|
|  [2911.0,5.0,31.0]|         2911|
|  [2661.0,2.0,34.0]|         2661|
|  [2028.0,4.0,28.0]|         2028|
| [9980.0,10.0,29.0]|         9980|
|  [3298.0,6.0,32.0]|         3298|
|  [2935.0,1.0,22.0]|         2935|
|[15427.0,25.0,53.0]|        15427|
|  [3944.0,3.0,38.0]|         3944|
+-------------------+-------------+
only showing top 20 rows


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
        \PY{k+kn}{import} \PY{n+nn}{findspark}
        \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{pyspark}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{o}{*}
        \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{logistic\PYZus{}regression\PYZus{}adv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} If you\PYZsq{}re getting an error with numpy, please type \PYZsq{}sudo pip install numpy \PYZhy{}\PYZhy{}user\PYZsq{} into the EC2 console.}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{classification} \PY{k}{import} \PY{n}{LogisticRegression}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} Train/test split. }
        \PY{n}{train\PYZus{}data}\PY{p}{,} \PY{n}{testc\PYZus{}data} \PY{o}{=} \PY{n}{final\PYZus{}data}\PY{o}{.}\PY{n}{randomSplit}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.7}\PY{p}{,}\PY{o}{.}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Now that we\PYZsq{}ve selected the relevant columns, let\PYZsq{}s drop the missing data.}
        \PY{n}{my\PYZus{}cols} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
         \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
         \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YearsAtCompany}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        NameError                                 Traceback (most recent call last)

        <ipython-input-6-ef0b8d5c7f7c> in <module>()
          1 \# Train/test split.
    ----> 2 train\_data, testc\_data = final\_data.randomSplit([0.7,.3])
          3 \# Now that we've selected the relevant columns, let's drop the missing data.
          4 my\_cols = data.select(['MonthlyIncome',
          5  'Age',


        NameError: name 'final\_data' is not defined

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{my\PYZus{}final\PYZus{}data} \PY{o}{=} \PY{n}{my\PYZus{}cols}\PY{o}{.}\PY{n}{na}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{feature} \PY{k}{import} \PY{p}{(}\PY{n}{VectorAssembler}\PY{p}{,}\PY{n}{VectorIndexer}\PY{p}{,}
                                        \PY{n}{OneHotEncoder}\PY{p}{,}\PY{n}{StringIndexer}\PY{p}{)}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml} \PY{k}{import} \PY{n}{Pipeline}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
         \PY{k+kn}{import} \PY{n+nn}{findspark}
         \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k+kn}{import} \PY{n+nn}{pyspark}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
         \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{linear\PYZus{}regression\PYZus{}adv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} If you\PYZsq{}re getting an error with numpy, please type \PYZsq{}sudo pip install numpy \PYZhy{}\PYZhy{}user\PYZsq{} into the EC2 console.}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{regression} \PY{k}{import} \PY{n}{LinearRegression}
         \PY{c+c1}{\PYZsh{} Use Spark to read in the Ecommerce Customers csv file. You can infer csv schemas. }
         \PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dataset.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Print the schema of the DataFrame. You can see potential features as well as the predictor.}
         \PY{n}{data}\PY{o}{.}\PY{n}{printSchema}\PY{p}{(}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Let\PYZsq{}s focus on one row to make it easier to read.}
         \PY{n}{data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} A simple for loop allows us to make it even clearer. }
         \PY{k}{for} \PY{n}{item} \PY{o+ow}{in} \PY{n}{data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{item}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
root
 |-- Age: integer (nullable = true)
 |-- Attrition: string (nullable = true)
 |-- BusinessTravel: string (nullable = true)
 |-- DailyRate: integer (nullable = true)
 |-- Department: string (nullable = true)
 |-- DistanceFromHome: integer (nullable = true)
 |-- Education: integer (nullable = true)
 |-- EducationField: string (nullable = true)
 |-- EmployeeCount: integer (nullable = true)
 |-- EmployeeNumber: integer (nullable = true)
 |-- EnvironmentSatisfaction: integer (nullable = true)
 |-- Gender: string (nullable = true)
 |-- HourlyRate: integer (nullable = true)
 |-- JobInvolvement: integer (nullable = true)
 |-- JobLevel: integer (nullable = true)
 |-- JobRole: string (nullable = true)
 |-- JobSatisfaction: integer (nullable = true)
 |-- MaritalStatus: string (nullable = true)
 |-- MonthlyIncome: integer (nullable = true)
 |-- MonthlyRate: integer (nullable = true)
 |-- NumCompaniesWorked: integer (nullable = true)
 |-- Over18: string (nullable = true)
 |-- OverTime: string (nullable = true)
 |-- PercentSalaryHike: integer (nullable = true)
 |-- PerformanceRating: integer (nullable = true)
 |-- RelationshipSatisfaction: integer (nullable = true)
 |-- StandardHours: integer (nullable = true)
 |-- StockOptionLevel: integer (nullable = true)
 |-- TotalWorkingYears: integer (nullable = true)
 |-- TrainingTimesLastYear: integer (nullable = true)
 |-- WorkLifeBalance: integer (nullable = true)
 |-- YearsAtCompany: integer (nullable = true)
 |-- YearsInCurrentRole: integer (nullable = true)
 |-- YearsSinceLastPromotion: integer (nullable = true)
 |-- YearsWithCurrManager: integer (nullable = true)

41
Yes
Travel\_Rarely
1102
Sales
1
2
Life Sciences
1
1
2
Female
94
3
2
Sales Executive
4
Single
5993
19479
8
Y
Yes
11
3
1
80
0
8
0
1
6
4
0
5

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{c+c1}{\PYZsh{} Import VectorAssembler and Vectors}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{linalg} \PY{k}{import} \PY{n}{Vectors}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{feature} \PY{k}{import} \PY{n}{VectorAssembler}
         \PY{c+c1}{\PYZsh{} The input columns are the feature column names, and the output column is what you\PYZsq{}d like the new column to be named. }
         \PY{n}{assembler} \PY{o}{=} \PY{n}{VectorAssembler}\PY{p}{(}
             \PY{n}{inputCols}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MonthlyIncome}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}  
                        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{YearsAtCompany}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
             \PY{n}{outputCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Now that we\PYZsq{}ve created the assembler variable, let\PYZsq{}s actually transform the data.}
         \PY{n}{output} \PY{o}{=} \PY{n}{assembler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{data}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Using print schema, you see that the features output column has been added. }
         \PY{n}{output}\PY{o}{.}\PY{n}{printSchema}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} You can see that the features column is a dense vector that combines the various features as expected.}
         \PY{n}{output}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Let\PYZsq{}s select two columns (the feature and predictor).}
         \PY{c+c1}{\PYZsh{} This is now in the appropriate format to be processed by Spark.}
         \PY{n}{final\PYZus{}data} \PY{o}{=} \PY{n}{output}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{final\PYZus{}data}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
root
 |-- Age: integer (nullable = true)
 |-- Attrition: string (nullable = true)
 |-- BusinessTravel: string (nullable = true)
 |-- DailyRate: integer (nullable = true)
 |-- Department: string (nullable = true)
 |-- DistanceFromHome: integer (nullable = true)
 |-- Education: integer (nullable = true)
 |-- EducationField: string (nullable = true)
 |-- EmployeeCount: integer (nullable = true)
 |-- EmployeeNumber: integer (nullable = true)
 |-- EnvironmentSatisfaction: integer (nullable = true)
 |-- Gender: string (nullable = true)
 |-- HourlyRate: integer (nullable = true)
 |-- JobInvolvement: integer (nullable = true)
 |-- JobLevel: integer (nullable = true)
 |-- JobRole: string (nullable = true)
 |-- JobSatisfaction: integer (nullable = true)
 |-- MaritalStatus: string (nullable = true)
 |-- MonthlyIncome: integer (nullable = true)
 |-- MonthlyRate: integer (nullable = true)
 |-- NumCompaniesWorked: integer (nullable = true)
 |-- Over18: string (nullable = true)
 |-- OverTime: string (nullable = true)
 |-- PercentSalaryHike: integer (nullable = true)
 |-- PerformanceRating: integer (nullable = true)
 |-- RelationshipSatisfaction: integer (nullable = true)
 |-- StandardHours: integer (nullable = true)
 |-- StockOptionLevel: integer (nullable = true)
 |-- TotalWorkingYears: integer (nullable = true)
 |-- TrainingTimesLastYear: integer (nullable = true)
 |-- WorkLifeBalance: integer (nullable = true)
 |-- YearsAtCompany: integer (nullable = true)
 |-- YearsInCurrentRole: integer (nullable = true)
 |-- YearsSinceLastPromotion: integer (nullable = true)
 |-- YearsWithCurrManager: integer (nullable = true)
 |-- features: vector (nullable = true)

+-------------------+-------------+
|           features|MonthlyIncome|
+-------------------+-------------+
|  [5993.0,6.0,41.0]|         5993|
| [5130.0,10.0,49.0]|         5130|
|  [2090.0,0.0,37.0]|         2090|
|  [2909.0,8.0,33.0]|         2909|
|  [3468.0,2.0,27.0]|         3468|
|  [3068.0,7.0,32.0]|         3068|
|  [2670.0,1.0,59.0]|         2670|
|  [2693.0,1.0,30.0]|         2693|
|  [9526.0,9.0,38.0]|         9526|
|  [5237.0,7.0,36.0]|         5237|
|  [2426.0,5.0,35.0]|         2426|
|  [4193.0,9.0,29.0]|         4193|
|  [2911.0,5.0,31.0]|         2911|
|  [2661.0,2.0,34.0]|         2661|
|  [2028.0,4.0,28.0]|         2028|
| [9980.0,10.0,29.0]|         9980|
|  [3298.0,6.0,32.0]|         3298|
|  [2935.0,1.0,22.0]|         2935|
|[15427.0,25.0,53.0]|        15427|
|  [3944.0,3.0,38.0]|         3944|
+-------------------+-------------+
only showing top 20 rows


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s do a randomised 70/30 split. }
         \PY{c+c1}{\PYZsh{} Remember, you can use other splits depending on how easy/difficult it is to train your model.}
         \PY{n}{train\PYZus{}data}\PY{p}{,}\PY{n}{test\PYZus{}data} \PY{o}{=} \PY{n}{final\PYZus{}data}\PY{o}{.}\PY{n}{randomSplit}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.7}\PY{p}{,}\PY{l+m+mf}{0.3}\PY{p}{]}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Let\PYZsq{}s see our training data.}
         \PY{n}{train\PYZus{}data}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} And our testing data.}
         \PY{n}{test\PYZus{}data}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
+-------+-----------------+
|summary|    MonthlyIncome|
+-------+-----------------+
|  count|             1013|
|   mean|6561.822309970385|
| stddev|4817.716393380911|
|    min|             1009|
|    max|            19973|
+-------+-----------------+

+-------+-----------------+
|summary|    MonthlyIncome|
+-------+-----------------+
|  count|              457|
|   mean|6372.391684901531|
| stddev|4457.390450112631|
|    min|             1051|
|    max|            19999|
+-------+-----------------+


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{n}{lr} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{n}{labelCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Fit the model to the data.}
         \PY{n}{lrModel} \PY{o}{=} \PY{n}{lr}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train\PYZus{}data}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Print the coefficients and intercept for linear regression.}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Coefficients: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ Intercept: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{lrModel}\PY{o}{.}\PY{n}{coefficients}\PY{p}{,}\PY{n}{lrModel}\PY{o}{.}\PY{n}{intercept}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Coefficients: [1.0000000000000004,1.0642678502607213e-13,-9.98927686807789e-14] Intercept: -2.5320589109657054e-13

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s evaluate the model against the test data.}
         \PY{n}{test\PYZus{}results} \PY{o}{=} \PY{n}{lrModel}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{test\PYZus{}data}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Interesting results! This shows the difference between the predicted value and the test data.}
         \PY{n}{test\PYZus{}results}\PY{o}{.}\PY{n}{residuals}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Let\PYZsq{}s get some evaluation metrics (as discussed in the previous linear regression notebook).}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RSME: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{test\PYZus{}results}\PY{o}{.}\PY{n}{rootMeanSquaredError}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
+--------------------+
|           residuals|
+--------------------+
|1.591615728102624{\ldots}|
|1.591615728102624{\ldots}|
|2.728484105318784{\ldots}|
|1.591615728102624{\ldots}|
|2.046363078989088{\ldots}|
|1.364242052659392{\ldots}|
|1.364242052659392{\ldots}|
|2.273736754432320{\ldots}|
|1.818989403545856{\ldots}|
|1.136868377216160{\ldots}|
|2.728484105318784{\ldots}|
|2.501110429875552{\ldots}|
|1.818989403545856{\ldots}|
|1.136868377216160{\ldots}|
|2.273736754432320{\ldots}|
|1.818989403545856{\ldots}|
|1.818989403545856{\ldots}|
|3.183231456205249{\ldots}|
|2.728484105318784{\ldots}|
|3.183231456205249{\ldots}|
+--------------------+
only showing top 20 rows

RSME: 2.261339201030291e-12

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{c+c1}{\PYZsh{} We can also get the R2 value. }
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{R2: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{test\PYZus{}results}\PY{o}{.}\PY{n}{r2}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
R2: 1.0

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{n}{final\PYZus{}data}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
+-------+-----------------+
|summary|    MonthlyIncome|
+-------+-----------------+
|  count|             1470|
|   mean|6502.931292517007|
| stddev|4707.956783097992|
|    min|             1009|
|    max|            19999|
+-------+-----------------+


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}33}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
         \PY{k+kn}{import} \PY{n+nn}{findspark}
         \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k+kn}{import} \PY{n+nn}{pyspark}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
         \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tree\PYZus{}methods\PYZus{}adv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Load training data. }
         \PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Let\PYZsq{}s get an idea of what the data looks like. }
         \PY{n}{data}\PY{o}{.}\PY{n}{printSchema}\PY{p}{(}\PY{p}{)}
         \PY{n}{data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
root
 |-- Age: integer (nullable = true)
 |-- Attrition: string (nullable = true)
 |-- BusinessTravel: string (nullable = true)
 |-- DailyRate: integer (nullable = true)
 |-- Department: string (nullable = true)
 |-- DistanceFromHome: integer (nullable = true)
 |-- Education: integer (nullable = true)
 |-- EducationField: string (nullable = true)
 |-- EmployeeCount: integer (nullable = true)
 |-- EmployeeNumber: integer (nullable = true)
 |-- EnvironmentSatisfaction: integer (nullable = true)
 |-- Gender: string (nullable = true)
 |-- HourlyRate: integer (nullable = true)
 |-- JobInvolvement: integer (nullable = true)
 |-- JobLevel: integer (nullable = true)
 |-- JobRole: string (nullable = true)
 |-- JobSatisfaction: integer (nullable = true)
 |-- MaritalStatus: string (nullable = true)
 |-- MonthlyIncome: integer (nullable = true)
 |-- MonthlyRate: integer (nullable = true)
 |-- NumCompaniesWorked: integer (nullable = true)
 |-- Over18: string (nullable = true)
 |-- OverTime: string (nullable = true)
 |-- PercentSalaryHike: integer (nullable = true)
 |-- PerformanceRating: integer (nullable = true)
 |-- RelationshipSatisfaction: integer (nullable = true)
 |-- StandardHours: integer (nullable = true)
 |-- StockOptionLevel: integer (nullable = true)
 |-- TotalWorkingYears: integer (nullable = true)
 |-- TrainingTimesLastYear: integer (nullable = true)
 |-- WorkLifeBalance: integer (nullable = true)
 |-- YearsAtCompany: integer (nullable = true)
 |-- YearsInCurrentRole: integer (nullable = true)
 |-- YearsSinceLastPromotion: integer (nullable = true)
 |-- YearsWithCurrManager: integer (nullable = true)


    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}33}]:} Row(Age=41, Attrition='Yes', BusinessTravel='Travel\_Rarely', DailyRate=1102, Department='Sales', DistanceFromHome=1, Education=2, EducationField='Life Sciences', EmployeeCount=1, EmployeeNumber=1, EnvironmentSatisfaction=2, Gender='Female', HourlyRate=94, JobInvolvement=3, JobLevel=2, JobRole='Sales Executive', JobSatisfaction=4, MaritalStatus='Single', MonthlyIncome=5993, MonthlyRate=19479, NumCompaniesWorked=8, Over18='Y', OverTime='Yes', PercentSalaryHike=11, PerformanceRating=3, RelationshipSatisfaction=1, StandardHours=80, StockOptionLevel=0, TotalWorkingYears=8, TrainingTimesLastYear=0, WorkLifeBalance=1, YearsAtCompany=6, YearsInCurrentRole=4, YearsSinceLastPromotion=0, YearsWithCurrManager=5)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}59}]:} \PY{c+c1}{\PYZsh{} A few things we need to do before Spark can accept the data!}
         \PY{c+c1}{\PYZsh{} It needs to be in the form of two columns: \PYZdq{}label\PYZdq{} and \PYZdq{}features\PYZdq{}.}
         
         \PY{c+c1}{\PYZsh{} Import VectorAssembler and Vectors}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{linalg} \PY{k}{import} \PY{n}{Vectors}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{feature} \PY{k}{import} \PY{n}{VectorAssembler}
         \PY{c+c1}{\PYZsh{} Let\PYZsq{}s visualise the columns to help with assembly. }
         \PY{n}{data}\PY{o}{.}\PY{n}{columns}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}59}]:} ['Age',
          'Attrition',
          'BusinessTravel',
          'DailyRate',
          'Department',
          'DistanceFromHome',
          'Education',
          'EducationField',
          'EmployeeCount',
          'EmployeeNumber',
          'EnvironmentSatisfaction',
          'Gender',
          'HourlyRate',
          'JobInvolvement',
          'JobLevel',
          'JobRole',
          'JobSatisfaction',
          'MaritalStatus',
          'MonthlyIncome',
          'MonthlyRate',
          'NumCompaniesWorked',
          'Over18',
          'OverTime',
          'PercentSalaryHike',
          'PerformanceRating',
          'RelationshipSatisfaction',
          'StandardHours',
          'StockOptionLevel',
          'TotalWorkingYears',
          'TrainingTimesLastYear',
          'WorkLifeBalance',
          'YearsAtCompany',
          'YearsInCurrentRole',
          'YearsSinceLastPromotion',
          'YearsWithCurrManager']
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
        \PY{k+kn}{import} \PY{n+nn}{findspark}
        \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{pyspark}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
        \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tree\PYZus{}methods\PYZus{}adv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Load training data. }
        \PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Let\PYZsq{}s get an idea of what the data looks like. }
        \PY{n}{data}\PY{o}{.}\PY{n}{printSchema}\PY{p}{(}\PY{p}{)}
        \PY{n}{data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} A few things we need to do before Spark can accept the data!}
        \PY{c+c1}{\PYZsh{} It needs to be in the form of two columns: \PYZdq{}label\PYZdq{} and \PYZdq{}features\PYZdq{}.}
        
        \PY{c+c1}{\PYZsh{} Import VectorAssembler and Vectors}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{linalg} \PY{k}{import} \PY{n}{Vectors}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{feature} \PY{k}{import} \PY{n}{VectorAssembler}
        \PY{c+c1}{\PYZsh{} Let\PYZsq{}s visualise the columns to help with assembly. }
        \PY{n}{data}\PY{o}{.}\PY{n}{columns}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
root
 |-- Age: integer (nullable = true)
 |-- Attrition: string (nullable = true)
 |-- BusinessTravel: string (nullable = true)
 |-- DailyRate: integer (nullable = true)
 |-- Department: string (nullable = true)
 |-- DistanceFromHome: integer (nullable = true)
 |-- Education: integer (nullable = true)
 |-- EducationField: string (nullable = true)
 |-- EmployeeCount: integer (nullable = true)
 |-- EmployeeNumber: integer (nullable = true)
 |-- EnvironmentSatisfaction: integer (nullable = true)
 |-- Gender: string (nullable = true)
 |-- HourlyRate: integer (nullable = true)
 |-- JobInvolvement: integer (nullable = true)
 |-- JobLevel: integer (nullable = true)
 |-- JobRole: string (nullable = true)
 |-- JobSatisfaction: integer (nullable = true)
 |-- MaritalStatus: string (nullable = true)
 |-- MonthlyIncome: integer (nullable = true)
 |-- MonthlyRate: integer (nullable = true)
 |-- NumCompaniesWorked: integer (nullable = true)
 |-- Over18: string (nullable = true)
 |-- OverTime: string (nullable = true)
 |-- PercentSalaryHike: integer (nullable = true)
 |-- PerformanceRating: integer (nullable = true)
 |-- RelationshipSatisfaction: integer (nullable = true)
 |-- StandardHours: integer (nullable = true)
 |-- StockOptionLevel: integer (nullable = true)
 |-- TotalWorkingYears: integer (nullable = true)
 |-- TrainingTimesLastYear: integer (nullable = true)
 |-- WorkLifeBalance: integer (nullable = true)
 |-- YearsAtCompany: integer (nullable = true)
 |-- YearsInCurrentRole: integer (nullable = true)
 |-- YearsSinceLastPromotion: integer (nullable = true)
 |-- YearsWithCurrManager: integer (nullable = true)


    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}7}]:} ['Age',
         'Attrition',
         'BusinessTravel',
         'DailyRate',
         'Department',
         'DistanceFromHome',
         'Education',
         'EducationField',
         'EmployeeCount',
         'EmployeeNumber',
         'EnvironmentSatisfaction',
         'Gender',
         'HourlyRate',
         'JobInvolvement',
         'JobLevel',
         'JobRole',
         'JobSatisfaction',
         'MaritalStatus',
         'MonthlyIncome',
         'MonthlyRate',
         'NumCompaniesWorked',
         'Over18',
         'OverTime',
         'PercentSalaryHike',
         'PerformanceRating',
         'RelationshipSatisfaction',
         'StandardHours',
         'StockOptionLevel',
         'TotalWorkingYears',
         'TrainingTimesLastYear',
         'WorkLifeBalance',
         'YearsAtCompany',
         'YearsInCurrentRole',
         'YearsSinceLastPromotion',
         'YearsWithCurrManager']
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{c+c1}{\PYZsh{} Combine all features into one vector named features.}
        \PY{n}{assembler} \PY{o}{=} \PY{n}{VectorAssembler}\PY{p}{(}
          \PY{n}{inputCols}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                     \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                     \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YearsAtCompany}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                      \PY{n}{outputCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s transform the data. }
         \PY{n}{output} \PY{o}{=} \PY{n}{assembler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{data}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s import the string indexer (similar to the logistic regression exercises).}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{feature} \PY{k}{import} \PY{n}{StringIndexer}
         \PY{n}{indexer} \PY{o}{=} \PY{n}{StringIndexer}\PY{p}{(}\PY{n}{inputCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Attrition}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{outputCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AttritionIndex}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{output\PYZus{}fixed} \PY{o}{=} \PY{n}{indexer}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{output}\PY{p}{)}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{output}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Let\PYZsq{}s select the two columns we want. Features (which contains vectors), and the predictor.}
         \PY{n}{final\PYZus{}data} \PY{o}{=} \PY{n}{output\PYZus{}fixed}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AttritionIndex}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Split the training and testing set.}
         \PY{n}{train\PYZus{}data}\PY{p}{,}\PY{n}{test\PYZus{}data} \PY{o}{=} \PY{n}{final\PYZus{}data}\PY{o}{.}\PY{n}{randomSplit}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.7}\PY{p}{,}\PY{l+m+mf}{0.3}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s import the relevant classifiers. }
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{classification} \PY{k}{import} \PY{n}{DecisionTreeClassifier}\PY{p}{,}\PY{n}{GBTClassifier}\PY{p}{,}\PY{n}{RandomForestClassifier}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml} \PY{k}{import} \PY{n}{Pipeline}
         \PY{c+c1}{\PYZsh{} Use defaults to make the comparison \PYZdq{}fair\PYZdq{}. This simplifies the comparison process.}
         
         \PY{n}{dtc} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{labelCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AttritionIndex}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{featuresCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{labelCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AttritionIndex}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{featuresCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{gbt} \PY{o}{=} \PY{n}{GBTClassifier}\PY{p}{(}\PY{n}{labelCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AttritionIndex}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{featuresCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Train the models (it\PYZsq{}s three models, so it might take some time).}
         \PY{n}{dtc\PYZus{}model} \PY{o}{=} \PY{n}{dtc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train\PYZus{}data}\PY{p}{)}
         \PY{n}{rfc\PYZus{}model} \PY{o}{=} \PY{n}{rfc}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train\PYZus{}data}\PY{p}{)}
         \PY{n}{gbt\PYZus{}model} \PY{o}{=} \PY{n}{gbt}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train\PYZus{}data}\PY{p}{)}
         \PY{n}{dtc\PYZus{}predictions} \PY{o}{=} \PY{n}{dtc\PYZus{}model}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{test\PYZus{}data}\PY{p}{)}
         \PY{n}{rfc\PYZus{}predictions} \PY{o}{=} \PY{n}{rfc\PYZus{}model}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{test\PYZus{}data}\PY{p}{)}
         \PY{n}{gbt\PYZus{}predictions} \PY{o}{=} \PY{n}{gbt\PYZus{}model}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{test\PYZus{}data}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s start off with binary classification.}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{evaluation} \PY{k}{import} \PY{n}{BinaryClassificationEvaluator}
         
         \PY{c+c1}{\PYZsh{} Note that the label column isn\PYZsq{}t named label, it\PYZsq{}s named PrivateIndex in this case.}
         \PY{n}{my\PYZus{}binary\PYZus{}eval} \PY{o}{=} \PY{n}{BinaryClassificationEvaluator}\PY{p}{(}\PY{n}{labelCol} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AttritionIndex}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{c+c1}{\PYZsh{} This is the area under the curve. This indicates that the data is highly seperable.}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DTC}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{my\PYZus{}binary\PYZus{}eval}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{dtc\PYZus{}predictions}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} RFC improves accuracy but also model complexity. RFC outperforms DTC in nearly every situation.}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RFC}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{my\PYZus{}binary\PYZus{}eval}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{rfc\PYZus{}predictions}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} We can\PYZsq{}t repeat these exact steps for GBT. If you print the schema of all three, you may be able to notice why.}
         \PY{c+c1}{\PYZsh{} Instead, let\PYZsq{}s redefine the object:}
         \PY{n}{my\PYZus{}binary\PYZus{}gbt\PYZus{}eval} \PY{o}{=} \PY{n}{BinaryClassificationEvaluator}\PY{p}{(}\PY{n}{labelCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AttritionIndex}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{rawPredictionCol}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{prediction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GBT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{my\PYZus{}binary\PYZus{}gbt\PYZus{}eval}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{gbt\PYZus{}predictions}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Interesting, GBT didn\PYZsq{}t perform as well as RFC or DTC. But that\PYZsq{}s because we left the model\PYZsq{}s settings as default. }
         \PY{c+c1}{\PYZsh{} In most cases, we should adjust these parameters. More trees may increase accuracy, but decrease precision and recall. }
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
DTC
0.4915412186379928
RFC
0.6156451612903223
GBT
0.5637096774193547

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s import the evaluator.}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{evaluation} \PY{k}{import} \PY{n}{MulticlassClassificationEvaluator}
         \PY{c+c1}{\PYZsh{} Select (prediction, true label) and compute test error. }
         \PY{n}{acc\PYZus{}evaluator} \PY{o}{=} \PY{n}{MulticlassClassificationEvaluator}\PY{p}{(}\PY{n}{labelCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AttritionIndex}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{predictionCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{prediction}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{metricName}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{accuracy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{dtc\PYZus{}acc} \PY{o}{=} \PY{n}{acc\PYZus{}evaluator}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{dtc\PYZus{}predictions}\PY{p}{)}
         \PY{n}{rfc\PYZus{}acc} \PY{o}{=} \PY{n}{acc\PYZus{}evaluator}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{rfc\PYZus{}predictions}\PY{p}{)}
         \PY{n}{gbt\PYZus{}acc} \PY{o}{=} \PY{n}{acc\PYZus{}evaluator}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{gbt\PYZus{}predictions}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{c+c1}{\PYZsh{} Let\PYZsq{}s do something a bit more complex in terms of printing, just so it\PYZsq{}s formatted nicer. }
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Here are the results!}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{*}\PY{l+m+mi}{40}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{A single decision tree has an accuracy of: }\PY{l+s+si}{\PYZob{}0:2.2f\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{dtc\PYZus{}acc}\PY{o}{*}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{*}\PY{l+m+mi}{40}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{A random forest ensemble has an accuracy of: }\PY{l+s+si}{\PYZob{}0:2.2f\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{rfc\PYZus{}acc}\PY{o}{*}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{*}\PY{l+m+mi}{40}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{An ensemble using GBT has an accuracy of: }\PY{l+s+si}{\PYZob{}0:2.2f\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{gbt\PYZus{}acc}\PY{o}{*}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Here are the results!
----------------------------------------
A single decision tree has an accuracy of: 82.10\%
----------------------------------------
A random forest ensemble has an accuracy of: 82.55\%
----------------------------------------
An ensemble using GBT has an accuracy of: 80.54\%

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{c+c1}{\PYZsh{} Create all three models. Note the number of trees. }
         \PY{c+c1}{\PYZsh{} The more trees you have, the more computation time. But this could also significantly increase accuracy. So there\PYZsq{}s a tradeoff. }
         \PY{n}{dt} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{p}{)}
         \PY{n}{rf} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{labelCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{label}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{featuresCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{numTrees}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Split the data into training and test sets (30\PYZpc{} held out for testing).}
         \PY{p}{(}\PY{n}{trainingData}\PY{p}{,} \PY{n}{testData}\PY{p}{)} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{randomSplit}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.7}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{]}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Train model. }
         \PY{n}{model\PYZus{}rf} \PY{o}{=} \PY{n}{rf}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{trainingData}\PY{p}{)}
         \PY{n}{model\PYZus{}dt} \PY{o}{=} \PY{n}{dt}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{trainingData}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        Py4JJavaError                             Traceback (most recent call last)

        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw)
         62         try:
    ---> 63             return f(*a, **kw)
         64         except py4j.protocol.Py4JJavaError as e:


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py in get\_return\_value(answer, gateway\_client, target\_id, name)
        318                     "An error occurred while calling \{0\}\{1\}\{2\}.\textbackslash{}n".
    --> 319                     format(target\_id, ".", name), value)
        320             else:


        Py4JJavaError: An error occurred while calling o526.fit.
    : java.lang.IllegalArgumentException: Field "features" does not exist.
    	at org.apache.spark.sql.types.StructType\$\$anonfun\$apply\$1.apply(StructType.scala:264)
    	at org.apache.spark.sql.types.StructType\$\$anonfun\$apply\$1.apply(StructType.scala:264)
    	at scala.collection.MapLike\$class.getOrElse(MapLike.scala:128)
    	at scala.collection.AbstractMap.getOrElse(Map.scala:59)
    	at org.apache.spark.sql.types.StructType.apply(StructType.scala:263)
    	at org.apache.spark.ml.util.SchemaUtils\$.checkColumnType(SchemaUtils.scala:40)
    	at org.apache.spark.ml.PredictorParams\$class.validateAndTransformSchema(Predictor.scala:51)
    	at org.apache.spark.ml.classification.Classifier.org\$apache\$spark\$ml\$classification\$ClassifierParams\$\$super\$validateAndTransformSchema(Classifier.scala:58)
    	at org.apache.spark.ml.classification.ClassifierParams\$class.validateAndTransformSchema(Classifier.scala:42)
    	at org.apache.spark.ml.classification.ProbabilisticClassifier.org\$apache\$spark\$ml\$classification\$ProbabilisticClassifierParams\$\$super\$validateAndTransformSchema(ProbabilisticClassifier.scala:53)
    	at org.apache.spark.ml.classification.ProbabilisticClassifierParams\$class.validateAndTransformSchema(ProbabilisticClassifier.scala:37)
    	at org.apache.spark.ml.classification.ProbabilisticClassifier.validateAndTransformSchema(ProbabilisticClassifier.scala:53)
    	at org.apache.spark.ml.Predictor.transformSchema(Predictor.scala:122)
    	at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)
    	at org.apache.spark.ml.Predictor.fit(Predictor.scala:90)
    	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.lang.reflect.Method.invoke(Method.java:498)
    	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
    	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
    	at py4j.Gateway.invoke(Gateway.java:280)
    	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
    	at py4j.commands.CallCommand.execute(CallCommand.java:79)
    	at py4j.GatewayConnection.run(GatewayConnection.java:214)
    	at java.lang.Thread.run(Thread.java:748)


        
    During handling of the above exception, another exception occurred:


        IllegalArgumentException                  Traceback (most recent call last)

        <ipython-input-27-19da259b44c3> in <module>()
          6 (trainingData, testData) = data.randomSplit([0.7, 0.3])
          7 \# Train model.
    ----> 8 model\_rf = rf.fit(trainingData)
          9 model\_dt = dt.fit(trainingData)


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py in fit(self, dataset, params)
         62                 return self.copy(params).\_fit(dataset)
         63             else:
    ---> 64                 return self.\_fit(dataset)
         65         else:
         66             raise ValueError("Params must be either a param map or a list/tuple of param maps, "


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py in \_fit(self, dataset)
        234 
        235     def \_fit(self, dataset):
    --> 236         java\_model = self.\_fit\_java(dataset)
        237         return self.\_create\_model(java\_model)
        238 


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py in \_fit\_java(self, dataset)
        231         """
        232         self.\_transfer\_params\_to\_java()
    --> 233         return self.\_java\_obj.fit(dataset.\_jdf)
        234 
        235     def \_fit(self, dataset):


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java\_gateway.py in \_\_call\_\_(self, *args)
       1131         answer = self.gateway\_client.send\_command(command)
       1132         return\_value = get\_return\_value(
    -> 1133             answer, self.gateway\_client, self.target\_id, self.name)
       1134 
       1135         for temp\_arg in temp\_args:


        \textasciitilde{}/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py in deco(*a, **kw)
         77                 raise QueryExecutionException(s.split(': ', 1)[1], stackTrace)
         78             if s.startswith('java.lang.IllegalArgumentException: '):
    ---> 79                 raise IllegalArgumentException(s.split(': ', 1)[1], stackTrace)
         80             raise
         81     return deco


        IllegalArgumentException: 'Field "features" does not exist.'

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
        \PY{k+kn}{import} \PY{n+nn}{findspark}
        \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{pyspark}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
        \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{basics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Read in the CSV data.}
        \PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Import the relevant Python libraries.}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        
        \PY{c+c1}{\PYZsh{} Convert sex to an array using Numpy and plot it using pyplot. }
        \PY{n}{OverTimeArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{OverTime}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{OverTimeArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Because you can interact with Spark using SQL, you can also filter the data you see. }
        \PY{c+c1}{\PYZsh{} For example, age has some null values. We can remove all null values before visualising the data.}
        \PY{n}{OverTimeArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{filter}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{OverTime \PYZgt{} 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{OverTime}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{AttritionArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_93_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_93_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
        \PY{k+kn}{import} \PY{n+nn}{findspark}
        \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{pyspark}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
        \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{basics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Read in the CSV data.}
        \PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Import the relevant Python libraries.}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        
        \PY{c+c1}{\PYZsh{} Convert sex to an array using Numpy and plot it using pyplot. }
        \PY{n}{JobSatisfactionArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{JobSatisfaction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{JobSatisfactionArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Because you can interact with Spark using SQL, you can also filter the data you see. }
        \PY{c+c1}{\PYZsh{} For example, age has some null values. We can remove all null values before visualising the data.}
        \PY{n}{OverTimeArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{filter}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{JobSatisfaction \PYZgt{} 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{JobSatisfaction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{AttritionArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_94_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_94_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
        \PY{k+kn}{import} \PY{n+nn}{findspark}
        \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{pyspark}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
        \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{basics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Read in the CSV data.}
        \PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Import the relevant Python libraries.}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        
        \PY{c+c1}{\PYZsh{} Convert sex to an array using Numpy and plot it using pyplot. }
        \PY{n}{AgeArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{AgeArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Because you can interact with Spark using SQL, you can also filter the data you see. }
        \PY{c+c1}{\PYZsh{} For example, age has some null values. We can remove all null values before visualising the data.}
        \PY{n}{OverTimeArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{filter}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age \PYZgt{} 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{AttritionArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_95_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_95_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{n}{Dataset1} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Dataset1.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n+nb}{print} \PY{p}{(}\PY{n}{Dataset1}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{n}{Dataset2} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Dataset2.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n+nb}{print} \PY{p}{(}\PY{n}{Dataset2}\PY{p}{)}
        \PY{n}{Dataset}\PY{o}{=}\PY{n}{pd}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{n}{Dataset1}\PY{p}{,} \PY{n}{Dataset2}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{Dataset}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
      Age Attrition     BusinessTravel  DailyRate              Department  \textbackslash{}
0      41       Yes      Travel\_Rarely       1102                   Sales   
1      49        No  Travel\_Frequently        279  Research \& Development   
2      37       Yes      Travel\_Rarely       1373  Research \& Development   
3      33        No  Travel\_Frequently       1392  Research \& Development   
4      27        No      Travel\_Rarely        591  Research \& Development   
5      32        No  Travel\_Frequently       1005  Research \& Development   
6      59        No      Travel\_Rarely       1324  Research \& Development   
7      30        No      Travel\_Rarely       1358  Research \& Development   
8      38        No  Travel\_Frequently        216  Research \& Development   
9      36        No      Travel\_Rarely       1299  Research \& Development   
10     35        No      Travel\_Rarely        809  Research \& Development   
11     29        No      Travel\_Rarely        153  Research \& Development   
12     31        No      Travel\_Rarely        670  Research \& Development   
13     34        No      Travel\_Rarely       1346  Research \& Development   
14     28       Yes      Travel\_Rarely        103  Research \& Development   
15     29        No      Travel\_Rarely       1389  Research \& Development   
16     32        No      Travel\_Rarely        334  Research \& Development   
17     22        No         Non-Travel       1123  Research \& Development   
18     53        No      Travel\_Rarely       1219                   Sales   
19     38        No      Travel\_Rarely        371  Research \& Development   
20     24        No         Non-Travel        673  Research \& Development   
21     36       Yes      Travel\_Rarely       1218                   Sales   
22     34        No      Travel\_Rarely        419  Research \& Development   
23     21        No      Travel\_Rarely        391  Research \& Development   
24     34       Yes      Travel\_Rarely        699  Research \& Development   
25     53        No      Travel\_Rarely       1282  Research \& Development   
26     32       Yes  Travel\_Frequently       1125  Research \& Development   
27     42        No      Travel\_Rarely        691                   Sales   
28     44        No      Travel\_Rarely        477  Research \& Development   
29     46        No      Travel\_Rarely        705                   Sales   
{\ldots}   {\ldots}       {\ldots}                {\ldots}        {\ldots}                     {\ldots}   
1440   36        No  Travel\_Frequently        688  Research \& Development   
1441   56        No         Non-Travel        667  Research \& Development   
1442   29       Yes      Travel\_Rarely       1092  Research \& Development   
1443   42        No      Travel\_Rarely        300  Research \& Development   
1444   56       Yes      Travel\_Rarely        310  Research \& Development   
1445   41        No      Travel\_Rarely        582  Research \& Development   
1446   34        No      Travel\_Rarely        704                   Sales   
1447   36        No         Non-Travel        301                   Sales   
1448   41        No      Travel\_Rarely        930                   Sales   
1449   32        No      Travel\_Rarely        529  Research \& Development   
1450   35        No      Travel\_Rarely       1146         Human Resources   
1451   38        No      Travel\_Rarely        345                   Sales   
1452   50       Yes  Travel\_Frequently        878                   Sales   
1453   36        No      Travel\_Rarely       1120                   Sales   
1454   45        No      Travel\_Rarely        374                   Sales   
1455   40        No      Travel\_Rarely       1322  Research \& Development   
1456   35        No  Travel\_Frequently       1199  Research \& Development   
1457   40        No      Travel\_Rarely       1194  Research \& Development   
1458   35        No      Travel\_Rarely        287  Research \& Development   
1459   29        No      Travel\_Rarely       1378  Research \& Development   
1460   29        No      Travel\_Rarely        468  Research \& Development   
1461   50       Yes      Travel\_Rarely        410                   Sales   
1462   39        No      Travel\_Rarely        722                   Sales   
1463   31        No         Non-Travel        325  Research \& Development   
1464   26        No      Travel\_Rarely       1167                   Sales   
1465   36        No  Travel\_Frequently        884  Research \& Development   
1466   39        No      Travel\_Rarely        613  Research \& Development   
1467   27        No      Travel\_Rarely        155  Research \& Development   
1468   49        No  Travel\_Frequently       1023                   Sales   
1469   34        No      Travel\_Rarely        628  Research \& Development   

      DistanceFromHome  Education    EducationField  EmployeeCount  \textbackslash{}
0                    1          2     Life Sciences              1   
1                    8          1     Life Sciences              1   
2                    2          2             Other              1   
3                    3          4     Life Sciences              1   
4                    2          1           Medical              1   
5                    2          2     Life Sciences              1   
6                    3          3           Medical              1   
7                   24          1     Life Sciences              1   
8                   23          3     Life Sciences              1   
9                   27          3           Medical              1   
10                  16          3           Medical              1   
11                  15          2     Life Sciences              1   
12                  26          1     Life Sciences              1   
13                  19          2           Medical              1   
14                  24          3     Life Sciences              1   
15                  21          4     Life Sciences              1   
16                   5          2     Life Sciences              1   
17                  16          2           Medical              1   
18                   2          4     Life Sciences              1   
19                   2          3     Life Sciences              1   
20                  11          2             Other              1   
21                   9          4     Life Sciences              1   
22                   7          4     Life Sciences              1   
23                  15          2     Life Sciences              1   
24                   6          1           Medical              1   
25                   5          3             Other              1   
26                  16          1     Life Sciences              1   
27                   8          4         Marketing              1   
28                   7          4           Medical              1   
29                   2          4         Marketing              1   
{\ldots}                {\ldots}        {\ldots}               {\ldots}            {\ldots}   
1440                 4          2     Life Sciences              1   
1441                 1          4     Life Sciences              1   
1442                 1          4           Medical              1   
1443                 2          3     Life Sciences              1   
1444                 7          2  Technical Degree              1   
1445                28          4     Life Sciences              1   
1446                28          3         Marketing              1   
1447                15          4         Marketing              1   
1448                 3          3     Life Sciences              1   
1449                 2          3  Technical Degree              1   
1450                26          4     Life Sciences              1   
1451                10          2     Life Sciences              1   
1452                 1          4     Life Sciences              1   
1453                11          4         Marketing              1   
1454                20          3     Life Sciences              1   
1455                 2          4     Life Sciences              1   
1456                18          4     Life Sciences              1   
1457                 2          4           Medical              1   
1458                 1          4     Life Sciences              1   
1459                13          2             Other              1   
1460                28          4           Medical              1   
1461                28          3         Marketing              1   
1462                24          1         Marketing              1   
1463                 5          3           Medical              1   
1464                 5          3             Other              1   
1465                23          2           Medical              1   
1466                 6          1           Medical              1   
1467                 4          3     Life Sciences              1   
1468                 2          3           Medical              1   
1469                 8          3           Medical              1   

      EmployeeNumber          {\ldots}           RelationshipSatisfaction  \textbackslash{}
0                  1          {\ldots}                                  1   
1                  2          {\ldots}                                  4   
2                  4          {\ldots}                                  2   
3                  5          {\ldots}                                  3   
4                  7          {\ldots}                                  4   
5                  8          {\ldots}                                  3   
6                 10          {\ldots}                                  1   
7                 11          {\ldots}                                  2   
8                 12          {\ldots}                                  2   
9                 13          {\ldots}                                  2   
10                14          {\ldots}                                  3   
11                15          {\ldots}                                  4   
12                16          {\ldots}                                  4   
13                18          {\ldots}                                  3   
14                19          {\ldots}                                  2   
15                20          {\ldots}                                  3   
16                21          {\ldots}                                  4   
17                22          {\ldots}                                  2   
18                23          {\ldots}                                  3   
19                24          {\ldots}                                  3   
20                26          {\ldots}                                  4   
21                27          {\ldots}                                  2   
22                28          {\ldots}                                  3   
23                30          {\ldots}                                  4   
24                31          {\ldots}                                  3   
25                32          {\ldots}                                  4   
26                33          {\ldots}                                  2   
27                35          {\ldots}                                  4   
28                36          {\ldots}                                  4   
29                38          {\ldots}                                  4   
{\ldots}              {\ldots}          {\ldots}                                {\ldots}   
1440            2025          {\ldots}                                  2   
1441            2026          {\ldots}                                  1   
1442            2027          {\ldots}                                  2   
1443            2031          {\ldots}                                  1   
1444            2032          {\ldots}                                  4   
1445            2034          {\ldots}                                  3   
1446            2035          {\ldots}                                  4   
1447            2036          {\ldots}                                  1   
1448            2037          {\ldots}                                  3   
1449            2038          {\ldots}                                  4   
1450            2040          {\ldots}                                  3   
1451            2041          {\ldots}                                  3   
1452            2044          {\ldots}                                  4   
1453            2045          {\ldots}                                  1   
1454            2046          {\ldots}                                  3   
1455            2048          {\ldots}                                  4   
1456            2049          {\ldots}                                  4   
1457            2051          {\ldots}                                  2   
1458            2052          {\ldots}                                  4   
1459            2053          {\ldots}                                  1   
1460            2054          {\ldots}                                  2   
1461            2055          {\ldots}                                  2   
1462            2056          {\ldots}                                  1   
1463            2057          {\ldots}                                  2   
1464            2060          {\ldots}                                  4   
1465            2061          {\ldots}                                  3   
1466            2062          {\ldots}                                  1   
1467            2064          {\ldots}                                  2   
1468            2065          {\ldots}                                  4   
1469            2068          {\ldots}                                  1   

     StandardHours  StockOptionLevel  TotalWorkingYears  \textbackslash{}
0               80                 0                  8   
1               80                 1                 10   
2               80                 0                  7   
3               80                 0                  8   
4               80                 1                  6   
5               80                 0                  8   
6               80                 3                 12   
7               80                 1                  1   
8               80                 0                 10   
9               80                 2                 17   
10              80                 1                  6   
11              80                 0                 10   
12              80                 1                  5   
13              80                 1                  3   
14              80                 0                  6   
15              80                 1                 10   
16              80                 2                  7   
17              80                 2                  1   
18              80                 0                 31   
19              80                 0                  6   
20              80                 1                  5   
21              80                 0                 10   
22              80                 0                 13   
23              80                 0                  0   
24              80                 0                  8   
25              80                 1                 26   
26              80                 0                 10   
27              80                 1                 10   
28              80                 1                 24   
29              80                 0                 22   
{\ldots}            {\ldots}               {\ldots}                {\ldots}   
1440            80                 3                 18   
1441            80                 1                 13   
1442            80                 3                  4   
1443            80                 0                 24   
1444            80                 1                 14   
1445            80                 1                 21   
1446            80                 2                  8   
1447            80                 1                 15   
1448            80                 1                 14   
1449            80                 0                  4   
1450            80                 0                  9   
1451            80                 1                 10   
1452            80                 2                 12   
1453            80                 1                  8   
1454            80                 0                  8   
1455            80                 0                  8   
1456            80                 2                 10   
1457            80                 3                 20   
1458            80                 1                  4   
1459            80                 1                 10   
1460            80                 0                  5   
1461            80                 1                 20   
1462            80                 1                 21   
1463            80                 0                 10   
1464            80                 0                  5   
1465            80                 1                 17   
1466            80                 1                  9   
1467            80                 1                  6   
1468            80                 0                 17   
1469            80                 0                  6   

      TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \textbackslash{}
0                         0               1               6   
1                         3               3              10   
2                         3               3               0   
3                         3               3               8   
4                         3               3               2   
5                         2               2               7   
6                         3               2               1   
7                         2               3               1   
8                         2               3               9   
9                         3               2               7   
10                        5               3               5   
11                        3               3               9   
12                        1               2               5   
13                        2               3               2   
14                        4               3               4   
15                        1               3              10   
16                        5               2               6   
17                        2               2               1   
18                        3               3              25   
19                        3               3               3   
20                        5               2               4   
21                        4               3               5   
22                        4               3              12   
23                        6               3               0   
24                        2               3               4   
25                        3               2              14   
26                        5               3              10   
27                        2               3               9   
28                        4               3              22   
29                        2               2               2   
{\ldots}                     {\ldots}             {\ldots}             {\ldots}   
1440                      3               3               4   
1441                      2               2              13   
1442                      3               4               2   
1443                      2               2              22   
1444                      4               1              10   
1445                      3               3              20   
1446                      2               3               8   
1447                      4               2              15   
1448                      5               3               5   
1449                      4               3               4   
1450                      2               3               9   
1451                      1               3              10   
1452                      3               3               6   
1453                      2               2               6   
1454                      3               3               5   
1455                      2               3               2   
1456                      2               4              10   
1457                      2               3               5   
1458                      5               3               4   
1459                      2               3               4   
1460                      3               1               5   
1461                      3               3               3   
1462                      2               2              20   
1463                      2               3               9   
1464                      2               3               4   
1465                      3               3               5   
1466                      5               3               7   
1467                      0               3               6   
1468                      3               2               9   
1469                      3               4               4   

     YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  
0                     4                        0                     5  
1                     7                        1                     7  
2                     0                        0                     0  
3                     7                        3                     0  
4                     2                        2                     2  
5                     7                        3                     6  
6                     0                        0                     0  
7                     0                        0                     0  
8                     7                        1                     8  
9                     7                        7                     7  
10                    4                        0                     3  
11                    5                        0                     8  
12                    2                        4                     3  
13                    2                        1                     2  
14                    2                        0                     3  
15                    9                        8                     8  
16                    2                        0                     5  
17                    0                        0                     0  
18                    8                        3                     7  
19                    2                        1                     2  
20                    2                        1                     3  
21                    3                        0                     3  
22                    6                        2                    11  
23                    0                        0                     0  
24                    2                        1                     3  
25                   13                        4                     8  
26                    2                        6                     7  
27                    7                        4                     2  
28                    6                        5                    17  
29                    2                        2                     1  
{\ldots}                 {\ldots}                      {\ldots}                   {\ldots}  
1440                  2                        0                     2  
1441                 12                        1                     9  
1442                  2                        2                     2  
1443                  6                        4                    14  
1444                  9                        9                     8  
1445                  7                        0                    10  
1446                  7                        1                     7  
1447                 12                       11                    11  
1448                  4                        0                     4  
1449                  2                        1                     2  
1450                  0                        1                     7  
1451                  7                        1                     9  
1452                  3                        0                     1  
1453                  3                        0                     0  
1454                  3                        0                     1  
1455                  2                        2                     2  
1456                  2                        0                     2  
1457                  3                        0                     2  
1458                  3                        1                     1  
1459                  3                        0                     3  
1460                  4                        0                     4  
1461                  2                        2                     0  
1462                  9                        9                     6  
1463                  4                        1                     7  
1464                  2                        0                     0  
1465                  2                        0                     3  
1466                  7                        1                     7  
1467                  2                        0                     3  
1468                  6                        0                     8  
1469                  3                        1                     2  

[1470 rows x 34 columns]
      MonthlyIncome
0              5993
1              5130
2              2090
3              2909
4              3468
5              3068
6              2670
7              2693
8              9526
9              5237
10             2426
11             4193
12             2911
13             2661
14             2028
15             9980
16             3298
17             2935
18            15427
19             3944
20             4011
21             3407
22            11994
23             1232
24             2960
25            19094
26             3919
27             6825
28            10248
29            18947
{\ldots}             {\ldots}
1440           5131
1441           6306
1442           4787
1443          18880
1444           2339
1445          13570
1446           6712
1447           5406
1448           8938
1449           2439
1450           8837
1451           5343
1452           6728
1453           6652
1454           4850
1455           2809
1456           5689
1457           2001
1458           2977
1459           4025
1460           3785
1461          10854
1462          12031
1463           9936
1464           2966
1465           2571
1466           9991
1467           6142
1468           5390
1469           4404

[1470 rows x 1 columns]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        MergeError                                Traceback (most recent call last)

        <ipython-input-1-148448fc79e2> in <module>()
          5 Dataset2 = pd.read\_csv("Dataset2.csv")
          6 print (Dataset2)
    ----> 7 Dataset=pd.merge(Dataset1, Dataset2)
          8 print(Dataset)


        \textasciitilde{}/.local/lib/python3.5/site-packages/pandas/core/reshape/merge.py in merge(left, right, how, on, left\_on, right\_on, left\_index, right\_index, sort, suffixes, copy, indicator, validate)
         59                          right\_index=right\_index, sort=sort, suffixes=suffixes,
         60                          copy=copy, indicator=indicator,
    ---> 61                          validate=validate)
         62     return op.get\_result()
         63 


        \textasciitilde{}/.local/lib/python3.5/site-packages/pandas/core/reshape/merge.py in \_\_init\_\_(self, left, right, how, on, left\_on, right\_on, axis, left\_index, right\_index, sort, suffixes, copy, indicator, validate)
        544             warnings.warn(msg, UserWarning)
        545 
    --> 546         self.\_validate\_specification()
        547 
        548         \# note this function has side effects


        \textasciitilde{}/.local/lib/python3.5/site-packages/pandas/core/reshape/merge.py in \_validate\_specification(self)
       1033                         'left\_index=\{lidx\}, right\_index=\{ridx\}'
       1034                         .format(lon=self.left\_on, ron=self.right\_on,
    -> 1035                                 lidx=self.left\_index, ridx=self.right\_index))
       1036                 if not common\_cols.is\_unique:
       1037                     raise MergeError("Data columns not unique: \{common!r\}"


        MergeError: No common columns to perform merge on. Merge options: left\_on=None, right\_on=None, left\_index=False, right\_index=False

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
        \PY{k+kn}{import} \PY{n+nn}{findspark}
        \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{pyspark}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
        \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{basics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Read in the CSV data.}
        \PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Import the relevant Python libraries.}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        
        \PY{c+c1}{\PYZsh{} Convert sex to an array using Numpy and plot it using pyplot. }
        \PY{n}{MonthlyIncomeArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{MonthlyIncomeArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Because you can interact with Spark using SQL, you can also filter the data you see. }
        \PY{c+c1}{\PYZsh{} For example, age has some null values. We can remove all null values before visualising the data.}
        \PY{n}{MonthlyIncomeArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{filter}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome \PYZgt{} 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{MonthlyIncomeArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_97_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_97_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
        \PY{k+kn}{import} \PY{n+nn}{findspark}
        \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{pyspark}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
        \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{basics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Read in the CSV data.}
        \PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Import the relevant Python libraries.}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        
        \PY{c+c1}{\PYZsh{} Convert sex to an array using Numpy and plot it using pyplot. }
        \PY{n}{AgeArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{AgeArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Because you can interact with Spark using SQL, you can also filter the data you see. }
        \PY{c+c1}{\PYZsh{} For example, age has some null values. We can remove all null values before visualising the data.}
        \PY{n}{AgeArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{filter}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age \PYZgt{} 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{AgeArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_98_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_98_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
        \PY{k+kn}{import} \PY{n+nn}{findspark}
        \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{pyspark}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
        \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{basics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Read in the CSV data.}
        \PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Import the relevant Python libraries.}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        
        \PY{c+c1}{\PYZsh{} Convert sex to an array using Numpy and plot it using pyplot. }
        \PY{n}{YearsAtCompanyArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YearsAtCompany}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{YearsAtCompanyArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Because you can interact with Spark using SQL, you can also filter the data you see. }
        \PY{c+c1}{\PYZsh{} For example, age has some null values. We can remove all null values before visualising the data.}
        \PY{n}{YearsAtCompanyArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{filter}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YearsAtCompany \PYZgt{} 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YearsAtCompany}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{YearsAtCompanyArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_99_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_99_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
        \PY{k+kn}{import} \PY{n+nn}{findspark}
        \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{pyspark}
        \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
        \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{basics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Read in the CSV data.}
        \PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Import the relevant Python libraries.}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        
        \PY{c+c1}{\PYZsh{} Convert sex to an array using Numpy and plot it using pyplot. }
        \PY{n}{JobSatisfactionArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{JobSatisfaction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{JobSatisfactionArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Because you can interact with Spark using SQL, you can also filter the data you see. }
        \PY{c+c1}{\PYZsh{} For example, age has some null values. We can remove all null values before visualising the data.}
        \PY{n}{JobSatisfactionArr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{filter}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{JobSatisfaction \PYZgt{} 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{JobSatisfaction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{JobSatisfactionArr}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_100_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_100_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{c+c1}{\PYZsh{} Must be included at the beginning of each new notebook. Remember to change the app name.}
         \PY{k+kn}{import} \PY{n+nn}{findspark}
         \PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/ubuntu/spark\PYZhy{}2.1.1\PYZhy{}bin\PYZhy{}hadoop2.7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k+kn}{import} \PY{n+nn}{pyspark}
         \PY{k+kn}{from} \PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql} \PY{k}{import} \PY{n}{SparkSession}
         \PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder}\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{basics}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Read in the CSV data.}
         \PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dataset.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Import the relevant Python libraries.}
         \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
         
         \PY{n}{X}\PY{o}{=}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{y}\PY{o}{=}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MonthlyIncome}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{reg}\PY{o}{=}\PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}
         \PY{n}{reg}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{The linear model is Y= }\PY{l+s+si}{\PYZob{}:.5\PYZcb{}}\PY{l+s+s2}{ + }\PY{l+s+si}{\PYZob{}:.5\PYZcb{}}\PY{l+s+s2}{X}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{reg}\PY{o}{.}\PY{n}{intercept\PYZus{}}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{reg}\PY{o}{.}\PY{n}{coef\PYZus{}}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        NameError                                 Traceback (most recent call last)

        <ipython-input-11-606e730f0558> in <module>()
         13 get\_ipython().run\_line\_magic('matplotlib', 'inline')
         14 
    ---> 15 X=dataset['Age'].values.reshape(-1,1)
         16 y=dataset['MonthlyIncome'].values.reshape(-1,1)
         17 reg=LinearRegression()


        NameError: name 'dataset' is not defined

    \end{Verbatim}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
